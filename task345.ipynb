{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTCST85Jf6sA"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vWAHL-gh-mt",
        "outputId": "75039135-77af-4d61-80d5-7d9b9ba3c28c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/COSRMAL_CHALLENGE/CORSMAL-Challenge-2022-Squids\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qzV3QqaG5Lv",
        "outputId": "abec0ab8-95c7-4078-bb8f-6a564a89c3d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/COSRMAL_CHALLENGE/CORSMAL-Challenge-2022-Squids\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v9ej-BmvgInY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "588b908e-eb91-4548-9721-d6ca60f65c2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import scipy\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import cv2\n",
        "import scipy.io.wavfile\n",
        "import time\n",
        "import IPython\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "import json\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms\n",
        "from dataset import MiniDataset\n",
        "from loss import computeScoreType1, myLoss\n",
        "from models import Net, effnetv2_xl, MobileNetV3_Large, mbv2_ca\n",
        "from helper import train_image, evaluate_image\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BTQA8MKYgN1r"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD_new/crops_rgb_train.zip /content/crops_rgb_train.zip\n",
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD_new/crops_rgb_test.zip /content/crops_rgb_test.zip\n",
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD_new/crops_depth_train.zip /content/crops_depth_train.zip\n",
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD_new/crops_depth_test.zip /content/crops_depth_test.zip\n",
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD_new/labals_test.zip /content/labels_test.zip\n",
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD_new/labals_train.zip /content/labels_train.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/crops_rgb_train.zip -d /content/\n",
        "!unzip /content/crops_rgb_test.zip -d /content/\n",
        "!unzip /content/crops_depth_train.zip -d /content/\n",
        "!unzip /content/crops_depth_test.zip -d /content/\n",
        "!unzip /content/labels_train.zip -d /content/\n",
        "!unzip /content/labels_test.zip -d /content/"
      ],
      "metadata": {
        "id": "hrzlH3cy8VwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d101339-a5fc-4dfe-9449-2e8c5c049da3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/crops_rgb_train.zip\n",
            "replace /content/train/crops_rgb/002215.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  /content/crops_rgb_test.zip\n",
            "replace /content/test/crops_rgb/000408.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  /content/crops_depth_train.zip\n",
            "replace /content/train/crops_depth/002215.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  /content/crops_depth_test.zip\n",
            "replace /content/test/crops_depth/000408.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  /content/labels_train.zip\n",
            "replace /content/train/labels/001861.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  /content/labels_test.zip\n",
            "replace /content/test/labels/000478.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GKjFsuRg8wX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de68f82e-6810-4ce7-a20b-96c059d7709f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/crops_rgb_train.zip\n",
            "replace /content/train/train/crops_rgb/002215.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  /content/crops_rgb_test.zip\n",
            "replace /content/test/test/crops_rgb/000408.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  /content/crops_depth_train.zip\n",
            "replace /content/train/train/crops_depth/002215.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  /content/crops_depth_test.zip\n",
            "replace /content/test/test/crops_depth/000408.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "os.makedirs('/content/train',exist_ok=True)\n",
        "os.makedirs('/content/test',exist_ok=True)\n",
        "!unzip /content/crops_rgb_train.zip -d /content/train/\n",
        "!unzip /content/crops_rgb_test.zip -d /content/test/\n",
        "!unzip /content/crops_depth_train.zip -d /content/train/\n",
        "!unzip /content/crops_depth_test.zip -d /content/test/\n",
        "!unzip /content/labels_train.zip -d /content/train/\n",
        "!unzip /content/labels_test.zip -d /content/test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2kxapxBc7_J"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugrRquc7DAqt"
      },
      "source": [
        "## Capacity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7ge09lVhZNY",
        "outputId": "e6ffa79b-2cf5-4e4d-ec58-297c4b6000fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/50 train loss:0.5427 train acc:31.11% val loss:0.5720 val acc:26.78%\n",
            "2/50 train loss:0.4562 train acc:48.15% val loss:0.4846 val acc:38.49%\n",
            "3/50 train loss:0.3094 train acc:69.06% val loss:0.3300 val acc:67.00%\n",
            "4/50 train loss:0.2892 train acc:71.08% val loss:0.3078 val acc:69.22%\n",
            "5/50 train loss:0.2902 train acc:70.98% val loss:0.3136 val acc:68.64%\n",
            "6/50 train loss:0.2866 train acc:71.34% val loss:0.3190 val acc:68.10%\n",
            "7/50 train loss:0.2842 train acc:71.58% val loss:0.3055 val acc:69.45%\n",
            "8/50 train loss:0.2883 train acc:71.17% val loss:0.3106 val acc:68.94%\n",
            "9/50 train loss:0.2878 train acc:71.22% val loss:0.3123 val acc:68.77%\n",
            "10/50 train loss:0.2875 train acc:71.25% val loss:0.3227 val acc:67.73%\n",
            "11/50 train loss:0.2860 train acc:71.40% val loss:0.3280 val acc:67.20%\n",
            "12/50 train loss:0.2822 train acc:71.78% val loss:0.3241 val acc:67.59%\n",
            "13/50 train loss:0.2841 train acc:71.59% val loss:0.3093 val acc:69.07%\n",
            "14/50 train loss:0.2835 train acc:71.65% val loss:0.3170 val acc:68.30%\n",
            "15/50 train loss:0.2819 train acc:71.81% val loss:0.2970 val acc:70.30%\n",
            "16/50 train loss:0.2795 train acc:72.05% val loss:0.3009 val acc:69.91%\n",
            "17/50 train loss:0.2811 train acc:71.89% val loss:0.2784 val acc:72.16%\n",
            "18/50 train loss:0.2796 train acc:72.04% val loss:0.2546 val acc:74.54%\n",
            "19/50 train loss:0.2710 train acc:72.90% val loss:0.2514 val acc:74.86%\n",
            "20/50 train loss:0.2632 train acc:73.68% val loss:0.2623 val acc:73.77%\n",
            "21/50 train loss:0.2486 train acc:75.14% val loss:0.2511 val acc:74.89%\n",
            "22/50 train loss:0.2391 train acc:76.09% val loss:0.2541 val acc:74.59%\n",
            "23/50 train loss:0.2295 train acc:77.05% val loss:0.2484 val acc:75.16%\n",
            "24/50 train loss:0.2156 train acc:78.44% val loss:0.2445 val acc:75.55%\n",
            "25/50 train loss:0.2117 train acc:78.83% val loss:0.2510 val acc:74.90%\n",
            "26/50 train loss:0.2049 train acc:79.51% val loss:0.2446 val acc:75.54%\n",
            "27/50 train loss:0.2025 train acc:79.75% val loss:0.2391 val acc:76.09%\n",
            "28/50 train loss:0.1977 train acc:80.23% val loss:0.2455 val acc:75.45%\n",
            "29/50 train loss:0.1950 train acc:80.50% val loss:0.2276 val acc:77.24%\n",
            "30/50 train loss:0.1874 train acc:81.26% val loss:0.2439 val acc:75.61%\n",
            "31/50 train loss:0.1846 train acc:81.54% val loss:0.2500 val acc:75.00%\n",
            "32/50 train loss:0.1814 train acc:81.86% val loss:0.2170 val acc:78.30%\n",
            "33/50 train loss:0.1772 train acc:82.28% val loss:0.2399 val acc:76.01%\n",
            "34/50 train loss:0.1730 train acc:82.70% val loss:0.2113 val acc:78.87%\n",
            "35/50 train loss:0.1670 train acc:83.30% val loss:0.2219 val acc:77.81%\n",
            "36/50 train loss:0.1560 train acc:84.40% val loss:0.2144 val acc:78.56%\n",
            "37/50 train loss:0.1521 train acc:84.79% val loss:0.2091 val acc:79.09%\n",
            "38/50 train loss:0.1467 train acc:85.33% val loss:0.2215 val acc:77.85%\n",
            "39/50 train loss:0.1413 train acc:85.87% val loss:0.1991 val acc:80.09%\n",
            "40/50 train loss:0.1392 train acc:86.08% val loss:0.1974 val acc:80.26%\n",
            "41/50 train loss:0.1346 train acc:86.54% val loss:0.2169 val acc:78.31%\n",
            "42/50 train loss:0.1313 train acc:86.87% val loss:0.2235 val acc:77.65%\n",
            "43/50 train loss:0.1261 train acc:87.39% val loss:0.2361 val acc:76.39%\n",
            "44/50 train loss:0.1220 train acc:87.80% val loss:0.2235 val acc:77.65%\n",
            "45/50 train loss:0.1216 train acc:87.84% val loss:0.2416 val acc:75.84%\n",
            "46/50 train loss:0.1205 train acc:87.95% val loss:0.2214 val acc:77.86%\n",
            "47/50 train loss:0.1122 train acc:88.78% val loss:0.1910 val acc:80.90%\n",
            "48/50 train loss:0.1136 train acc:88.64% val loss:0.2016 val acc:79.84%\n",
            "49/50 train loss:0.1125 train acc:88.75% val loss:0.1894 val acc:81.06%\n",
            "50/50 train loss:0.1070 train acc:89.30% val loss:0.1910 val acc:80.90%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 2\n",
        "train_split = 0.8\n",
        "lr = 1e-4\n",
        "epochs = 50\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb')\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                        '/content/test/labels', \n",
        "                        '/content/test/crops_depth',\n",
        "                        '/content/test/crops_rgb')\n",
        "model = effnetv2_xl(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  \n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train / num_train, 100 * correct_train/num_train,\n",
        "      loss_val /num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"XL-my{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB5uZuFlmZgS",
        "outputId": "7e2279bc-862e-4d90-afca-ad5edc9e722c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5963 train acc:24.71% val loss:0.5315 val acc:35.67%\n",
            "2/100 train loss:0.4706 train acc:38.27% val loss:0.7242 val acc:0.60%\n",
            "3/100 train loss:0.3704 train acc:55.41% val loss:0.3444 val acc:60.08%\n",
            "4/100 train loss:0.3108 train acc:65.45% val loss:0.4562 val acc:53.52%\n",
            "5/100 train loss:0.2637 train acc:72.20% val loss:0.2807 val acc:71.67%\n",
            "6/100 train loss:0.2341 train acc:75.72% val loss:0.4366 val acc:55.67%\n",
            "7/100 train loss:0.2190 train acc:77.07% val loss:0.2541 val acc:74.59%\n",
            "8/100 train loss:0.1995 train acc:79.21% val loss:0.2256 val acc:77.44%\n",
            "9/100 train loss:0.1982 train acc:79.42% val loss:0.3874 val acc:61.26%\n",
            "10/100 train loss:0.2175 train acc:77.48% val loss:0.5762 val acc:41.36%\n",
            "11/100 train loss:0.2191 train acc:77.38% val loss:0.2387 val acc:76.13%\n",
            "12/100 train loss:0.2662 train acc:72.18% val loss:0.2828 val acc:71.19%\n",
            "13/100 train loss:0.2357 train acc:75.66% val loss:0.5781 val acc:41.99%\n",
            "14/100 train loss:0.2013 train acc:79.18% val loss:0.2625 val acc:73.75%\n",
            "15/100 train loss:0.1889 train acc:80.45% val loss:0.2993 val acc:69.19%\n",
            "16/100 train loss:0.1938 train acc:79.96% val loss:0.3623 val acc:63.62%\n",
            "17/100 train loss:0.2068 train acc:78.61% val loss:0.2088 val acc:79.12%\n",
            "18/100 train loss:0.1971 train acc:79.57% val loss:0.2024 val acc:79.60%\n",
            "19/100 train loss:0.1821 train acc:81.11% val loss:0.2021 val acc:79.79%\n",
            "20/100 train loss:0.1735 train acc:81.99% val loss:0.1882 val acc:80.93%\n",
            "21/100 train loss:0.1667 train acc:82.61% val loss:0.1913 val acc:80.87%\n",
            "22/100 train loss:0.1554 train acc:83.82% val loss:0.1904 val acc:80.96%\n",
            "23/100 train loss:0.1610 train acc:83.24% val loss:0.2215 val acc:77.85%\n",
            "24/100 train loss:0.1554 train acc:83.81% val loss:0.1851 val acc:81.49%\n",
            "25/100 train loss:0.1617 train acc:83.18% val loss:0.6047 val acc:39.00%\n",
            "26/100 train loss:0.1587 train acc:83.48% val loss:0.1821 val acc:81.79%\n",
            "27/100 train loss:0.1960 train acc:79.71% val loss:0.2470 val acc:75.30%\n",
            "28/100 train loss:0.1934 train acc:79.94% val loss:0.1959 val acc:80.41%\n",
            "29/100 train loss:0.1795 train acc:81.39% val loss:0.1746 val acc:82.54%\n",
            "30/100 train loss:0.1712 train acc:82.23% val loss:0.1782 val acc:82.18%\n",
            "31/100 train loss:0.1726 train acc:82.03% val loss:0.1837 val acc:81.63%\n",
            "32/100 train loss:0.1603 train acc:83.33% val loss:0.1666 val acc:83.34%\n",
            "33/100 train loss:0.1667 train acc:82.67% val loss:0.1705 val acc:82.95%\n",
            "34/100 train loss:0.1573 train acc:83.64% val loss:0.1627 val acc:83.73%\n",
            "35/100 train loss:0.1495 train acc:84.40% val loss:0.1928 val acc:80.72%\n",
            "36/100 train loss:0.1510 train acc:84.21% val loss:0.2148 val acc:78.52%\n",
            "37/100 train loss:0.1688 train acc:82.43% val loss:0.1882 val acc:81.18%\n",
            "38/100 train loss:0.1495 train acc:84.40% val loss:0.1883 val acc:81.17%\n",
            "39/100 train loss:0.1473 train acc:84.63% val loss:0.1714 val acc:82.86%\n",
            "40/100 train loss:0.1596 train acc:83.36% val loss:0.1954 val acc:80.46%\n",
            "41/100 train loss:0.1575 train acc:83.58% val loss:0.1883 val acc:81.17%\n",
            "42/100 train loss:0.1516 train acc:84.17% val loss:0.1923 val acc:80.77%\n",
            "43/100 train loss:0.1442 train acc:84.92% val loss:0.2223 val acc:77.77%\n",
            "44/100 train loss:0.1600 train acc:83.32% val loss:0.1849 val acc:81.24%\n",
            "45/100 train loss:0.1435 train acc:85.01% val loss:0.1673 val acc:83.07%\n",
            "46/100 train loss:0.1494 train acc:84.41% val loss:0.1795 val acc:81.84%\n",
            "47/100 train loss:0.1571 train acc:83.65% val loss:0.2100 val acc:79.00%\n",
            "48/100 train loss:0.2046 train acc:78.79% val loss:0.2094 val acc:79.06%\n",
            "49/100 train loss:0.1716 train acc:82.18% val loss:0.1830 val acc:81.50%\n",
            "50/100 train loss:0.1737 train acc:81.92% val loss:0.2684 val acc:73.16%\n",
            "51/100 train loss:0.1845 train acc:80.86% val loss:0.2211 val acc:77.89%\n",
            "52/100 train loss:0.1867 train acc:80.62% val loss:0.1923 val acc:80.77%\n",
            "53/100 train loss:0.1679 train acc:82.53% val loss:0.1785 val acc:82.15%\n",
            "54/100 train loss:0.1646 train acc:82.87% val loss:0.2060 val acc:79.40%\n",
            "55/100 train loss:0.1666 train acc:82.69% val loss:0.3236 val acc:67.64%\n",
            "56/100 train loss:0.1510 train acc:84.26% val loss:0.2078 val acc:79.16%\n",
            "57/100 train loss:0.1572 train acc:83.64% val loss:0.1707 val acc:82.93%\n",
            "58/100 train loss:0.1594 train acc:83.37% val loss:0.1772 val acc:82.28%\n",
            "59/100 train loss:0.1408 train acc:85.18% val loss:0.1722 val acc:82.78%\n",
            "60/100 train loss:0.1452 train acc:84.68% val loss:0.1808 val acc:81.92%\n",
            "61/100 train loss:0.1396 train acc:85.33% val loss:0.2462 val acc:75.38%\n",
            "62/100 train loss:0.1593 train acc:83.26% val loss:0.2206 val acc:77.94%\n",
            "63/100 train loss:0.1627 train acc:82.93% val loss:0.1713 val acc:82.87%\n",
            "64/100 train loss:0.1574 train acc:83.55% val loss:0.1884 val acc:81.16%\n",
            "65/100 train loss:0.1531 train acc:83.96% val loss:0.1799 val acc:82.01%\n",
            "66/100 train loss:0.1447 train acc:84.71% val loss:0.1831 val acc:81.49%\n",
            "67/100 train loss:0.1410 train acc:85.21% val loss:0.1680 val acc:82.99%\n",
            "68/100 train loss:0.1471 train acc:84.53% val loss:0.2071 val acc:79.29%\n",
            "69/100 train loss:0.1653 train acc:82.61% val loss:0.1919 val acc:80.81%\n",
            "70/100 train loss:0.1579 train acc:83.37% val loss:0.1965 val acc:80.35%\n",
            "71/100 train loss:0.1546 train acc:83.59% val loss:0.1833 val acc:81.67%\n",
            "72/100 train loss:0.1434 train acc:84.73% val loss:0.1920 val acc:80.80%\n",
            "73/100 train loss:0.1482 train acc:84.23% val loss:0.1704 val acc:82.68%\n",
            "74/100 train loss:0.1528 train acc:83.77% val loss:0.2837 val acc:71.35%\n",
            "75/100 train loss:0.1509 train acc:84.07% val loss:0.3615 val acc:63.85%\n",
            "76/100 train loss:0.1481 train acc:84.41% val loss:0.1888 val acc:81.12%\n",
            "77/100 train loss:0.1395 train acc:85.36% val loss:0.1883 val acc:81.17%\n",
            "78/100 train loss:0.1397 train acc:85.20% val loss:0.1949 val acc:80.45%\n",
            "79/100 train loss:0.1394 train acc:85.23% val loss:0.1700 val acc:82.93%\n",
            "80/100 train loss:0.1421 train acc:85.00% val loss:0.1743 val acc:82.10%\n",
            "81/100 train loss:0.1388 train acc:85.35% val loss:0.2795 val acc:72.05%\n",
            "82/100 train loss:0.1547 train acc:83.70% val loss:0.1996 val acc:80.04%\n",
            "83/100 train loss:0.1622 train acc:82.75% val loss:0.2502 val acc:74.27%\n",
            "84/100 train loss:0.1525 train acc:84.04% val loss:0.1771 val acc:82.29%\n",
            "85/100 train loss:0.1539 train acc:83.84% val loss:0.3409 val acc:65.91%\n",
            "86/100 train loss:0.1569 train acc:83.59% val loss:0.1885 val acc:81.15%\n",
            "87/100 train loss:0.1492 train acc:84.21% val loss:0.1829 val acc:81.71%\n",
            "88/100 train loss:0.1454 train acc:84.57% val loss:0.1954 val acc:80.26%\n",
            "89/100 train loss:0.1469 train acc:84.47% val loss:0.1929 val acc:80.71%\n",
            "90/100 train loss:0.1408 train acc:85.02% val loss:0.1600 val acc:84.00%\n",
            "91/100 train loss:0.1395 train acc:85.22% val loss:0.1723 val acc:82.77%\n",
            "92/100 train loss:0.1376 train acc:85.46% val loss:0.1836 val acc:81.64%\n",
            "93/100 train loss:0.1364 train acc:85.52% val loss:0.1772 val acc:82.28%\n",
            "94/100 train loss:0.1490 train acc:84.25% val loss:0.2010 val acc:79.90%\n",
            "95/100 train loss:0.1571 train acc:83.58% val loss:0.1859 val acc:81.41%\n",
            "96/100 train loss:0.1430 train acc:84.93% val loss:0.1967 val acc:80.33%\n",
            "97/100 train loss:0.1502 train acc:84.26% val loss:0.1944 val acc:80.56%\n",
            "98/100 train loss:0.1397 train acc:85.12% val loss:0.1861 val acc:81.39%\n",
            "99/100 train loss:0.1457 train acc:84.53% val loss:0.1783 val acc:82.17%\n",
            "100/100 train loss:0.1393 train acc:85.20% val loss:0.1822 val acc:81.78%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb')\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                        '/content/test/labels', \n",
        "                        '/content/test/crops_depth',\n",
        "                        '/content/test/crops_rgb')\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3buwods0G4bU"
      },
      "source": [
        "## Mass estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJnFwsafG7AD",
        "outputId": "97997721-2cb3-4780-e19b-678d54305acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5667 train acc:37.74% val loss:0.5231 val acc:44.64%\n",
            "2/100 train loss:0.5083 train acc:43.19% val loss:0.5097 val acc:47.50%\n",
            "3/100 train loss:0.4908 train acc:46.11% val loss:0.5032 val acc:48.44%\n",
            "4/100 train loss:0.4784 train acc:47.61% val loss:0.4909 val acc:49.17%\n",
            "5/100 train loss:0.4683 train acc:49.29% val loss:0.4888 val acc:50.77%\n",
            "6/100 train loss:0.4605 train acc:51.14% val loss:0.4803 val acc:51.59%\n",
            "7/100 train loss:0.4529 train acc:52.43% val loss:0.4681 val acc:52.47%\n",
            "8/100 train loss:0.4413 train acc:53.27% val loss:0.4599 val acc:52.16%\n",
            "9/100 train loss:0.4282 train acc:54.98% val loss:0.4517 val acc:53.61%\n",
            "10/100 train loss:0.4172 train acc:55.60% val loss:0.4335 val acc:56.07%\n",
            "11/100 train loss:0.4110 train acc:56.66% val loss:0.4307 val acc:56.48%\n",
            "12/100 train loss:0.3991 train acc:58.20% val loss:0.4280 val acc:56.90%\n",
            "13/100 train loss:0.3940 train acc:59.06% val loss:0.4195 val acc:57.86%\n",
            "14/100 train loss:0.3837 train acc:60.33% val loss:0.4118 val acc:58.62%\n",
            "15/100 train loss:0.3765 train acc:60.94% val loss:0.4041 val acc:59.59%\n",
            "16/100 train loss:0.3742 train acc:61.17% val loss:0.4049 val acc:59.11%\n",
            "17/100 train loss:0.3729 train acc:61.36% val loss:0.4052 val acc:58.77%\n",
            "18/100 train loss:0.3744 train acc:61.32% val loss:0.4077 val acc:59.19%\n",
            "19/100 train loss:0.3735 train acc:61.62% val loss:0.3961 val acc:60.35%\n",
            "20/100 train loss:0.3737 train acc:61.55% val loss:0.3884 val acc:60.89%\n",
            "21/100 train loss:0.3696 train acc:62.09% val loss:0.4060 val acc:59.40%\n",
            "22/100 train loss:0.3627 train acc:62.89% val loss:0.3890 val acc:61.10%\n",
            "23/100 train loss:0.3587 train acc:63.19% val loss:0.3949 val acc:60.48%\n",
            "24/100 train loss:0.3529 train acc:63.71% val loss:0.3904 val acc:60.82%\n",
            "25/100 train loss:0.3438 train acc:64.63% val loss:0.3887 val acc:61.13%\n",
            "26/100 train loss:0.3453 train acc:64.57% val loss:0.3814 val acc:61.81%\n",
            "27/100 train loss:0.3367 train acc:65.32% val loss:0.3959 val acc:60.08%\n",
            "28/100 train loss:0.3372 train acc:65.30% val loss:0.3949 val acc:60.48%\n",
            "29/100 train loss:0.3315 train acc:65.85% val loss:0.3830 val acc:61.63%\n",
            "30/100 train loss:0.3278 train acc:66.22% val loss:0.3791 val acc:62.09%\n",
            "31/100 train loss:0.3326 train acc:65.84% val loss:0.3697 val acc:63.03%\n",
            "32/100 train loss:0.3314 train acc:65.98% val loss:0.3710 val acc:62.90%\n",
            "33/100 train loss:0.3211 train acc:66.97% val loss:0.3686 val acc:62.85%\n",
            "34/100 train loss:0.3289 train acc:66.24% val loss:0.3631 val acc:63.69%\n",
            "35/100 train loss:0.3285 train acc:66.37% val loss:0.3744 val acc:62.56%\n",
            "36/100 train loss:0.3204 train acc:67.23% val loss:0.3696 val acc:63.04%\n",
            "37/100 train loss:0.3166 train acc:67.56% val loss:0.3587 val acc:64.13%\n",
            "38/100 train loss:0.3162 train acc:67.52% val loss:0.3631 val acc:63.69%\n",
            "39/100 train loss:0.3130 train acc:67.89% val loss:0.3455 val acc:65.45%\n",
            "40/100 train loss:0.3173 train acc:67.46% val loss:0.3654 val acc:63.46%\n",
            "41/100 train loss:0.3175 train acc:67.41% val loss:0.3604 val acc:63.96%\n",
            "42/100 train loss:0.3077 train acc:68.35% val loss:0.3640 val acc:63.59%\n",
            "43/100 train loss:0.3039 train acc:68.69% val loss:0.3591 val acc:64.09%\n",
            "44/100 train loss:0.3007 train acc:69.01% val loss:0.3627 val acc:63.72%\n",
            "45/100 train loss:0.3027 train acc:68.85% val loss:0.3569 val acc:64.29%\n",
            "46/100 train loss:0.3045 train acc:68.64% val loss:0.3550 val acc:64.50%\n",
            "47/100 train loss:0.3103 train acc:68.09% val loss:0.3520 val acc:64.80%\n",
            "48/100 train loss:0.3057 train acc:68.57% val loss:0.3539 val acc:64.61%\n",
            "49/100 train loss:0.3009 train acc:68.99% val loss:0.3581 val acc:64.19%\n",
            "50/100 train loss:0.3064 train acc:68.40% val loss:0.3377 val acc:66.23%\n",
            "51/100 train loss:0.3074 train acc:68.29% val loss:0.3485 val acc:65.15%\n",
            "52/100 train loss:0.3016 train acc:68.86% val loss:0.3597 val acc:63.98%\n",
            "53/100 train loss:0.2974 train acc:69.27% val loss:0.3737 val acc:62.60%\n",
            "54/100 train loss:0.2955 train acc:69.44% val loss:0.3534 val acc:64.66%\n",
            "55/100 train loss:0.3014 train acc:68.85% val loss:0.3437 val acc:65.60%\n",
            "56/100 train loss:0.3045 train acc:68.56% val loss:0.3480 val acc:65.16%\n",
            "57/100 train loss:0.3006 train acc:69.03% val loss:0.3585 val acc:64.13%\n",
            "58/100 train loss:0.2900 train acc:70.08% val loss:0.3434 val acc:65.66%\n",
            "59/100 train loss:0.2921 train acc:69.88% val loss:0.3434 val acc:65.65%\n",
            "60/100 train loss:0.2860 train acc:70.49% val loss:0.3412 val acc:65.85%\n",
            "61/100 train loss:0.2897 train acc:70.11% val loss:0.3456 val acc:65.44%\n",
            "62/100 train loss:0.2887 train acc:70.21% val loss:0.3518 val acc:64.82%\n",
            "63/100 train loss:0.2926 train acc:69.86% val loss:0.3281 val acc:67.13%\n",
            "64/100 train loss:0.2881 train acc:70.31% val loss:0.3400 val acc:66.00%\n",
            "65/100 train loss:0.3019 train acc:68.93% val loss:0.3614 val acc:63.86%\n",
            "66/100 train loss:0.3058 train acc:68.69% val loss:0.3504 val acc:64.90%\n",
            "67/100 train loss:0.3199 train acc:67.28% val loss:0.3608 val acc:63.67%\n",
            "68/100 train loss:0.3105 train acc:68.22% val loss:0.3473 val acc:65.27%\n",
            "69/100 train loss:0.2998 train acc:69.24% val loss:0.3441 val acc:65.59%\n",
            "70/100 train loss:0.2947 train acc:69.81% val loss:0.3408 val acc:65.92%\n",
            "71/100 train loss:0.2930 train acc:69.98% val loss:0.3504 val acc:64.71%\n",
            "72/100 train loss:0.2880 train acc:70.50% val loss:0.3470 val acc:65.30%\n",
            "73/100 train loss:0.2943 train acc:69.89% val loss:0.3516 val acc:64.84%\n",
            "74/100 train loss:0.2911 train acc:70.14% val loss:0.3455 val acc:65.44%\n",
            "75/100 train loss:0.2834 train acc:70.94% val loss:0.3401 val acc:65.99%\n",
            "76/100 train loss:0.2842 train acc:70.83% val loss:0.3343 val acc:66.57%\n",
            "77/100 train loss:0.2796 train acc:71.25% val loss:0.3350 val acc:66.50%\n",
            "78/100 train loss:0.2782 train acc:71.40% val loss:0.3346 val acc:66.54%\n",
            "79/100 train loss:0.2847 train acc:70.76% val loss:0.3550 val acc:64.50%\n",
            "80/100 train loss:0.2857 train acc:70.69% val loss:0.3401 val acc:65.99%\n",
            "81/100 train loss:0.2863 train acc:70.65% val loss:0.3410 val acc:65.90%\n",
            "82/100 train loss:0.2875 train acc:70.55% val loss:0.3366 val acc:66.34%\n",
            "83/100 train loss:0.2910 train acc:70.16% val loss:0.3444 val acc:65.56%\n",
            "84/100 train loss:0.3066 train acc:68.63% val loss:0.3454 val acc:65.45%\n",
            "85/100 train loss:0.2990 train acc:69.40% val loss:0.3490 val acc:65.10%\n",
            "86/100 train loss:0.2963 train acc:69.67% val loss:0.3555 val acc:64.45%\n",
            "87/100 train loss:0.2876 train acc:70.53% val loss:0.3406 val acc:65.93%\n",
            "88/100 train loss:0.2905 train acc:70.26% val loss:0.3425 val acc:65.75%\n",
            "89/100 train loss:0.2902 train acc:70.29% val loss:0.3392 val acc:66.08%\n",
            "90/100 train loss:0.2866 train acc:70.64% val loss:0.3390 val acc:66.10%\n",
            "91/100 train loss:0.3093 train acc:68.34% val loss:0.3257 val acc:67.43%\n",
            "92/100 train loss:0.2923 train acc:70.09% val loss:0.3232 val acc:67.68%\n",
            "93/100 train loss:0.2931 train acc:69.99% val loss:0.3387 val acc:66.13%\n",
            "94/100 train loss:0.2909 train acc:70.21% val loss:0.3456 val acc:65.40%\n",
            "95/100 train loss:0.2834 train acc:70.98% val loss:0.3420 val acc:65.80%\n",
            "96/100 train loss:0.2823 train acc:71.09% val loss:0.3431 val acc:65.69%\n",
            "97/100 train loss:0.2799 train acc:71.32% val loss:0.3545 val acc:64.55%\n",
            "98/100 train loss:0.2785 train acc:71.47% val loss:0.3449 val acc:65.51%\n",
            "99/100 train loss:0.2772 train acc:71.59% val loss:0.3518 val acc:64.82%\n",
            "100/100 train loss:0.2788 train acc:71.37% val loss:0.3381 val acc:66.19%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-4\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        ['container mass']\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                      ['container mass']\n",
        "                       \n",
        "                      )\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-mass{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nEdFbrOkMnd"
      },
      "source": [
        "## height"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hkzm8FO9kPDI",
        "outputId": "9b161049-bee6-4212-d72d-6526797824b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5241 train acc:34.56% val loss:0.6423 val acc:14.70%\n",
            "2/100 train loss:0.3415 train acc:58.34% val loss:0.7800 val acc:0.76%\n",
            "3/100 train loss:0.2358 train acc:74.05% val loss:0.2700 val acc:72.25%\n",
            "4/100 train loss:0.1861 train acc:80.48% val loss:0.1998 val acc:80.02%\n",
            "5/100 train loss:0.1459 train acc:84.69% val loss:0.2061 val acc:79.39%\n",
            "6/100 train loss:0.1383 train acc:85.53% val loss:0.1615 val acc:83.85%\n",
            "7/100 train loss:0.1295 train acc:86.39% val loss:0.1569 val acc:84.31%\n",
            "8/100 train loss:0.1238 train acc:86.97% val loss:0.2292 val acc:77.08%\n",
            "9/100 train loss:0.1379 train acc:85.56% val loss:0.1402 val acc:85.98%\n",
            "10/100 train loss:0.1278 train acc:86.59% val loss:0.1362 val acc:86.38%\n",
            "11/100 train loss:0.1339 train acc:85.93% val loss:0.2093 val acc:78.79%\n",
            "12/100 train loss:0.1228 train acc:87.07% val loss:0.1471 val acc:85.29%\n",
            "13/100 train loss:0.1266 train acc:86.69% val loss:0.1381 val acc:86.19%\n",
            "14/100 train loss:0.1209 train acc:87.27% val loss:0.1244 val acc:87.56%\n",
            "15/100 train loss:0.1201 train acc:87.35% val loss:0.1354 val acc:86.46%\n",
            "16/100 train loss:0.1136 train acc:88.01% val loss:0.1188 val acc:88.12%\n",
            "17/100 train loss:0.1178 train acc:87.58% val loss:0.2634 val acc:73.66%\n",
            "18/100 train loss:0.1211 train acc:87.25% val loss:0.1261 val acc:87.39%\n",
            "19/100 train loss:0.1176 train acc:87.59% val loss:0.3015 val acc:69.85%\n",
            "20/100 train loss:0.1548 train acc:83.83% val loss:0.3131 val acc:68.69%\n",
            "21/100 train loss:0.1346 train acc:85.89% val loss:0.2235 val acc:77.65%\n",
            "22/100 train loss:0.1270 train acc:86.66% val loss:0.1492 val acc:85.08%\n",
            "23/100 train loss:0.1245 train acc:86.89% val loss:0.1352 val acc:86.48%\n",
            "24/100 train loss:0.1200 train acc:87.35% val loss:0.1427 val acc:85.73%\n",
            "25/100 train loss:0.1157 train acc:87.77% val loss:0.2118 val acc:78.82%\n",
            "26/100 train loss:0.1143 train acc:87.92% val loss:0.1445 val acc:85.55%\n",
            "27/100 train loss:0.1089 train acc:88.47% val loss:0.1456 val acc:85.36%\n",
            "28/100 train loss:0.1049 train acc:88.88% val loss:0.1193 val acc:88.07%\n",
            "29/100 train loss:0.1035 train acc:89.01% val loss:0.1186 val acc:88.00%\n",
            "30/100 train loss:0.1054 train acc:88.81% val loss:0.1440 val acc:85.33%\n",
            "31/100 train loss:0.1070 train acc:88.67% val loss:0.1440 val acc:85.60%\n",
            "32/100 train loss:0.1358 train acc:85.74% val loss:0.1711 val acc:82.70%\n",
            "33/100 train loss:0.1350 train acc:85.86% val loss:0.1409 val acc:85.91%\n",
            "34/100 train loss:0.1254 train acc:86.80% val loss:0.1227 val acc:87.73%\n",
            "35/100 train loss:0.1196 train acc:87.39% val loss:0.1438 val acc:85.17%\n",
            "36/100 train loss:0.1191 train acc:87.43% val loss:0.1303 val acc:86.97%\n",
            "37/100 train loss:0.1153 train acc:87.83% val loss:0.1279 val acc:87.21%\n",
            "38/100 train loss:0.1195 train acc:87.41% val loss:0.1378 val acc:86.15%\n",
            "39/100 train loss:0.1303 train acc:86.27% val loss:0.1314 val acc:86.86%\n",
            "40/100 train loss:0.1361 train acc:85.75% val loss:0.1690 val acc:82.92%\n",
            "41/100 train loss:0.1243 train acc:86.92% val loss:0.1464 val acc:85.19%\n",
            "42/100 train loss:0.1236 train acc:86.99% val loss:0.1392 val acc:86.08%\n",
            "43/100 train loss:0.1184 train acc:87.52% val loss:0.1453 val acc:85.47%\n",
            "44/100 train loss:0.1157 train acc:87.79% val loss:0.1671 val acc:83.29%\n",
            "45/100 train loss:0.1173 train acc:87.63% val loss:0.1390 val acc:86.10%\n",
            "46/100 train loss:0.1124 train acc:88.13% val loss:0.1494 val acc:85.06%\n",
            "47/100 train loss:0.1107 train acc:88.28% val loss:0.1522 val acc:84.78%\n",
            "48/100 train loss:0.1399 train acc:85.29% val loss:0.6164 val acc:38.14%\n",
            "49/100 train loss:0.1423 train acc:85.09% val loss:0.1362 val acc:86.38%\n",
            "50/100 train loss:0.1316 train acc:86.12% val loss:0.1478 val acc:85.22%\n",
            "51/100 train loss:0.1208 train acc:87.26% val loss:0.1339 val acc:86.61%\n",
            "52/100 train loss:0.1177 train acc:87.56% val loss:0.1248 val acc:87.52%\n",
            "53/100 train loss:0.1155 train acc:87.78% val loss:0.2297 val acc:77.03%\n",
            "54/100 train loss:0.1177 train acc:87.55% val loss:0.1887 val acc:81.13%\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-7e81e694cd58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m#start_time = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m   \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m   \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;31m#elapsed_time = time.time() - start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-ca1b4bac615a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mnum_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        ['height']\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                      ['height']\n",
        "                       \n",
        "                      )\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-height{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXoG_PAxwUDt"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xytYsQDyuV7I"
      },
      "source": [
        "## Width top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnNrMyZCuYNs",
        "outputId": "845dc971-1953-430d-eb05-cedfa0e24f96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5314 train acc:39.50% val loss:0.6005 val acc:23.41%\n",
            "2/100 train loss:0.2665 train acc:69.09% val loss:0.6406 val acc:34.77%\n",
            "3/100 train loss:0.1906 train acc:79.53% val loss:0.5340 val acc:44.57%\n",
            "4/100 train loss:0.1843 train acc:80.41% val loss:0.2215 val acc:77.22%\n",
            "5/100 train loss:0.1499 train acc:84.31% val loss:0.3014 val acc:69.86%\n",
            "6/100 train loss:0.1405 train acc:85.28% val loss:0.1717 val acc:82.83%\n",
            "7/100 train loss:0.1491 train acc:84.38% val loss:0.5779 val acc:42.21%\n",
            "8/100 train loss:0.1401 train acc:85.34% val loss:0.1335 val acc:86.65%\n",
            "9/100 train loss:0.1587 train acc:83.36% val loss:0.1406 val acc:85.94%\n",
            "10/100 train loss:0.1332 train acc:86.04% val loss:0.1495 val acc:85.05%\n",
            "11/100 train loss:0.1254 train acc:86.82% val loss:0.1280 val acc:87.20%\n",
            "12/100 train loss:0.1159 train acc:87.76% val loss:0.1435 val acc:85.65%\n",
            "13/100 train loss:0.1275 train acc:86.57% val loss:0.3790 val acc:62.10%\n",
            "14/100 train loss:0.1245 train acc:86.88% val loss:0.1282 val acc:87.18%\n",
            "15/100 train loss:0.1138 train acc:87.98% val loss:0.1412 val acc:85.88%\n",
            "16/100 train loss:0.1078 train acc:88.56% val loss:0.1372 val acc:86.28%\n",
            "17/100 train loss:0.1202 train acc:87.22% val loss:0.1621 val acc:83.79%\n",
            "18/100 train loss:0.1187 train acc:87.47% val loss:0.2359 val acc:75.97%\n",
            "19/100 train loss:0.1112 train acc:88.21% val loss:0.1293 val acc:86.84%\n",
            "20/100 train loss:0.1133 train acc:87.99% val loss:0.2723 val acc:71.22%\n",
            "21/100 train loss:0.1261 train acc:86.65% val loss:0.1262 val acc:87.38%\n",
            "22/100 train loss:0.1058 train acc:88.78% val loss:0.1322 val acc:86.78%\n",
            "23/100 train loss:0.1132 train acc:88.03% val loss:0.3227 val acc:66.47%\n",
            "24/100 train loss:0.1075 train acc:88.61% val loss:0.1343 val acc:86.57%\n",
            "25/100 train loss:0.0969 train acc:89.67% val loss:0.1684 val acc:82.99%\n",
            "26/100 train loss:0.0970 train acc:89.66% val loss:0.1599 val acc:83.85%\n",
            "27/100 train loss:0.1031 train acc:89.03% val loss:0.1458 val acc:85.42%\n",
            "28/100 train loss:0.1131 train acc:88.03% val loss:0.1513 val acc:84.87%\n",
            "29/100 train loss:0.1014 train acc:89.23% val loss:0.1291 val acc:86.89%\n",
            "30/100 train loss:0.1340 train acc:85.80% val loss:0.4019 val acc:56.89%\n",
            "31/100 train loss:0.1361 train acc:85.55% val loss:0.1337 val acc:86.63%\n",
            "32/100 train loss:0.1084 train acc:88.51% val loss:0.1286 val acc:86.86%\n",
            "33/100 train loss:0.1021 train acc:89.11% val loss:0.1194 val acc:88.06%\n",
            "34/100 train loss:0.1054 train acc:88.81% val loss:0.1329 val acc:86.71%\n",
            "35/100 train loss:0.0998 train acc:89.38% val loss:0.1228 val acc:87.72%\n",
            "36/100 train loss:0.1363 train acc:85.60% val loss:0.1738 val acc:82.62%\n",
            "37/100 train loss:0.1503 train acc:84.18% val loss:0.1562 val acc:84.38%\n",
            "38/100 train loss:0.1328 train acc:85.96% val loss:0.1898 val acc:80.61%\n",
            "39/100 train loss:0.1105 train acc:88.28% val loss:0.1690 val acc:82.68%\n",
            "40/100 train loss:0.1147 train acc:87.84% val loss:0.1493 val acc:85.07%\n",
            "41/100 train loss:0.1163 train acc:87.68% val loss:0.1567 val acc:84.33%\n",
            "42/100 train loss:0.1211 train acc:87.23% val loss:0.1283 val acc:87.17%\n",
            "43/100 train loss:0.1085 train acc:88.51% val loss:0.1348 val acc:86.52%\n",
            "44/100 train loss:0.1061 train acc:88.76% val loss:0.1325 val acc:86.75%\n",
            "45/100 train loss:0.1011 train acc:89.24% val loss:0.1213 val acc:87.87%\n",
            "46/100 train loss:0.0955 train acc:89.81% val loss:0.1253 val acc:87.47%\n",
            "47/100 train loss:0.0974 train acc:89.61% val loss:0.1312 val acc:86.88%\n",
            "48/100 train loss:0.0924 train acc:90.12% val loss:0.1418 val acc:85.13%\n",
            "49/100 train loss:0.0944 train acc:89.90% val loss:0.1188 val acc:88.12%\n",
            "50/100 train loss:0.0912 train acc:90.24% val loss:0.1297 val acc:87.03%\n",
            "51/100 train loss:0.0999 train acc:89.31% val loss:0.1122 val acc:88.78%\n",
            "52/100 train loss:0.1022 train acc:89.11% val loss:0.1342 val acc:86.58%\n",
            "53/100 train loss:0.1088 train acc:88.41% val loss:0.1725 val acc:82.40%\n",
            "54/100 train loss:0.1020 train acc:89.08% val loss:0.1380 val acc:86.20%\n",
            "55/100 train loss:0.0987 train acc:89.46% val loss:0.1606 val acc:83.94%\n",
            "56/100 train loss:0.0939 train acc:89.95% val loss:0.1345 val acc:86.55%\n",
            "57/100 train loss:0.1090 train acc:88.38% val loss:0.1417 val acc:85.83%\n",
            "58/100 train loss:0.1019 train acc:89.13% val loss:0.1222 val acc:87.51%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        ['width at the top']\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                      ['width at the top']\n",
        "                       \n",
        "                      )\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-wt{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkq1JglY8nRh"
      },
      "source": [
        "## Width bottom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ext8gXOE8j_m",
        "outputId": "62930783-738b-4a6e-bc18-6457a5a5d115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.4981 train acc:40.20% val loss:0.3756 val acc:55.33%\n",
            "2/100 train loss:0.2650 train acc:69.72% val loss:0.2494 val acc:73.34%\n",
            "3/100 train loss:0.2077 train acc:77.56% val loss:0.8076 val acc:1.79%\n",
            "4/100 train loss:0.1845 train acc:80.56% val loss:0.6332 val acc:34.38%\n",
            "5/100 train loss:0.1622 train acc:82.80% val loss:0.1551 val acc:84.49%\n",
            "6/100 train loss:0.1621 train acc:82.82% val loss:0.1393 val acc:85.95%\n",
            "7/100 train loss:0.1503 train acc:83.98% val loss:0.3631 val acc:61.43%\n",
            "8/100 train loss:0.1444 train acc:84.65% val loss:0.1260 val acc:87.15%\n",
            "9/100 train loss:0.1362 train acc:85.55% val loss:0.1376 val acc:86.24%\n",
            "10/100 train loss:0.1363 train acc:85.52% val loss:0.1353 val acc:86.47%\n",
            "11/100 train loss:0.1459 train acc:84.48% val loss:0.1963 val acc:80.37%\n",
            "12/100 train loss:0.1396 train acc:85.22% val loss:0.1243 val acc:87.30%\n",
            "13/100 train loss:0.1306 train acc:86.06% val loss:0.1328 val acc:86.59%\n",
            "14/100 train loss:0.1272 train acc:86.48% val loss:0.2046 val acc:77.95%\n",
            "15/100 train loss:0.1392 train acc:85.08% val loss:0.1315 val acc:86.85%\n",
            "16/100 train loss:0.1268 train acc:86.58% val loss:0.1172 val acc:88.28%\n",
            "17/100 train loss:0.1327 train acc:85.89% val loss:0.1627 val acc:83.44%\n",
            "18/100 train loss:0.1359 train acc:85.55% val loss:0.1752 val acc:81.43%\n",
            "19/100 train loss:0.1294 train acc:86.21% val loss:0.1632 val acc:83.68%\n",
            "20/100 train loss:0.1310 train acc:86.11% val loss:0.1362 val acc:84.22%\n",
            "21/100 train loss:0.1352 train acc:85.59% val loss:0.1211 val acc:87.89%\n",
            "22/100 train loss:0.1354 train acc:85.55% val loss:0.1589 val acc:84.11%\n",
            "23/100 train loss:0.1406 train acc:85.00% val loss:0.2322 val acc:76.78%\n",
            "24/100 train loss:0.1310 train acc:86.04% val loss:0.1540 val acc:84.60%\n",
            "25/100 train loss:0.1447 train acc:84.62% val loss:0.6835 val acc:13.30%\n",
            "26/100 train loss:0.1445 train acc:84.55% val loss:0.6294 val acc:37.06%\n",
            "27/100 train loss:0.1317 train acc:85.91% val loss:0.7050 val acc:15.54%\n",
            "28/100 train loss:0.1319 train acc:85.86% val loss:0.5432 val acc:43.67%\n",
            "29/100 train loss:0.1248 train acc:86.67% val loss:0.1651 val acc:83.49%\n",
            "30/100 train loss:0.1348 train acc:85.42% val loss:0.3342 val acc:66.02%\n",
            "31/100 train loss:0.1361 train acc:85.35% val loss:0.1875 val acc:81.25%\n",
            "32/100 train loss:0.1256 train acc:86.63% val loss:0.6280 val acc:37.20%\n",
            "33/100 train loss:0.1295 train acc:86.18% val loss:0.1229 val acc:87.32%\n",
            "34/100 train loss:0.1229 train acc:86.93% val loss:0.1565 val acc:83.92%\n",
            "35/100 train loss:0.1237 train acc:86.85% val loss:0.1237 val acc:87.63%\n",
            "36/100 train loss:0.1287 train acc:86.25% val loss:0.1559 val acc:83.35%\n",
            "37/100 train loss:0.1276 train acc:86.42% val loss:0.1565 val acc:84.35%\n",
            "38/100 train loss:0.1256 train acc:86.31% val loss:0.1143 val acc:88.57%\n",
            "39/100 train loss:0.1243 train acc:86.64% val loss:0.1381 val acc:86.19%\n",
            "40/100 train loss:0.1218 train acc:86.95% val loss:0.1229 val acc:87.50%\n",
            "41/100 train loss:0.1167 train acc:87.43% val loss:0.1374 val acc:85.46%\n",
            "42/100 train loss:0.1143 train acc:87.68% val loss:0.1345 val acc:86.11%\n",
            "43/100 train loss:0.1162 train acc:87.57% val loss:0.2172 val acc:74.91%\n",
            "44/100 train loss:0.1158 train acc:87.71% val loss:0.1540 val acc:84.39%\n",
            "45/100 train loss:0.1150 train acc:87.73% val loss:0.1286 val acc:87.14%\n",
            "46/100 train loss:0.1203 train acc:87.14% val loss:0.1126 val acc:88.74%\n",
            "47/100 train loss:0.1124 train acc:87.94% val loss:0.1566 val acc:83.24%\n",
            "48/100 train loss:0.1186 train acc:87.30% val loss:0.1392 val acc:85.83%\n",
            "49/100 train loss:0.1137 train acc:87.86% val loss:0.1494 val acc:85.06%\n",
            "50/100 train loss:0.1206 train acc:86.88% val loss:0.1878 val acc:81.22%\n",
            "51/100 train loss:0.1171 train acc:87.38% val loss:0.1438 val acc:84.97%\n",
            "52/100 train loss:0.1099 train acc:88.15% val loss:0.1315 val acc:86.85%\n",
            "53/100 train loss:0.1126 train acc:87.91% val loss:0.1739 val acc:82.14%\n",
            "54/100 train loss:0.1282 train acc:86.00% val loss:0.1264 val acc:87.36%\n",
            "55/100 train loss:0.1322 train acc:85.64% val loss:0.1625 val acc:83.75%\n",
            "56/100 train loss:0.1494 train acc:83.99% val loss:0.1423 val acc:85.77%\n",
            "57/100 train loss:0.1332 train acc:85.93% val loss:0.3976 val acc:56.28%\n",
            "58/100 train loss:0.1243 train acc:86.86% val loss:0.1976 val acc:80.24%\n",
            "59/100 train loss:0.1724 train acc:81.86% val loss:0.2362 val acc:75.91%\n",
            "60/100 train loss:0.1521 train acc:84.05% val loss:0.2994 val acc:68.97%\n",
            "61/100 train loss:0.1811 train acc:80.91% val loss:0.5832 val acc:41.31%\n",
            "62/100 train loss:0.1548 train acc:83.73% val loss:0.1563 val acc:83.98%\n",
            "63/100 train loss:0.1341 train acc:85.92% val loss:0.1256 val acc:87.44%\n",
            "64/100 train loss:0.1216 train acc:87.17% val loss:0.1696 val acc:83.04%\n",
            "65/100 train loss:0.1315 train acc:86.20% val loss:0.1204 val acc:87.96%\n",
            "66/100 train loss:0.1168 train acc:87.67% val loss:0.1139 val acc:88.61%\n",
            "67/100 train loss:0.1141 train acc:87.94% val loss:0.1132 val acc:88.68%\n",
            "68/100 train loss:0.1315 train acc:86.14% val loss:0.2196 val acc:77.57%\n",
            "69/100 train loss:0.1296 train acc:86.32% val loss:0.4459 val acc:54.62%\n",
            "70/100 train loss:0.1201 train acc:87.33% val loss:0.1396 val acc:85.85%\n",
            "71/100 train loss:0.1243 train acc:86.91% val loss:0.4837 val acc:50.76%\n",
            "72/100 train loss:0.1250 train acc:86.83% val loss:0.1410 val acc:85.90%\n",
            "73/100 train loss:0.1127 train acc:88.07% val loss:0.1330 val acc:86.70%\n",
            "74/100 train loss:0.1112 train acc:88.22% val loss:0.1270 val acc:87.30%\n",
            "75/100 train loss:0.1094 train acc:88.42% val loss:0.1289 val acc:87.01%\n",
            "76/100 train loss:0.1044 train acc:88.92% val loss:0.1183 val acc:88.17%\n",
            "77/100 train loss:0.1053 train acc:88.83% val loss:0.1064 val acc:89.36%\n",
            "78/100 train loss:0.1066 train acc:88.70% val loss:0.1175 val acc:88.25%\n",
            "79/100 train loss:0.0988 train acc:89.48% val loss:0.1192 val acc:88.08%\n",
            "80/100 train loss:0.1036 train acc:88.98% val loss:0.1255 val acc:87.45%\n",
            "81/100 train loss:0.0981 train acc:89.55% val loss:0.1194 val acc:88.06%\n",
            "82/100 train loss:0.0979 train acc:89.57% val loss:0.1257 val acc:87.35%\n",
            "83/100 train loss:0.0959 train acc:89.77% val loss:0.1095 val acc:89.05%\n",
            "84/100 train loss:0.0954 train acc:89.83% val loss:0.1280 val acc:87.20%\n",
            "85/100 train loss:0.0992 train acc:89.42% val loss:0.1392 val acc:86.08%\n",
            "86/100 train loss:0.1171 train acc:87.55% val loss:0.1314 val acc:86.60%\n",
            "87/100 train loss:0.1047 train acc:88.86% val loss:0.1129 val acc:88.71%\n",
            "88/100 train loss:0.1042 train acc:88.90% val loss:0.1233 val acc:87.35%\n",
            "89/100 train loss:0.1020 train acc:89.12% val loss:0.1079 val acc:89.21%\n",
            "90/100 train loss:0.0971 train acc:89.63% val loss:0.1083 val acc:89.17%\n",
            "91/100 train loss:0.1007 train acc:89.24% val loss:0.1148 val acc:88.52%\n",
            "92/100 train loss:0.1051 train acc:88.84% val loss:0.1005 val acc:89.95%\n",
            "93/100 train loss:0.1104 train acc:88.27% val loss:0.1218 val acc:87.73%\n",
            "94/100 train loss:0.1228 train acc:86.90% val loss:0.1530 val acc:84.70%\n",
            "95/100 train loss:0.1125 train acc:88.03% val loss:0.1242 val acc:87.58%\n",
            "96/100 train loss:0.1084 train acc:88.48% val loss:0.1205 val acc:87.95%\n",
            "97/100 train loss:0.1239 train acc:86.83% val loss:0.1313 val acc:86.87%\n",
            "98/100 train loss:0.1114 train acc:88.14% val loss:0.1260 val acc:87.40%\n",
            "99/100 train loss:0.1033 train acc:89.01% val loss:0.1099 val acc:88.89%\n",
            "100/100 train loss:0.1052 train acc:88.77% val loss:0.2345 val acc:76.55%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        ['width at the bottom']\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                      ['width at the bottom']\n",
        "                       \n",
        "                      )\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-wb{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer"
      ],
      "metadata": {
        "id": "JWvyZzfyDEwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb')\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                        '/content/test/labels', \n",
        "                        '/content/test/crops_depth',\n",
        "                        '/content/test/crops_rgb')\n",
        "model = MobileNetV3_Large(num_classes=1)\n",
        "pretrain = '/content/drive/MyDrive/COSRMAL_CHALLENGE/audios/RGBD/mobile-wt88.78.pth'\n",
        "model.load_state_dict(torch.load(pretrain))\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ],
      "metadata": {
        "id": "LhT4LV8BDGNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53bfa135-315a-4474-cb79-bf3a49259db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.3746 train acc:57.25% val loss:0.3028 val acc:68.45%\n",
            "2/100 train loss:0.2891 train acc:67.07% val loss:0.2930 val acc:70.70%\n",
            "3/100 train loss:0.2518 train acc:72.43% val loss:0.5375 val acc:41.42%\n",
            "4/100 train loss:0.2243 train acc:75.84% val loss:0.4622 val acc:53.36%\n",
            "5/100 train loss:0.2000 train acc:79.29% val loss:0.2390 val acc:76.10%\n",
            "6/100 train loss:0.1855 train acc:80.82% val loss:0.3805 val acc:61.11%\n",
            "7/100 train loss:0.1857 train acc:80.79% val loss:0.2686 val acc:73.14%\n",
            "8/100 train loss:0.1731 train acc:82.03% val loss:0.2466 val acc:75.34%\n",
            "9/100 train loss:0.1703 train acc:82.31% val loss:0.2486 val acc:75.14%\n",
            "10/100 train loss:0.1826 train acc:81.02% val loss:0.3201 val acc:67.99%\n",
            "11/100 train loss:0.1669 train acc:82.62% val loss:0.2178 val acc:78.22%\n",
            "12/100 train loss:0.1493 train acc:84.40% val loss:0.2141 val acc:78.34%\n",
            "13/100 train loss:0.1418 train acc:85.17% val loss:0.2774 val acc:72.26%\n",
            "14/100 train loss:0.1373 train acc:85.62% val loss:0.1745 val acc:82.55%\n",
            "15/100 train loss:0.1347 train acc:85.89% val loss:0.1759 val acc:82.41%\n",
            "16/100 train loss:0.1250 train acc:86.86% val loss:0.1758 val acc:82.42%\n",
            "17/100 train loss:0.1367 train acc:85.63% val loss:0.1946 val acc:80.54%\n",
            "18/100 train loss:0.1351 train acc:85.81% val loss:0.1841 val acc:81.59%\n",
            "19/100 train loss:0.1669 train acc:82.47% val loss:0.2173 val acc:78.27%\n",
            "20/100 train loss:0.1462 train acc:84.70% val loss:0.1907 val acc:80.93%\n",
            "21/100 train loss:0.1404 train acc:85.32% val loss:0.2368 val acc:76.32%\n",
            "22/100 train loss:0.1292 train acc:86.43% val loss:0.1759 val acc:82.41%\n",
            "23/100 train loss:0.1347 train acc:85.87% val loss:0.2115 val acc:78.69%\n",
            "24/100 train loss:0.1400 train acc:85.34% val loss:0.4032 val acc:59.68%\n",
            "25/100 train loss:0.1584 train acc:83.48% val loss:0.3096 val acc:69.04%\n",
            "26/100 train loss:0.1356 train acc:85.79% val loss:0.9540 val acc:4.60%\n",
            "27/100 train loss:0.1499 train acc:84.37% val loss:0.1767 val acc:82.33%\n",
            "28/100 train loss:0.1327 train acc:86.08% val loss:0.1661 val acc:83.39%\n",
            "29/100 train loss:0.1303 train acc:86.33% val loss:0.1596 val acc:83.82%\n",
            "30/100 train loss:0.1317 train acc:86.18% val loss:0.2065 val acc:79.35%\n",
            "31/100 train loss:0.1403 train acc:85.29% val loss:0.3059 val acc:69.41%\n",
            "32/100 train loss:0.1364 train acc:85.70% val loss:0.1844 val acc:81.12%\n",
            "33/100 train loss:0.1385 train acc:85.49% val loss:0.1873 val acc:81.27%\n",
            "34/100 train loss:0.1287 train acc:86.49% val loss:0.1694 val acc:83.06%\n",
            "35/100 train loss:0.1218 train acc:87.18% val loss:0.3677 val acc:63.23%\n",
            "36/100 train loss:0.1433 train acc:84.98% val loss:0.1463 val acc:85.37%\n",
            "37/100 train loss:0.1300 train acc:86.35% val loss:0.2236 val acc:77.64%\n",
            "38/100 train loss:0.1448 train acc:84.86% val loss:0.2030 val acc:79.70%\n",
            "39/100 train loss:0.1310 train acc:86.27% val loss:0.1863 val acc:81.37%\n",
            "40/100 train loss:0.1300 train acc:86.36% val loss:0.2112 val acc:78.88%\n",
            "41/100 train loss:0.1340 train acc:85.95% val loss:0.1748 val acc:82.52%\n",
            "42/100 train loss:0.1373 train acc:85.63% val loss:0.3486 val acc:65.14%\n",
            "43/100 train loss:0.1411 train acc:85.21% val loss:0.1590 val acc:84.10%\n",
            "44/100 train loss:0.1280 train acc:86.54% val loss:0.1849 val acc:81.51%\n",
            "45/100 train loss:0.1195 train acc:87.41% val loss:0.1460 val acc:85.40%\n",
            "46/100 train loss:0.1230 train acc:87.03% val loss:0.2895 val acc:71.05%\n",
            "47/100 train loss:0.1249 train acc:86.88% val loss:0.1461 val acc:85.39%\n",
            "48/100 train loss:0.1291 train acc:86.44% val loss:0.1956 val acc:80.44%\n",
            "49/100 train loss:0.1294 train acc:86.43% val loss:0.1640 val acc:83.60%\n",
            "50/100 train loss:0.1245 train acc:86.92% val loss:0.1554 val acc:84.46%\n",
            "51/100 train loss:0.1223 train acc:87.13% val loss:0.9799 val acc:2.01%\n",
            "52/100 train loss:0.1230 train acc:87.04% val loss:0.1692 val acc:83.08%\n",
            "53/100 train loss:0.1255 train acc:86.80% val loss:0.1918 val acc:80.82%\n",
            "54/100 train loss:0.1263 train acc:86.74% val loss:0.1606 val acc:83.94%\n",
            "55/100 train loss:0.1223 train acc:87.13% val loss:0.1611 val acc:83.89%\n",
            "56/100 train loss:0.1174 train acc:87.62% val loss:0.1517 val acc:84.83%\n",
            "57/100 train loss:0.1181 train acc:87.55% val loss:0.1618 val acc:83.82%\n",
            "58/100 train loss:0.1166 train acc:87.70% val loss:0.9663 val acc:3.37%\n",
            "59/100 train loss:0.1165 train acc:87.72% val loss:1.0000 val acc:0.00%\n",
            "60/100 train loss:0.1165 train acc:87.71% val loss:0.1878 val acc:81.22%\n",
            "61/100 train loss:0.1122 train acc:88.14% val loss:0.1930 val acc:80.70%\n",
            "62/100 train loss:0.1129 train acc:88.06% val loss:0.1784 val acc:82.16%\n",
            "63/100 train loss:0.1110 train acc:88.25% val loss:0.2866 val acc:71.34%\n",
            "64/100 train loss:0.1076 train acc:88.58% val loss:0.2465 val acc:75.35%\n",
            "65/100 train loss:0.1090 train acc:88.47% val loss:0.1620 val acc:83.80%\n",
            "66/100 train loss:0.1093 train acc:88.43% val loss:0.2970 val acc:70.30%\n",
            "67/100 train loss:0.1020 train acc:89.16% val loss:0.1807 val acc:81.80%\n",
            "68/100 train loss:0.0972 train acc:89.64% val loss:0.1855 val acc:81.45%\n",
            "69/100 train loss:0.0982 train acc:89.54% val loss:0.1555 val acc:84.45%\n",
            "70/100 train loss:0.1063 train acc:88.74% val loss:0.1683 val acc:83.17%\n",
            "71/100 train loss:0.1120 train acc:88.16% val loss:0.1663 val acc:83.37%\n",
            "72/100 train loss:0.1122 train acc:88.14% val loss:0.2364 val acc:76.36%\n",
            "73/100 train loss:0.1426 train acc:85.09% val loss:0.3598 val acc:64.02%\n",
            "74/100 train loss:0.1618 train acc:83.15% val loss:0.2017 val acc:79.83%\n",
            "75/100 train loss:0.1455 train acc:84.82% val loss:0.1715 val acc:82.56%\n",
            "76/100 train loss:0.1325 train acc:86.10% val loss:0.2077 val acc:79.23%\n",
            "77/100 train loss:0.1291 train acc:86.46% val loss:0.1949 val acc:80.51%\n",
            "78/100 train loss:0.1284 train acc:86.53% val loss:0.1663 val acc:83.37%\n",
            "79/100 train loss:0.1287 train acc:86.49% val loss:0.1602 val acc:83.98%\n",
            "80/100 train loss:0.1308 train acc:86.29% val loss:0.1658 val acc:83.42%\n",
            "81/100 train loss:0.1219 train acc:87.17% val loss:0.1675 val acc:83.25%\n",
            "82/100 train loss:0.1203 train acc:87.34% val loss:0.1475 val acc:85.25%\n",
            "83/100 train loss:0.1359 train acc:85.74% val loss:0.1603 val acc:83.97%\n",
            "84/100 train loss:0.1243 train acc:86.94% val loss:0.1520 val acc:84.80%\n",
            "85/100 train loss:0.1207 train acc:87.29% val loss:0.1536 val acc:84.19%\n",
            "86/100 train loss:0.1313 train acc:86.12% val loss:0.1694 val acc:83.06%\n",
            "87/100 train loss:0.1430 train acc:84.92% val loss:0.1827 val acc:81.73%\n",
            "88/100 train loss:0.1416 train acc:85.20% val loss:0.1586 val acc:84.14%\n",
            "89/100 train loss:0.1240 train acc:86.96% val loss:0.1517 val acc:84.83%\n",
            "90/100 train loss:0.1197 train acc:87.40% val loss:0.1615 val acc:83.85%\n",
            "91/100 train loss:0.1230 train acc:87.06% val loss:0.1519 val acc:84.81%\n",
            "92/100 train loss:0.1144 train acc:87.93% val loss:0.1434 val acc:85.66%\n",
            "93/100 train loss:0.1130 train acc:88.06% val loss:0.1550 val acc:84.50%\n",
            "94/100 train loss:0.1096 train acc:88.41% val loss:0.1555 val acc:84.45%\n",
            "95/100 train loss:0.1204 train acc:87.32% val loss:0.2165 val acc:78.35%\n",
            "96/100 train loss:0.1329 train acc:86.07% val loss:0.1952 val acc:80.24%\n",
            "97/100 train loss:0.1235 train acc:86.96% val loss:0.1524 val acc:84.76%\n",
            "98/100 train loss:0.1134 train acc:88.02% val loss:0.1394 val acc:86.06%\n",
            "99/100 train loss:0.1056 train acc:88.80% val loss:0.1385 val acc:86.15%\n",
            "100/100 train loss:0.1076 train acc:88.61% val loss:0.1366 val acc:86.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-4\n",
        "epochs = 200\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        ['container mass']\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                      ['container mass']          \n",
        "                      )\n",
        "model = MobileNetV3_Large(num_classes=1)\n",
        "pretrain = '/content/drive/MyDrive/COSRMAL_CHALLENGE/audios/RGBD/mobile-wt88.78.pth'\n",
        "model.load_state_dict(torch.load(pretrain))\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-mass{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57TzJw_TNFm-",
        "outputId": "df2a1b24-aa49-4ae1-8044-bdbd831f5cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "1/200 train loss:0.7068 train acc:28.62% val loss:0.6739 val acc:32.33%\n",
            "2/200 train loss:0.6874 train acc:30.53% val loss:0.6544 val acc:34.56%\n",
            "3/200 train loss:0.6820 train acc:31.10% val loss:0.6364 val acc:36.36%\n",
            "4/200 train loss:0.6744 train acc:31.85% val loss:0.6362 val acc:36.38%\n",
            "5/200 train loss:0.6648 train acc:32.74% val loss:0.6391 val acc:35.65%\n",
            "6/200 train loss:0.6571 train acc:33.54% val loss:0.6412 val acc:35.59%\n",
            "7/200 train loss:0.6421 train acc:35.06% val loss:0.6135 val acc:38.65%\n",
            "8/200 train loss:0.6359 train acc:35.60% val loss:0.6261 val acc:37.39%\n",
            "9/200 train loss:0.6373 train acc:35.43% val loss:0.5957 val acc:40.43%\n",
            "10/200 train loss:0.6311 train acc:36.15% val loss:0.6008 val acc:39.92%\n",
            "11/200 train loss:0.6232 train acc:36.84% val loss:0.5813 val acc:41.61%\n",
            "12/200 train loss:0.6133 train acc:37.92% val loss:0.5554 val acc:44.22%\n",
            "13/200 train loss:0.6044 train acc:38.81% val loss:0.5662 val acc:43.38%\n",
            "14/200 train loss:0.5993 train acc:39.37% val loss:0.5565 val acc:44.35%\n",
            "15/200 train loss:0.5899 train acc:40.26% val loss:0.5218 val acc:47.82%\n",
            "16/200 train loss:0.5834 train acc:40.99% val loss:0.4947 val acc:50.53%\n",
            "17/200 train loss:0.5674 train acc:42.63% val loss:0.4837 val acc:51.42%\n",
            "18/200 train loss:0.5427 train acc:45.08% val loss:0.4796 val acc:52.04%\n",
            "19/200 train loss:0.5205 train acc:47.31% val loss:0.4698 val acc:52.74%\n",
            "20/200 train loss:0.5144 train acc:47.88% val loss:0.4527 val acc:54.73%\n",
            "21/200 train loss:0.4992 train acc:49.44% val loss:0.4560 val acc:54.40%\n",
            "22/200 train loss:0.4914 train acc:50.21% val loss:0.4572 val acc:54.28%\n",
            "23/200 train loss:0.4863 train acc:50.71% val loss:0.4410 val acc:55.90%\n",
            "24/200 train loss:0.4782 train acc:51.55% val loss:0.4336 val acc:56.64%\n",
            "25/200 train loss:0.4772 train acc:51.63% val loss:0.4365 val acc:56.35%\n",
            "26/200 train loss:0.4744 train acc:51.92% val loss:0.4387 val acc:56.13%\n",
            "27/200 train loss:0.4679 train acc:52.58% val loss:0.4323 val acc:56.77%\n",
            "28/200 train loss:0.4606 train acc:53.29% val loss:0.4305 val acc:56.95%\n",
            "29/200 train loss:0.4624 train acc:53.12% val loss:0.4322 val acc:56.78%\n",
            "30/200 train loss:0.4536 train acc:54.00% val loss:0.4380 val acc:56.20%\n",
            "31/200 train loss:0.4536 train acc:54.00% val loss:0.4280 val acc:57.20%\n",
            "32/200 train loss:0.4464 train acc:54.73% val loss:0.4231 val acc:57.69%\n",
            "33/200 train loss:0.4517 train acc:54.19% val loss:0.4376 val acc:56.24%\n",
            "34/200 train loss:0.4480 train acc:54.56% val loss:0.4303 val acc:56.97%\n",
            "35/200 train loss:0.4490 train acc:54.47% val loss:0.4291 val acc:57.09%\n",
            "36/200 train loss:0.4375 train acc:55.61% val loss:0.4116 val acc:58.84%\n",
            "37/200 train loss:0.4373 train acc:55.63% val loss:0.4084 val acc:59.16%\n",
            "38/200 train loss:0.4375 train acc:55.61% val loss:0.4150 val acc:58.50%\n",
            "39/200 train loss:0.4318 train acc:56.18% val loss:0.4162 val acc:58.38%\n",
            "40/200 train loss:0.4331 train acc:56.04% val loss:0.4057 val acc:59.43%\n",
            "41/200 train loss:0.4368 train acc:55.65% val loss:0.4092 val acc:59.08%\n",
            "42/200 train loss:0.4353 train acc:55.83% val loss:0.4211 val acc:57.89%\n",
            "43/200 train loss:0.4351 train acc:55.85% val loss:0.4229 val acc:57.71%\n",
            "44/200 train loss:0.4446 train acc:54.45% val loss:0.4512 val acc:53.47%\n",
            "45/200 train loss:0.4022 train acc:58.85% val loss:0.4252 val acc:57.34%\n",
            "46/200 train loss:0.3625 train acc:63.05% val loss:0.3847 val acc:61.53%\n",
            "47/200 train loss:0.3424 train acc:65.01% val loss:0.3540 val acc:64.60%\n",
            "48/200 train loss:0.3440 train acc:64.90% val loss:0.3335 val acc:66.65%\n",
            "49/200 train loss:0.3261 train acc:66.71% val loss:0.3435 val acc:65.65%\n",
            "50/200 train loss:0.3202 train acc:67.33% val loss:0.3530 val acc:64.70%\n",
            "51/200 train loss:0.3247 train acc:66.87% val loss:0.3407 val acc:65.93%\n",
            "52/200 train loss:0.3080 train acc:68.57% val loss:0.3278 val acc:67.22%\n",
            "53/200 train loss:0.3019 train acc:69.17% val loss:0.3274 val acc:67.26%\n",
            "54/200 train loss:0.3003 train acc:69.33% val loss:0.3242 val acc:67.58%\n",
            "55/200 train loss:0.2846 train acc:70.90% val loss:0.3060 val acc:69.40%\n",
            "56/200 train loss:0.2879 train acc:70.57% val loss:0.2837 val acc:71.63%\n",
            "57/200 train loss:0.2823 train acc:71.12% val loss:0.2888 val acc:71.12%\n",
            "58/200 train loss:0.2729 train acc:72.06% val loss:0.2914 val acc:70.86%\n",
            "59/200 train loss:0.2762 train acc:71.73% val loss:0.2952 val acc:70.48%\n",
            "60/200 train loss:0.2721 train acc:72.14% val loss:0.3024 val acc:69.76%\n",
            "61/200 train loss:0.2601 train acc:73.35% val loss:0.2816 val acc:71.84%\n",
            "62/200 train loss:0.2611 train acc:73.25% val loss:0.2851 val acc:71.49%\n",
            "63/200 train loss:0.2621 train acc:73.15% val loss:0.2650 val acc:73.50%\n",
            "64/200 train loss:0.2667 train acc:72.68% val loss:0.2785 val acc:72.15%\n",
            "65/200 train loss:0.2516 train acc:74.20% val loss:0.2932 val acc:70.68%\n",
            "66/200 train loss:0.2482 train acc:74.52% val loss:0.2820 val acc:71.80%\n",
            "67/200 train loss:0.2594 train acc:73.42% val loss:0.2809 val acc:71.91%\n",
            "68/200 train loss:0.2576 train acc:73.61% val loss:0.2761 val acc:72.39%\n",
            "69/200 train loss:0.2633 train acc:73.04% val loss:0.2848 val acc:71.52%\n",
            "70/200 train loss:0.2587 train acc:73.47% val loss:0.2838 val acc:71.62%\n",
            "71/200 train loss:0.2588 train acc:73.46% val loss:0.3077 val acc:69.23%\n",
            "72/200 train loss:0.2515 train acc:74.20% val loss:0.3003 val acc:69.97%\n",
            "73/200 train loss:0.2435 train acc:75.02% val loss:0.2931 val acc:70.69%\n",
            "74/200 train loss:0.2397 train acc:75.39% val loss:0.3104 val acc:68.96%\n",
            "75/200 train loss:0.2466 train acc:74.69% val loss:0.3144 val acc:68.56%\n",
            "76/200 train loss:0.2514 train acc:74.22% val loss:0.3136 val acc:68.64%\n",
            "77/200 train loss:0.2467 train acc:74.68% val loss:0.3208 val acc:67.92%\n",
            "78/200 train loss:0.2486 train acc:74.50% val loss:0.2985 val acc:70.15%\n",
            "79/200 train loss:0.2422 train acc:75.14% val loss:0.2905 val acc:70.52%\n",
            "80/200 train loss:0.2332 train acc:76.05% val loss:0.3145 val acc:68.55%\n",
            "81/200 train loss:0.2272 train acc:76.65% val loss:0.2981 val acc:70.19%\n",
            "82/200 train loss:0.2283 train acc:76.53% val loss:0.3072 val acc:69.28%\n",
            "83/200 train loss:0.2308 train acc:76.28% val loss:0.3023 val acc:69.77%\n",
            "84/200 train loss:0.2302 train acc:76.34% val loss:0.3061 val acc:69.39%\n",
            "85/200 train loss:0.2328 train acc:76.08% val loss:0.2891 val acc:71.09%\n",
            "86/200 train loss:0.2401 train acc:75.36% val loss:0.2932 val acc:70.68%\n",
            "87/200 train loss:0.2218 train acc:77.17% val loss:0.2884 val acc:71.16%\n",
            "88/200 train loss:0.2281 train acc:76.56% val loss:0.2941 val acc:70.59%\n",
            "89/200 train loss:0.2255 train acc:76.81% val loss:0.3036 val acc:69.64%\n",
            "90/200 train loss:0.2223 train acc:77.13% val loss:0.2958 val acc:70.24%\n",
            "91/200 train loss:0.2266 train acc:76.70% val loss:0.3002 val acc:69.98%\n",
            "92/200 train loss:0.2348 train acc:75.87% val loss:0.2933 val acc:70.67%\n",
            "93/200 train loss:0.2266 train acc:76.68% val loss:0.2770 val acc:72.30%\n",
            "94/200 train loss:0.2211 train acc:77.23% val loss:0.3019 val acc:69.81%\n",
            "95/200 train loss:0.2242 train acc:76.95% val loss:0.2784 val acc:72.16%\n",
            "96/200 train loss:0.2190 train acc:77.46% val loss:0.2730 val acc:72.70%\n",
            "97/200 train loss:0.2237 train acc:76.99% val loss:0.2843 val acc:71.57%\n",
            "98/200 train loss:0.2152 train acc:77.84% val loss:0.2775 val acc:72.25%\n",
            "99/200 train loss:0.2165 train acc:77.71% val loss:0.2790 val acc:72.10%\n",
            "100/200 train loss:0.2178 train acc:77.59% val loss:0.2701 val acc:72.99%\n",
            "101/200 train loss:0.2139 train acc:77.97% val loss:0.2956 val acc:70.44%\n",
            "102/200 train loss:0.2220 train acc:77.16% val loss:0.2716 val acc:72.84%\n",
            "103/200 train loss:0.2157 train acc:77.79% val loss:0.2878 val acc:71.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentation"
      ],
      "metadata": {
        "id": "GqsKRBKNiLuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def randomlyAug(crop, depth, label, max_val=640):\n",
        "  h, w, c = crop.shape\n",
        "\n",
        "  if h >= w:\n",
        "    max_dim = h\n",
        "  else:\n",
        "    max_dim = w\n",
        "  max_rand = max_val / max_dim\n",
        "\n",
        "  rand_num = np.random.uniform(0.5,max_rand,1).item()\n",
        "\n",
        "  width = int(w * rand_num)\n",
        "  height = int(h * rand_num)\n",
        "  dim = (width, height)\n",
        "    \n",
        "  # resize image\n",
        "  crop = cv2.resize(crop, dim, interpolation = cv2.INTER_AREA)\n",
        "  depth = cv2.resize(depth, dim, interpolation = cv2.INTER_NEAREST)[:, :, np.newaxis]\n",
        "\n",
        "  label *= (height / h)\n",
        "\n",
        "  \n",
        "  \n",
        "  return crop, depth, label\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "def get_annotation(id,input,anno_path='/content/labels'):\n",
        "    anno = np.load(os.path.join(anno_path,'{:06d}.npy'.format(id)),allow_pickle=True).item()\n",
        "    return anno.get(input)\n",
        "    \n",
        "\n",
        "class MiniDataset(Dataset):\n",
        "    def __init__(self, base_p, label_f, depth, crops_rgb_f, aug=False, label_name=['container capacity']):\n",
        "      self.label_f = label_f #_f = folder\n",
        "      self.depth = depth\n",
        "      self.base = base_p\n",
        "      self.label_name = label_name\n",
        "      self.crops_rgb_f = crops_rgb_f\n",
        "      self.samples = os.listdir(crops_rgb_f)\n",
        "      self.ids = [ int(x.split('.')[0]) for x in self.samples]\n",
        "      self.transform = transforms.Compose([\n",
        "                                             transforms.Resize((320, 320)),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.ConvertImageDtype(torch.float),\n",
        "                                             ])\n",
        "      self.aug = aug\n",
        "    def __len__(self):\n",
        "      return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      id_ = self.ids[idx]\n",
        "        \n",
        "      # depth\n",
        "      depth = np.asarray(Image.open(os.path.join(self.depth,'{:06d}.png'.format(id_))))[:,:,np.newaxis]\n",
        "      \n",
        "      # rgb_cropped\n",
        "      crop = np.asarray(Image.open(os.path.join(self.crops_rgb_f,'{:06d}.png'.format(id_))))\n",
        "      # label\n",
        "      label = np.array([get_annotation(id_,name,os.path.join(self.base, 'labels')) for name in self.label_name])\n",
        "\n",
        "      if self.aug:\n",
        "          crop, depth, label = randomlyAug(crop, depth, label, max_val=640)\n",
        "\n",
        "      h, w, c = crop.shape\n",
        "\n",
        "      resX = 640 - h\n",
        "      resY = 640 - w\n",
        "\n",
        "      up = resX // 2\n",
        "      down = up\n",
        "      if resX % 2 != 0:\n",
        "        down +=1\n",
        "\n",
        "      left = resY // 2\n",
        "      right = left\n",
        "\n",
        "      if resY % 2 != 0:\n",
        "        left += 1\n",
        "\n",
        "      padding = transforms.Pad((left, up, right, down))\n",
        "\n",
        "    \n",
        "      image = Image.fromarray(np.concatenate((crop, depth), axis=2))\n",
        "      image = padding(image)\n",
        "      image = self.transform(image)\n",
        "      \n",
        "\n",
        "      return image, label"
      ],
      "metadata": {
        "id": "GCr38T3ViNPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        aug=True)\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                        '/content/test/labels', \n",
        "                        '/content/test/crops_depth',\n",
        "                        '/content/test/crops_rgb')\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-aug{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohku2D3FiTO7",
        "outputId": "2b932682-767d-49b6-b39a-8d2f57026098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.6046 train acc:21.23% val loss:0.5439 val acc:37.81%\n",
            "2/100 train loss:0.5463 train acc:29.05% val loss:0.3676 val acc:62.11%\n",
            "3/100 train loss:0.5021 train acc:38.07% val loss:0.3545 val acc:63.48%\n",
            "4/100 train loss:0.4593 train acc:44.55% val loss:0.3810 val acc:58.59%\n",
            "5/100 train loss:0.4084 train acc:52.29% val loss:0.3735 val acc:62.35%\n",
            "6/100 train loss:0.3723 train acc:58.19% val loss:0.3151 val acc:68.20%\n",
            "7/100 train loss:0.3370 train acc:62.11% val loss:0.2992 val acc:70.08%\n",
            "8/100 train loss:0.2984 train acc:67.44% val loss:0.7842 val acc:21.58%\n",
            "9/100 train loss:0.2751 train acc:71.59% val loss:0.2216 val acc:77.84%\n",
            "10/100 train loss:0.2663 train acc:72.74% val loss:0.4636 val acc:53.64%\n",
            "11/100 train loss:0.2620 train acc:73.17% val loss:0.2832 val acc:71.68%\n",
            "12/100 train loss:0.2506 train acc:74.30% val loss:0.2553 val acc:74.47%\n",
            "13/100 train loss:0.2387 train acc:75.49% val loss:0.2207 val acc:77.93%\n",
            "14/100 train loss:0.2356 train acc:75.80% val loss:0.2476 val acc:75.24%\n",
            "15/100 train loss:0.2332 train acc:76.04% val loss:0.2210 val acc:77.90%\n",
            "16/100 train loss:0.2267 train acc:76.69% val loss:0.2214 val acc:77.86%\n",
            "17/100 train loss:0.2355 train acc:75.81% val loss:0.2840 val acc:71.60%\n",
            "18/100 train loss:0.2350 train acc:75.87% val loss:0.2486 val acc:75.14%\n",
            "19/100 train loss:0.2407 train acc:75.29% val loss:0.8346 val acc:16.54%\n",
            "20/100 train loss:0.2324 train acc:76.12% val loss:0.2250 val acc:77.50%\n",
            "21/100 train loss:0.2243 train acc:76.93% val loss:0.2159 val acc:78.41%\n",
            "22/100 train loss:0.2242 train acc:76.95% val loss:0.9636 val acc:3.64%\n",
            "23/100 train loss:0.2566 train acc:73.70% val loss:0.2300 val acc:77.00%\n",
            "24/100 train loss:0.2322 train acc:76.14% val loss:0.2420 val acc:75.80%\n",
            "25/100 train loss:0.2221 train acc:77.16% val loss:0.5667 val acc:43.33%\n",
            "26/100 train loss:0.2240 train acc:76.96% val loss:0.2356 val acc:76.44%\n",
            "27/100 train loss:0.2214 train acc:77.23% val loss:0.2734 val acc:72.66%\n",
            "28/100 train loss:0.2466 train acc:74.71% val loss:0.2572 val acc:74.28%\n",
            "29/100 train loss:0.2562 train acc:73.74% val loss:0.2233 val acc:77.67%\n",
            "30/100 train loss:0.2362 train acc:75.74% val loss:0.2555 val acc:74.45%\n",
            "31/100 train loss:0.2310 train acc:76.26% val loss:0.4714 val acc:52.86%\n",
            "32/100 train loss:0.2384 train acc:75.53% val loss:0.2160 val acc:78.40%\n",
            "33/100 train loss:0.2316 train acc:76.21% val loss:0.2121 val acc:78.79%\n",
            "34/100 train loss:0.2242 train acc:76.95% val loss:0.3048 val acc:69.52%\n",
            "35/100 train loss:0.2474 train acc:74.62% val loss:0.2977 val acc:70.23%\n",
            "36/100 train loss:0.2319 train acc:76.17% val loss:0.2512 val acc:74.88%\n",
            "37/100 train loss:0.2319 train acc:76.17% val loss:0.2719 val acc:72.81%\n",
            "38/100 train loss:0.2220 train acc:77.17% val loss:0.8565 val acc:14.35%\n",
            "39/100 train loss:0.2181 train acc:77.56% val loss:0.2584 val acc:74.16%\n",
            "40/100 train loss:0.2291 train acc:76.45% val loss:0.2074 val acc:79.26%\n",
            "41/100 train loss:0.2227 train acc:77.09% val loss:0.2467 val acc:75.33%\n",
            "42/100 train loss:0.2299 train acc:76.37% val loss:0.2422 val acc:75.78%\n",
            "43/100 train loss:0.2159 train acc:77.78% val loss:0.2253 val acc:77.47%\n",
            "44/100 train loss:0.2152 train acc:77.84% val loss:0.2333 val acc:76.67%\n",
            "45/100 train loss:0.2146 train acc:77.90% val loss:0.2057 val acc:79.43%\n",
            "46/100 train loss:0.2144 train acc:77.92% val loss:0.3882 val acc:60.89%\n",
            "47/100 train loss:0.2197 train acc:77.39% val loss:0.2234 val acc:77.66%\n",
            "48/100 train loss:0.2185 train acc:77.52% val loss:0.2487 val acc:75.13%\n",
            "49/100 train loss:0.2109 train acc:78.27% val loss:0.2591 val acc:74.09%\n",
            "50/100 train loss:0.2056 train acc:78.80% val loss:0.2225 val acc:77.75%\n",
            "51/100 train loss:0.2026 train acc:79.10% val loss:0.2538 val acc:74.62%\n",
            "52/100 train loss:0.2047 train acc:78.90% val loss:0.8094 val acc:19.06%\n",
            "53/100 train loss:0.2106 train acc:78.31% val loss:0.2193 val acc:77.54%\n",
            "54/100 train loss:0.2066 train acc:78.71% val loss:0.2126 val acc:78.74%\n",
            "55/100 train loss:0.1983 train acc:79.54% val loss:0.2434 val acc:75.66%\n",
            "56/100 train loss:0.1978 train acc:79.59% val loss:0.2151 val acc:78.49%\n",
            "57/100 train loss:0.2041 train acc:78.95% val loss:0.2419 val acc:75.81%\n",
            "58/100 train loss:0.2177 train acc:77.60% val loss:0.2445 val acc:75.55%\n",
            "59/100 train loss:0.2056 train acc:78.81% val loss:0.2280 val acc:77.20%\n",
            "60/100 train loss:0.2018 train acc:79.18% val loss:0.6748 val acc:32.52%\n",
            "61/100 train loss:0.1960 train acc:79.76% val loss:0.4527 val acc:54.73%\n",
            "62/100 train loss:0.2148 train acc:77.89% val loss:0.2585 val acc:74.15%\n",
            "63/100 train loss:0.2054 train acc:78.83% val loss:0.9043 val acc:9.57%\n",
            "64/100 train loss:0.2280 train acc:76.56% val loss:0.2308 val acc:76.92%\n",
            "65/100 train loss:0.2182 train acc:77.55% val loss:0.7865 val acc:21.35%\n",
            "66/100 train loss:0.2069 train acc:78.68% val loss:0.2431 val acc:75.69%\n",
            "67/100 train loss:0.2040 train acc:78.96% val loss:0.2715 val acc:72.85%\n",
            "68/100 train loss:0.2033 train acc:79.04% val loss:0.2269 val acc:77.04%\n",
            "69/100 train loss:0.1977 train acc:79.60% val loss:0.7976 val acc:20.24%\n",
            "70/100 train loss:0.1978 train acc:79.59% val loss:0.2292 val acc:77.08%\n",
            "71/100 train loss:0.1972 train acc:79.65% val loss:0.2414 val acc:75.86%\n",
            "72/100 train loss:0.1977 train acc:79.59% val loss:0.2264 val acc:77.36%\n",
            "73/100 train loss:0.1917 train acc:80.19% val loss:0.2749 val acc:72.51%\n",
            "74/100 train loss:0.1955 train acc:79.81% val loss:0.2208 val acc:77.92%\n",
            "75/100 train loss:0.1885 train acc:80.51% val loss:0.2195 val acc:78.05%\n",
            "76/100 train loss:0.1900 train acc:80.37% val loss:0.2212 val acc:77.88%\n",
            "77/100 train loss:0.1824 train acc:81.12% val loss:0.2279 val acc:77.21%\n",
            "78/100 train loss:0.1833 train acc:81.03% val loss:0.2107 val acc:78.93%\n",
            "79/100 train loss:0.1885 train acc:80.51% val loss:0.2068 val acc:79.32%\n",
            "80/100 train loss:0.1820 train acc:81.16% val loss:0.2369 val acc:76.31%\n",
            "81/100 train loss:0.1804 train acc:81.32% val loss:0.2037 val acc:79.63%\n",
            "82/100 train loss:0.1748 train acc:81.88% val loss:0.2188 val acc:78.12%\n",
            "83/100 train loss:0.1706 train acc:82.30% val loss:0.2087 val acc:79.13%\n",
            "84/100 train loss:0.1734 train acc:82.02% val loss:0.2063 val acc:79.37%\n",
            "85/100 train loss:0.1697 train acc:82.40% val loss:0.2048 val acc:79.52%\n",
            "86/100 train loss:0.1728 train acc:82.08% val loss:0.2046 val acc:79.54%\n",
            "87/100 train loss:0.1739 train acc:81.98% val loss:0.4171 val acc:58.29%\n",
            "88/100 train loss:0.1716 train acc:82.20% val loss:0.2027 val acc:79.73%\n",
            "89/100 train loss:0.1669 train acc:82.67% val loss:0.1968 val acc:80.32%\n",
            "90/100 train loss:0.1653 train acc:82.84% val loss:0.2143 val acc:78.57%\n",
            "91/100 train loss:0.1724 train acc:82.13% val loss:0.1985 val acc:80.15%\n",
            "92/100 train loss:0.1708 train acc:82.28% val loss:0.3389 val acc:66.11%\n",
            "93/100 train loss:0.1712 train acc:82.24% val loss:0.2134 val acc:78.66%\n",
            "94/100 train loss:0.1724 train acc:82.12% val loss:0.2136 val acc:78.64%\n",
            "95/100 train loss:0.1675 train acc:82.61% val loss:0.2046 val acc:79.54%\n",
            "96/100 train loss:0.1705 train acc:82.31% val loss:0.2372 val acc:76.28%\n",
            "97/100 train loss:0.1606 train acc:83.30% val loss:0.2429 val acc:75.71%\n",
            "98/100 train loss:0.1671 train acc:82.66% val loss:0.1977 val acc:80.23%\n",
            "99/100 train loss:0.1634 train acc:83.02% val loss:0.2464 val acc:75.36%\n",
            "100/100 train loss:0.1637 train acc:83.00% val loss:0.2215 val acc:77.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XMeJoFiYlBuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MobileCA"
      ],
      "metadata": {
        "id": "05ZB_SJxvC8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from models import mbv2_ca\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        aug=True\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                       \n",
        "                      )\n",
        "model = mbv2_ca(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-ca{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fonuDUPEvEcn",
        "outputId": "bc1b45e7-b41c-4ebd-e199-62e8f8aaf10b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5660 train acc:42.75% val loss:0.6299 val acc:37.01%\n",
            "2/100 train loss:0.4838 train acc:50.99% val loss:0.5819 val acc:41.81%\n",
            "3/100 train loss:0.4136 train acc:58.01% val loss:0.3188 val acc:68.12%\n",
            "4/100 train loss:0.3301 train acc:66.36% val loss:0.4220 val acc:57.80%\n",
            "5/100 train loss:0.2672 train acc:72.65% val loss:0.7110 val acc:28.90%\n",
            "6/100 train loss:0.2441 train acc:74.96% val loss:0.2595 val acc:74.05%\n",
            "7/100 train loss:0.2269 train acc:76.67% val loss:0.3324 val acc:66.76%\n",
            "8/100 train loss:0.2166 train acc:77.71% val loss:0.2413 val acc:75.87%\n",
            "9/100 train loss:0.2116 train acc:78.21% val loss:0.2650 val acc:73.50%\n",
            "10/100 train loss:0.2103 train acc:78.33% val loss:0.2533 val acc:74.67%\n",
            "11/100 train loss:0.2008 train acc:79.29% val loss:0.2437 val acc:75.63%\n",
            "12/100 train loss:0.1962 train acc:79.75% val loss:0.3192 val acc:68.08%\n",
            "13/100 train loss:0.1909 train acc:80.27% val loss:0.2448 val acc:75.52%\n",
            "14/100 train loss:0.1920 train acc:80.16% val loss:0.2338 val acc:76.62%\n",
            "15/100 train loss:0.1828 train acc:81.08% val loss:0.2105 val acc:78.95%\n",
            "16/100 train loss:0.1809 train acc:81.27% val loss:0.7148 val acc:28.52%\n",
            "17/100 train loss:0.1836 train acc:81.01% val loss:0.2230 val acc:77.70%\n",
            "18/100 train loss:0.1767 train acc:81.69% val loss:0.2086 val acc:79.14%\n",
            "19/100 train loss:0.1761 train acc:81.76% val loss:0.4881 val acc:51.19%\n",
            "20/100 train loss:0.1709 train acc:82.28% val loss:0.2206 val acc:77.94%\n",
            "21/100 train loss:0.1733 train acc:82.03% val loss:0.2323 val acc:76.77%\n",
            "22/100 train loss:0.1671 train acc:82.65% val loss:0.4433 val acc:55.67%\n",
            "23/100 train loss:0.1692 train acc:82.45% val loss:0.2057 val acc:79.43%\n",
            "24/100 train loss:0.1621 train acc:83.16% val loss:0.2222 val acc:77.78%\n",
            "25/100 train loss:0.1606 train acc:83.31% val loss:0.2371 val acc:76.29%\n",
            "26/100 train loss:0.1639 train acc:82.97% val loss:0.2079 val acc:79.21%\n",
            "27/100 train loss:0.1522 train acc:84.14% val loss:0.2291 val acc:77.09%\n",
            "28/100 train loss:0.1564 train acc:83.73% val loss:0.2453 val acc:75.47%\n",
            "29/100 train loss:0.1533 train acc:84.04% val loss:0.2450 val acc:75.50%\n",
            "30/100 train loss:0.1492 train acc:84.45% val loss:0.1954 val acc:80.46%\n",
            "31/100 train loss:0.1444 train acc:84.92% val loss:0.7269 val acc:27.31%\n",
            "32/100 train loss:0.1504 train acc:84.33% val loss:0.2266 val acc:77.34%\n",
            "33/100 train loss:0.1463 train acc:84.73% val loss:0.1988 val acc:80.12%\n",
            "34/100 train loss:0.1462 train acc:84.75% val loss:0.1965 val acc:80.35%\n",
            "35/100 train loss:0.1380 train acc:85.57% val loss:0.2228 val acc:77.72%\n",
            "36/100 train loss:0.1442 train acc:84.94% val loss:0.2181 val acc:78.19%\n",
            "37/100 train loss:0.1441 train acc:84.95% val loss:0.2105 val acc:78.95%\n",
            "38/100 train loss:0.1479 train acc:84.57% val loss:0.2509 val acc:74.91%\n",
            "39/100 train loss:0.1364 train acc:85.72% val loss:0.2156 val acc:78.44%\n",
            "40/100 train loss:0.1387 train acc:85.50% val loss:0.2051 val acc:79.49%\n",
            "41/100 train loss:0.1323 train acc:86.13% val loss:0.1871 val acc:81.29%\n",
            "42/100 train loss:0.1310 train acc:86.26% val loss:0.1863 val acc:81.37%\n",
            "43/100 train loss:0.1343 train acc:85.93% val loss:0.6400 val acc:36.00%\n",
            "44/100 train loss:0.1327 train acc:86.09% val loss:0.2088 val acc:79.12%\n",
            "45/100 train loss:0.1324 train acc:86.12% val loss:0.1840 val acc:81.60%\n",
            "46/100 train loss:0.1318 train acc:86.19% val loss:0.1849 val acc:81.51%\n",
            "47/100 train loss:0.1279 train acc:86.57% val loss:0.2130 val acc:78.70%\n",
            "48/100 train loss:0.1301 train acc:86.36% val loss:0.1857 val acc:81.43%\n",
            "49/100 train loss:0.1287 train acc:86.49% val loss:0.1983 val acc:80.17%\n",
            "50/100 train loss:0.1247 train acc:86.89% val loss:0.1950 val acc:80.50%\n",
            "51/100 train loss:0.1211 train acc:87.25% val loss:0.2282 val acc:77.18%\n",
            "52/100 train loss:0.1177 train acc:87.59% val loss:0.2161 val acc:78.39%\n",
            "53/100 train loss:0.1218 train acc:87.18% val loss:0.1777 val acc:82.23%\n",
            "54/100 train loss:0.1262 train acc:86.75% val loss:0.1814 val acc:81.86%\n",
            "55/100 train loss:0.1166 train acc:87.71% val loss:0.1847 val acc:81.53%\n",
            "56/100 train loss:0.1124 train acc:88.12% val loss:0.1826 val acc:81.74%\n",
            "57/100 train loss:0.1214 train acc:87.23% val loss:0.1876 val acc:81.24%\n",
            "58/100 train loss:0.1150 train acc:87.86% val loss:0.2286 val acc:77.14%\n",
            "59/100 train loss:0.1129 train acc:88.07% val loss:0.1940 val acc:80.60%\n",
            "60/100 train loss:0.1155 train acc:87.82% val loss:0.2117 val acc:78.83%\n",
            "61/100 train loss:0.1150 train acc:87.86% val loss:0.1892 val acc:81.08%\n",
            "62/100 train loss:0.1091 train acc:88.45% val loss:0.1894 val acc:81.06%\n",
            "63/100 train loss:0.1064 train acc:88.73% val loss:0.3647 val acc:63.53%\n",
            "64/100 train loss:0.1136 train acc:88.00% val loss:0.1842 val acc:81.58%\n",
            "65/100 train loss:0.1092 train acc:88.45% val loss:0.1900 val acc:81.00%\n",
            "66/100 train loss:0.1101 train acc:88.36% val loss:0.6476 val acc:35.24%\n",
            "67/100 train loss:0.1065 train acc:88.72% val loss:0.1955 val acc:80.45%\n",
            "68/100 train loss:0.1069 train acc:88.68% val loss:0.1709 val acc:82.91%\n",
            "69/100 train loss:0.1080 train acc:88.56% val loss:0.1835 val acc:81.65%\n",
            "70/100 train loss:0.1046 train acc:88.90% val loss:0.1831 val acc:81.69%\n",
            "71/100 train loss:0.1079 train acc:88.58% val loss:0.1729 val acc:82.71%\n",
            "72/100 train loss:0.1050 train acc:88.86% val loss:0.4923 val acc:50.77%\n",
            "73/100 train loss:0.1035 train acc:89.01% val loss:0.1993 val acc:80.07%\n",
            "74/100 train loss:0.1024 train acc:89.12% val loss:0.1854 val acc:81.46%\n",
            "75/100 train loss:0.1024 train acc:89.13% val loss:0.1601 val acc:83.99%\n",
            "76/100 train loss:0.1050 train acc:88.87% val loss:0.4991 val acc:50.09%\n",
            "77/100 train loss:0.1027 train acc:89.09% val loss:0.1732 val acc:82.68%\n",
            "78/100 train loss:0.1050 train acc:88.86% val loss:0.1895 val acc:81.05%\n",
            "79/100 train loss:0.1005 train acc:89.32% val loss:0.1826 val acc:81.74%\n",
            "80/100 train loss:0.0989 train acc:89.48% val loss:0.1798 val acc:82.02%\n",
            "81/100 train loss:0.1030 train acc:89.06% val loss:0.1806 val acc:81.94%\n",
            "82/100 train loss:0.0978 train acc:89.59% val loss:0.1746 val acc:82.54%\n",
            "83/100 train loss:0.0961 train acc:89.76% val loss:0.1795 val acc:82.05%\n",
            "84/100 train loss:0.0954 train acc:89.82% val loss:0.1801 val acc:81.99%\n",
            "85/100 train loss:0.0956 train acc:89.81% val loss:0.1732 val acc:82.68%\n",
            "86/100 train loss:0.0947 train acc:89.89% val loss:0.2104 val acc:78.96%\n",
            "87/100 train loss:0.0983 train acc:89.53% val loss:0.1881 val acc:81.19%\n",
            "88/100 train loss:0.0953 train acc:89.83% val loss:0.1674 val acc:83.26%\n",
            "89/100 train loss:0.0996 train acc:89.40% val loss:0.1705 val acc:82.95%\n",
            "90/100 train loss:0.0946 train acc:89.90% val loss:0.1678 val acc:83.22%\n",
            "91/100 train loss:0.0934 train acc:90.03% val loss:0.1990 val acc:80.10%\n",
            "92/100 train loss:0.0964 train acc:89.72% val loss:0.1803 val acc:81.97%\n",
            "93/100 train loss:0.0949 train acc:89.87% val loss:0.1666 val acc:83.34%\n",
            "94/100 train loss:0.0946 train acc:89.91% val loss:0.1737 val acc:82.63%\n",
            "95/100 train loss:0.0932 train acc:90.05% val loss:0.1810 val acc:81.90%\n",
            "96/100 train loss:0.0962 train acc:89.75% val loss:0.1763 val acc:82.37%\n",
            "97/100 train loss:0.0957 train acc:89.80% val loss:0.1709 val acc:82.91%\n",
            "98/100 train loss:0.0914 train acc:90.22% val loss:0.1803 val acc:81.97%\n",
            "99/100 train loss:0.0943 train acc:89.94% val loss:0.2515 val acc:74.85%\n",
            "100/100 train loss:0.0982 train acc:89.54% val loss:0.1662 val acc:83.38%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chaoran dataset"
      ],
      "metadata": {
        "id": "UdNvv6DB8j93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def randomlyAug(crop, depth, label, max_val=640):\n",
        "  h, w, c = crop.shape\n",
        "\n",
        "  if h >= w:\n",
        "    max_dim = h\n",
        "  else:\n",
        "    max_dim = w\n",
        "  max_rand = max_val / max_dim\n",
        "\n",
        "  rand_num = np.random.uniform(0.5,max_rand,1).item()\n",
        "\n",
        "  width = int(w * rand_num)\n",
        "  height = int(h * rand_num)\n",
        "  dim = (width, height)\n",
        "    \n",
        "  # resize image\n",
        "  crop = cv2.resize(crop, dim, interpolation = cv2.INTER_AREA)\n",
        "  depth = cv2.resize(depth, dim, interpolation = cv2.INTER_NEAREST)[:, :, np.newaxis]\n",
        "\n",
        "  label *= (height / h)\n",
        "\n",
        "  \n",
        "  \n",
        "  return crop, depth, label\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "def get_annotation(id,input,anno_path='/content/labels'):\n",
        "    anno = np.load(os.path.join(anno_path,'{:06d}.npy'.format(id)),allow_pickle=True).item()\n",
        "    return anno.get(input)\n",
        "    \n",
        "\n",
        "class MiniDataset(Dataset):\n",
        "    def __init__(self, base_p, label_f, depth, crops_rgb_f, aug=False, label_name=['container capacity']):\n",
        "      self.label_f = label_f #_f = folder\n",
        "      self.depth = depth\n",
        "      self.base = base_p\n",
        "      self.label_name = label_name\n",
        "      self.crops_rgb_f = crops_rgb_f\n",
        "      self.samples = os.listdir(crops_rgb_f)\n",
        "      self.ids = [ int(x.split('.')[0]) for x in self.samples]\n",
        "      self.transform = transforms.Compose([\n",
        "                                             transforms.Resize((320, 320)),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.ConvertImageDtype(torch.float),\n",
        "                                             ])\n",
        "      self.aug = aug\n",
        "    def __len__(self):\n",
        "      return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      id_ = self.ids[idx]\n",
        "        \n",
        "      # depth\n",
        "      depth = np.asarray(Image.open(os.path.join(self.depth,'{:06d}.png'.format(id_))))[:,:,np.newaxis]\n",
        "      \n",
        "      # rgb_cropped\n",
        "      crop = np.asarray(Image.open(os.path.join(self.crops_rgb_f,'{:06d}.png'.format(id_))))\n",
        "      # label\n",
        "      label = np.array([get_annotation(id_,name,os.path.join(self.base, 'labels')) for name in self.label_name])\n",
        "\n",
        "      if self.aug:\n",
        "          crop, depth, label = randomlyAug(crop, depth, label, max_val=640)\n",
        "\n",
        "      h, w, c = crop.shape\n",
        "\n",
        "      resX = 640 - h\n",
        "      resY = 640 - w\n",
        "\n",
        "      up = resX // 2\n",
        "      down = up\n",
        "      if resX % 2 != 0:\n",
        "        down +=1\n",
        "\n",
        "      left = resY // 2\n",
        "      right = left\n",
        "\n",
        "      if resY % 2 != 0:\n",
        "        left += 1\n",
        "\n",
        "      padding = transforms.Pad((left, up, right, down))\n",
        "\n",
        "    \n",
        "      image = Image.fromarray(np.concatenate((crop, depth), axis=2))\n",
        "      image = padding(image)\n",
        "      image = self.transform(image)\n",
        "      \n",
        "\n",
        "      return image, label"
      ],
      "metadata": {
        "id": "1QgGDUZ88l-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models import mbv2_ca\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE/task3'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        aug=True\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                       \n",
        "                      )\n",
        "model = mbv2_ca(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              \"mobile-ca{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpPCp2tU8ott",
        "outputId": "6017ca6a-d824-46e8-cdcc-15b459eb4211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5757 train acc:42.17% val loss:0.6286 val acc:37.14%\n",
            "2/100 train loss:0.4836 train acc:51.40% val loss:0.4326 val acc:56.74%\n",
            "3/100 train loss:0.4223 train acc:57.54% val loss:0.5826 val acc:41.74%\n",
            "4/100 train loss:0.3646 train acc:63.30% val loss:0.4875 val acc:51.25%\n",
            "5/100 train loss:0.3035 train acc:69.42% val loss:0.1998 val acc:80.02%\n",
            "6/100 train loss:0.2727 train acc:72.49% val loss:0.3511 val acc:64.89%\n",
            "7/100 train loss:0.2281 train acc:76.96% val loss:0.4130 val acc:58.70%\n",
            "8/100 train loss:0.2076 train acc:79.00% val loss:0.1869 val acc:81.31%\n",
            "9/100 train loss:0.1834 train acc:81.43% val loss:0.2043 val acc:79.57%\n",
            "10/100 train loss:0.1797 train acc:81.79% val loss:0.3986 val acc:60.14%\n",
            "11/100 train loss:0.1731 train acc:82.45% val loss:0.3703 val acc:62.97%\n",
            "12/100 train loss:0.1718 train acc:82.58% val loss:0.3273 val acc:67.27%\n",
            "13/100 train loss:0.1646 train acc:83.30% val loss:0.4105 val acc:58.95%\n",
            "14/100 train loss:0.1577 train acc:83.99% val loss:0.4752 val acc:52.48%\n",
            "15/100 train loss:0.1567 train acc:84.09% val loss:0.4330 val acc:56.70%\n",
            "16/100 train loss:0.1602 train acc:83.74% val loss:0.3989 val acc:60.11%\n",
            "17/100 train loss:0.1544 train acc:84.33% val loss:0.4165 val acc:58.35%\n",
            "18/100 train loss:0.1510 train acc:84.67% val loss:0.3882 val acc:61.18%\n",
            "19/100 train loss:0.1577 train acc:83.99% val loss:0.1441 val acc:85.59%\n",
            "20/100 train loss:0.1518 train acc:84.59% val loss:0.3508 val acc:64.92%\n",
            "21/100 train loss:0.1485 train acc:84.92% val loss:0.2646 val acc:73.54%\n",
            "22/100 train loss:0.1472 train acc:85.04% val loss:0.2738 val acc:72.62%\n",
            "23/100 train loss:0.1489 train acc:84.88% val loss:0.3849 val acc:61.51%\n",
            "24/100 train loss:0.1504 train acc:84.72% val loss:0.3668 val acc:63.32%\n",
            "25/100 train loss:0.1415 train acc:85.61% val loss:0.3928 val acc:60.72%\n",
            "26/100 train loss:0.1408 train acc:85.68% val loss:0.3903 val acc:60.97%\n",
            "27/100 train loss:0.1388 train acc:85.88% val loss:0.3766 val acc:62.34%\n",
            "28/100 train loss:0.1382 train acc:85.94% val loss:0.3723 val acc:62.77%\n",
            "29/100 train loss:0.1382 train acc:85.94% val loss:0.1538 val acc:84.62%\n",
            "30/100 train loss:0.1316 train acc:86.61% val loss:0.4156 val acc:58.44%\n",
            "31/100 train loss:0.1381 train acc:85.95% val loss:0.1941 val acc:80.59%\n",
            "32/100 train loss:0.1238 train acc:87.39% val loss:0.1177 val acc:88.23%\n",
            "33/100 train loss:0.1304 train acc:86.72% val loss:0.3565 val acc:64.35%\n",
            "34/100 train loss:0.1257 train acc:87.19% val loss:0.1571 val acc:84.29%\n",
            "35/100 train loss:0.1262 train acc:87.14% val loss:0.2203 val acc:77.97%\n",
            "36/100 train loss:0.1273 train acc:87.03% val loss:0.3790 val acc:62.10%\n",
            "37/100 train loss:0.1333 train acc:86.43% val loss:0.4064 val acc:59.36%\n",
            "38/100 train loss:0.1231 train acc:87.45% val loss:0.2430 val acc:75.70%\n",
            "39/100 train loss:0.1266 train acc:87.10% val loss:0.3325 val acc:66.75%\n",
            "40/100 train loss:0.1263 train acc:87.13% val loss:0.2752 val acc:72.48%\n",
            "41/100 train loss:0.1155 train acc:88.21% val loss:0.3083 val acc:69.17%\n",
            "42/100 train loss:0.1196 train acc:87.80% val loss:0.3711 val acc:62.89%\n",
            "43/100 train loss:0.1190 train acc:87.86% val loss:0.4131 val acc:58.69%\n",
            "44/100 train loss:0.1214 train acc:87.63% val loss:0.2873 val acc:71.27%\n",
            "45/100 train loss:0.1162 train acc:88.14% val loss:0.4451 val acc:55.49%\n",
            "46/100 train loss:0.1151 train acc:88.25% val loss:0.2035 val acc:79.65%\n",
            "47/100 train loss:0.1108 train acc:88.69% val loss:0.2059 val acc:79.41%\n",
            "48/100 train loss:0.1200 train acc:87.77% val loss:0.4186 val acc:58.14%\n",
            "49/100 train loss:0.1168 train acc:88.08% val loss:0.3904 val acc:60.96%\n",
            "50/100 train loss:0.1132 train acc:88.44% val loss:0.4339 val acc:56.61%\n",
            "51/100 train loss:0.1192 train acc:87.84% val loss:0.4265 val acc:57.35%\n",
            "52/100 train loss:0.1156 train acc:88.20% val loss:0.3215 val acc:67.85%\n",
            "53/100 train loss:0.1124 train acc:88.52% val loss:0.4445 val acc:55.55%\n",
            "54/100 train loss:0.1107 train acc:88.69% val loss:0.8388 val acc:16.12%\n",
            "55/100 train loss:0.1100 train acc:88.76% val loss:0.3985 val acc:60.15%\n",
            "56/100 train loss:0.1194 train acc:87.82% val loss:0.4554 val acc:54.46%\n",
            "57/100 train loss:0.1100 train acc:88.77% val loss:0.4138 val acc:58.62%\n",
            "58/100 train loss:0.1043 train acc:89.34% val loss:0.3677 val acc:63.23%\n",
            "59/100 train loss:0.1065 train acc:89.11% val loss:0.2010 val acc:79.90%\n",
            "60/100 train loss:0.1049 train acc:89.27% val loss:0.3614 val acc:63.86%\n",
            "61/100 train loss:0.1026 train acc:89.50% val loss:0.3612 val acc:63.88%\n",
            "62/100 train loss:0.1074 train acc:89.02% val loss:0.3608 val acc:63.92%\n",
            "63/100 train loss:0.1062 train acc:89.14% val loss:0.2578 val acc:74.22%\n",
            "64/100 train loss:0.1054 train acc:89.22% val loss:0.3870 val acc:61.30%\n",
            "65/100 train loss:0.1032 train acc:89.44% val loss:0.4244 val acc:57.56%\n",
            "66/100 train loss:0.0985 train acc:89.91% val loss:0.4208 val acc:57.92%\n",
            "67/100 train loss:0.1028 train acc:89.48% val loss:0.4249 val acc:57.51%\n",
            "68/100 train loss:0.1054 train acc:89.22% val loss:0.3558 val acc:64.42%\n",
            "69/100 train loss:0.0938 train acc:90.38% val loss:0.4029 val acc:59.71%\n",
            "70/100 train loss:0.1008 train acc:89.68% val loss:0.3835 val acc:61.65%\n",
            "71/100 train loss:0.0953 train acc:90.23% val loss:0.3891 val acc:61.09%\n",
            "72/100 train loss:0.0983 train acc:89.94% val loss:0.3555 val acc:64.45%\n",
            "73/100 train loss:0.0929 train acc:90.47% val loss:0.4034 val acc:59.66%\n",
            "74/100 train loss:0.0998 train acc:89.78% val loss:0.3595 val acc:64.05%\n",
            "75/100 train loss:0.0962 train acc:90.14% val loss:0.2387 val acc:76.13%\n",
            "76/100 train loss:0.0941 train acc:90.35% val loss:0.4207 val acc:57.93%\n",
            "77/100 train loss:0.0907 train acc:90.69% val loss:0.4249 val acc:57.51%\n",
            "78/100 train loss:0.0885 train acc:90.91% val loss:0.3717 val acc:62.83%\n",
            "79/100 train loss:0.0906 train acc:90.70% val loss:0.3744 val acc:62.56%\n",
            "80/100 train loss:0.0904 train acc:90.72% val loss:0.4412 val acc:55.88%\n",
            "81/100 train loss:0.0873 train acc:91.03% val loss:0.3812 val acc:61.88%\n",
            "82/100 train loss:0.0896 train acc:90.80% val loss:0.4512 val acc:54.88%\n",
            "83/100 train loss:0.0909 train acc:90.67% val loss:0.4162 val acc:58.38%\n",
            "84/100 train loss:0.0884 train acc:90.93% val loss:0.2789 val acc:72.11%\n",
            "85/100 train loss:0.0892 train acc:90.84% val loss:0.3709 val acc:62.91%\n",
            "86/100 train loss:0.0868 train acc:91.08% val loss:0.4144 val acc:58.56%\n",
            "87/100 train loss:0.0891 train acc:90.85% val loss:0.4139 val acc:58.61%\n",
            "88/100 train loss:0.0886 train acc:90.90% val loss:0.4398 val acc:56.02%\n",
            "89/100 train loss:0.0893 train acc:90.83% val loss:0.4033 val acc:59.67%\n",
            "90/100 train loss:0.0895 train acc:90.81% val loss:0.4163 val acc:58.37%\n",
            "91/100 train loss:0.0904 train acc:90.72% val loss:0.3736 val acc:62.64%\n",
            "92/100 train loss:0.0864 train acc:91.12% val loss:0.2935 val acc:70.65%\n",
            "93/100 train loss:0.0877 train acc:91.00% val loss:0.2812 val acc:71.88%\n",
            "94/100 train loss:0.0901 train acc:90.75% val loss:0.3171 val acc:68.29%\n",
            "95/100 train loss:0.0841 train acc:91.35% val loss:0.3961 val acc:60.39%\n",
            "96/100 train loss:0.0845 train acc:91.31% val loss:0.3611 val acc:63.89%\n",
            "97/100 train loss:0.0830 train acc:91.47% val loss:0.4098 val acc:59.02%\n",
            "98/100 train loss:0.0826 train acc:91.50% val loss:0.4447 val acc:55.53%\n",
            "99/100 train loss:0.0802 train acc:91.74% val loss:0.4386 val acc:56.14%\n",
            "100/100 train loss:0.0810 train acc:91.66% val loss:0.4260 val acc:57.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE/task3/mobileV3'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        aug=True)\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                        '/content/test/labels', \n",
        "                        '/content/test/crops_depth',\n",
        "                        '/content/test/crops_rgb')\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path,\n",
        "                                              \"mobile-aug{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT_DXBRR8zqM",
        "outputId": "2687bcf6-29cb-473b-b8e1-2758928011f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.6007 train acc:18.98% val loss:0.5936 val acc:37.28%\n",
            "2/100 train loss:0.5425 train acc:26.85% val loss:0.5103 val acc:48.29%\n",
            "3/100 train loss:0.4951 train acc:35.74% val loss:0.4270 val acc:57.03%\n",
            "4/100 train loss:0.4432 train acc:44.76% val loss:0.5623 val acc:29.87%\n",
            "5/100 train loss:0.4003 train acc:51.15% val loss:0.6894 val acc:0.30%\n",
            "6/100 train loss:0.3715 train acc:55.96% val loss:0.2282 val acc:77.18%\n",
            "7/100 train loss:0.3684 train acc:60.66% val loss:0.2483 val acc:75.17%\n",
            "8/100 train loss:0.3058 train acc:67.16% val loss:0.4231 val acc:57.69%\n",
            "9/100 train loss:0.2833 train acc:70.18% val loss:0.3984 val acc:60.02%\n",
            "10/100 train loss:0.2671 train acc:72.29% val loss:0.3780 val acc:62.20%\n",
            "11/100 train loss:0.2417 train acc:75.38% val loss:0.3536 val acc:64.64%\n",
            "12/100 train loss:0.2277 train acc:76.89% val loss:0.3453 val acc:65.47%\n",
            "13/100 train loss:0.2184 train acc:77.88% val loss:0.3924 val acc:60.76%\n",
            "14/100 train loss:0.2277 train acc:76.86% val loss:0.3750 val acc:62.50%\n",
            "15/100 train loss:0.2233 train acc:77.40% val loss:0.4217 val acc:57.83%\n",
            "16/100 train loss:0.2311 train acc:76.60% val loss:0.1875 val acc:81.25%\n",
            "17/100 train loss:0.2132 train acc:78.38% val loss:0.2860 val acc:71.40%\n",
            "18/100 train loss:0.2078 train acc:78.93% val loss:0.4081 val acc:59.19%\n",
            "19/100 train loss:0.2092 train acc:78.82% val loss:0.3716 val acc:62.84%\n",
            "20/100 train loss:0.2044 train acc:79.31% val loss:0.6832 val acc:31.68%\n",
            "21/100 train loss:0.2035 train acc:79.40% val loss:0.3817 val acc:61.83%\n",
            "22/100 train loss:0.1997 train acc:79.77% val loss:0.1605 val acc:83.84%\n",
            "23/100 train loss:0.2070 train acc:79.03% val loss:0.3741 val acc:62.59%\n",
            "24/100 train loss:0.1961 train acc:80.13% val loss:0.3330 val acc:66.70%\n",
            "25/100 train loss:0.1902 train acc:80.73% val loss:0.3667 val acc:63.33%\n",
            "26/100 train loss:0.1956 train acc:80.20% val loss:0.1715 val acc:82.85%\n",
            "27/100 train loss:0.2017 train acc:79.60% val loss:0.4033 val acc:59.67%\n",
            "28/100 train loss:0.1945 train acc:80.28% val loss:0.3786 val acc:62.14%\n",
            "29/100 train loss:0.1875 train acc:81.00% val loss:0.4199 val acc:58.01%\n",
            "30/100 train loss:0.1843 train acc:81.32% val loss:0.4220 val acc:57.80%\n",
            "31/100 train loss:0.1796 train acc:81.80% val loss:0.3882 val acc:61.18%\n",
            "32/100 train loss:0.1966 train acc:80.11% val loss:0.3979 val acc:60.21%\n",
            "33/100 train loss:0.1803 train acc:81.72% val loss:0.2056 val acc:79.44%\n",
            "34/100 train loss:0.1939 train acc:80.37% val loss:0.3729 val acc:62.71%\n",
            "35/100 train loss:0.1924 train acc:80.50% val loss:0.3704 val acc:62.96%\n",
            "36/100 train loss:0.1968 train acc:80.03% val loss:0.4461 val acc:55.39%\n",
            "37/100 train loss:0.1863 train acc:81.11% val loss:0.4095 val acc:59.05%\n",
            "38/100 train loss:0.1834 train acc:81.39% val loss:0.3762 val acc:62.38%\n",
            "39/100 train loss:0.1829 train acc:81.47% val loss:0.4179 val acc:58.21%\n",
            "40/100 train loss:0.1917 train acc:80.58% val loss:0.3960 val acc:60.40%\n",
            "41/100 train loss:0.1834 train acc:81.39% val loss:0.4322 val acc:56.78%\n",
            "42/100 train loss:0.1773 train acc:82.03% val loss:0.3866 val acc:61.34%\n",
            "43/100 train loss:0.1759 train acc:82.17% val loss:0.4184 val acc:58.16%\n",
            "44/100 train loss:0.1789 train acc:81.87% val loss:0.4279 val acc:57.21%\n",
            "45/100 train loss:0.1888 train acc:80.87% val loss:0.3357 val acc:66.43%\n",
            "46/100 train loss:0.1945 train acc:80.28% val loss:0.4532 val acc:54.68%\n",
            "47/100 train loss:0.2018 train acc:79.54% val loss:0.6642 val acc:33.58%\n",
            "48/100 train loss:0.1848 train acc:81.25% val loss:0.1790 val acc:82.10%\n",
            "49/100 train loss:0.2229 train acc:77.43% val loss:0.3908 val acc:60.92%\n",
            "50/100 train loss:0.2048 train acc:79.25% val loss:0.3957 val acc:60.43%\n",
            "51/100 train loss:0.2129 train acc:78.46% val loss:0.2188 val acc:78.08%\n",
            "52/100 train loss:0.1987 train acc:79.86% val loss:0.3433 val acc:65.67%\n",
            "53/100 train loss:0.1919 train acc:80.57% val loss:0.2271 val acc:77.29%\n",
            "54/100 train loss:0.2017 train acc:79.58% val loss:0.4541 val acc:54.53%\n",
            "55/100 train loss:0.1912 train acc:80.59% val loss:0.4113 val acc:58.87%\n",
            "56/100 train loss:0.1878 train acc:80.90% val loss:0.4077 val acc:59.23%\n",
            "57/100 train loss:0.1857 train acc:81.18% val loss:0.3328 val acc:66.72%\n",
            "58/100 train loss:0.1786 train acc:81.90% val loss:0.3927 val acc:60.69%\n",
            "59/100 train loss:0.1824 train acc:81.49% val loss:0.3736 val acc:62.46%\n",
            "60/100 train loss:0.2222 train acc:77.47% val loss:0.2802 val acc:71.98%\n",
            "61/100 train loss:0.2050 train acc:79.20% val loss:0.3768 val acc:61.94%\n",
            "62/100 train loss:0.2188 train acc:77.82% val loss:0.2600 val acc:74.00%\n",
            "63/100 train loss:0.2119 train acc:78.53% val loss:0.2855 val acc:71.45%\n",
            "64/100 train loss:0.2148 train acc:78.25% val loss:0.3560 val acc:64.40%\n",
            "65/100 train loss:0.2152 train acc:78.23% val loss:0.3415 val acc:65.29%\n",
            "66/100 train loss:0.2353 train acc:76.19% val loss:0.4991 val acc:50.09%\n",
            "67/100 train loss:0.2266 train acc:77.09% val loss:0.3921 val acc:60.79%\n",
            "68/100 train loss:0.2074 train acc:79.01% val loss:0.3167 val acc:68.33%\n",
            "69/100 train loss:0.2184 train acc:77.92% val loss:0.3600 val acc:64.00%\n",
            "70/100 train loss:0.2021 train acc:79.51% val loss:0.4182 val acc:58.18%\n",
            "71/100 train loss:0.2136 train acc:78.22% val loss:0.4081 val acc:59.19%\n",
            "72/100 train loss:0.2327 train acc:76.42% val loss:0.2989 val acc:70.11%\n",
            "73/100 train loss:0.2374 train acc:75.98% val loss:0.3650 val acc:63.50%\n",
            "74/100 train loss:0.2284 train acc:76.88% val loss:0.3543 val acc:64.44%\n",
            "75/100 train loss:0.2096 train acc:78.79% val loss:0.3111 val acc:68.82%\n",
            "76/100 train loss:0.1978 train acc:79.96% val loss:0.3194 val acc:68.06%\n",
            "77/100 train loss:0.2034 train acc:79.34% val loss:0.3975 val acc:60.25%\n",
            "78/100 train loss:0.1962 train acc:80.10% val loss:0.4048 val acc:59.45%\n",
            "79/100 train loss:0.1975 train acc:79.97% val loss:0.3970 val acc:60.18%\n",
            "80/100 train loss:0.2031 train acc:79.43% val loss:0.2029 val acc:79.71%\n",
            "81/100 train loss:0.2201 train acc:77.75% val loss:0.5985 val acc:40.15%\n",
            "82/100 train loss:0.2002 train acc:79.71% val loss:0.2637 val acc:73.52%\n",
            "83/100 train loss:0.2001 train acc:79.74% val loss:0.3947 val acc:60.53%\n",
            "84/100 train loss:0.1946 train acc:80.29% val loss:0.2098 val acc:79.02%\n",
            "85/100 train loss:0.2000 train acc:79.75% val loss:0.3415 val acc:65.85%\n",
            "86/100 train loss:0.1910 train acc:80.66% val loss:0.3122 val acc:68.78%\n",
            "87/100 train loss:0.2146 train acc:78.26% val loss:0.3599 val acc:64.01%\n",
            "88/100 train loss:0.2182 train acc:77.94% val loss:0.2998 val acc:70.02%\n",
            "89/100 train loss:0.2098 train acc:78.73% val loss:0.4074 val acc:59.19%\n",
            "90/100 train loss:0.2105 train acc:78.69% val loss:0.4074 val acc:59.26%\n",
            "91/100 train loss:0.1966 train acc:80.08% val loss:0.3989 val acc:60.11%\n",
            "92/100 train loss:0.1950 train acc:80.25% val loss:0.3794 val acc:62.06%\n",
            "93/100 train loss:0.2163 train acc:78.12% val loss:0.3378 val acc:66.22%\n",
            "94/100 train loss:0.2142 train acc:78.33% val loss:0.3533 val acc:64.67%\n",
            "95/100 train loss:0.1931 train acc:80.44% val loss:0.5511 val acc:44.89%\n",
            "96/100 train loss:0.1980 train acc:79.97% val loss:0.3146 val acc:68.54%\n",
            "97/100 train loss:0.1863 train acc:81.14% val loss:0.3452 val acc:65.48%\n",
            "98/100 train loss:0.1880 train acc:80.94% val loss:0.4141 val acc:58.59%\n",
            "99/100 train loss:0.1994 train acc:79.78% val loss:0.3433 val acc:65.67%\n",
            "100/100 train loss:0.1932 train acc:80.42% val loss:0.3680 val acc:63.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.load('mbv2_ca.pth')"
      ],
      "metadata": {
        "id": "WRntakusiKf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.features[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNO1IR67myTe",
        "outputId": "49974c91-4e89-4f68-9123-7d058dc390b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MobileV2 pretrained weights"
      ],
      "metadata": {
        "id": "CPDi9dI9iK0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Capacity"
      ],
      "metadata": {
        "id": "pS7s4KZ3Jyu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from models import mbv2_ca\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE/task3/mobile_ca_pretrain'\n",
        "os.makedirs(my_save_path,exist_ok=True)\n",
        "\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        aug=True\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                       \n",
        "                      )\n",
        "model = mbv2_ca(in_c=3, num_classes=1).to(device)\n",
        "\n",
        "weights = torch.load('mbv2_ca.pth')\n",
        "model.load_state_dict(weights, strict=False)\n",
        "pretrained_weights = model.features[0][0].weight\n",
        "model.features[0][0] = nn.Conv2d(4, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "model.features[0][0].weight.data.normal_(0, 0.001)\n",
        "model.features[0][0].weight.data[:, :3, :, :] = pretrained_weights\n",
        "\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              \"mobile-ca{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSweJ5LtiNm8",
        "outputId": "31a5487d-a2d7-414e-8fc5-2c7d477882fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5549 train acc:43.06% val loss:0.4770 val acc:52.30%\n",
            "2/100 train loss:0.4588 train acc:53.89% val loss:0.3632 val acc:63.68%\n",
            "3/100 train loss:0.3950 train acc:60.26% val loss:0.3361 val acc:66.39%\n",
            "4/100 train loss:0.3370 train acc:66.06% val loss:0.5445 val acc:45.55%\n",
            "5/100 train loss:0.2889 train acc:70.88% val loss:0.3780 val acc:62.20%\n",
            "6/100 train loss:0.2498 train acc:74.78% val loss:0.3302 val acc:66.98%\n",
            "7/100 train loss:0.2193 train acc:77.83% val loss:0.3735 val acc:62.65%\n",
            "8/100 train loss:0.1942 train acc:80.35% val loss:0.4059 val acc:59.41%\n",
            "9/100 train loss:0.1778 train acc:81.98% val loss:0.4124 val acc:58.76%\n",
            "10/100 train loss:0.1738 train acc:82.38% val loss:0.4171 val acc:58.29%\n",
            "11/100 train loss:0.1669 train acc:83.08% val loss:0.4141 val acc:58.59%\n",
            "12/100 train loss:0.1601 train acc:83.76% val loss:0.3806 val acc:61.94%\n",
            "13/100 train loss:0.1558 train acc:84.18% val loss:0.4167 val acc:58.33%\n",
            "14/100 train loss:0.1610 train acc:83.66% val loss:0.3405 val acc:65.95%\n",
            "15/100 train loss:0.1558 train acc:84.19% val loss:0.4066 val acc:59.34%\n",
            "16/100 train loss:0.1502 train acc:84.75% val loss:0.2407 val acc:75.93%\n",
            "17/100 train loss:0.1530 train acc:84.46% val loss:0.4328 val acc:56.72%\n",
            "18/100 train loss:0.1509 train acc:84.67% val loss:0.4590 val acc:54.10%\n",
            "19/100 train loss:0.1414 train acc:85.62% val loss:0.4314 val acc:56.86%\n",
            "20/100 train loss:0.1446 train acc:85.30% val loss:0.2903 val acc:70.97%\n",
            "21/100 train loss:0.1431 train acc:85.46% val loss:0.4056 val acc:59.44%\n",
            "22/100 train loss:0.1377 train acc:85.99% val loss:0.4131 val acc:58.69%\n",
            "23/100 train loss:0.1409 train acc:85.67% val loss:0.3866 val acc:61.34%\n",
            "24/100 train loss:0.1296 train acc:86.81% val loss:0.3600 val acc:64.00%\n",
            "25/100 train loss:0.1312 train acc:86.64% val loss:0.3642 val acc:63.58%\n",
            "26/100 train loss:0.1388 train acc:85.88% val loss:0.2915 val acc:70.85%\n",
            "27/100 train loss:0.1289 train acc:86.88% val loss:0.4580 val acc:54.20%\n",
            "28/100 train loss:0.1290 train acc:86.86% val loss:0.3672 val acc:63.28%\n",
            "29/100 train loss:0.1302 train acc:86.75% val loss:0.3940 val acc:60.60%\n",
            "30/100 train loss:0.1278 train acc:86.98% val loss:0.3941 val acc:60.59%\n",
            "31/100 train loss:0.1204 train acc:87.72% val loss:0.3844 val acc:61.56%\n",
            "32/100 train loss:0.1260 train acc:87.16% val loss:0.4314 val acc:56.86%\n",
            "33/100 train loss:0.1165 train acc:88.12% val loss:0.3478 val acc:65.22%\n",
            "34/100 train loss:0.1127 train acc:88.49% val loss:0.3923 val acc:60.77%\n",
            "35/100 train loss:0.1164 train acc:88.12% val loss:0.4054 val acc:59.46%\n",
            "36/100 train loss:0.1248 train acc:87.28% val loss:0.3204 val acc:67.96%\n",
            "37/100 train loss:0.1178 train acc:87.98% val loss:0.4028 val acc:59.72%\n",
            "38/100 train loss:0.1117 train acc:88.59% val loss:0.3990 val acc:60.10%\n",
            "39/100 train loss:0.1077 train acc:88.99% val loss:0.3453 val acc:65.47%\n",
            "40/100 train loss:0.1100 train acc:88.76% val loss:0.4090 val acc:59.10%\n",
            "41/100 train loss:0.1014 train acc:89.62% val loss:0.2506 val acc:74.94%\n",
            "42/100 train loss:0.1031 train acc:89.45% val loss:0.4111 val acc:58.89%\n",
            "43/100 train loss:0.1027 train acc:89.49% val loss:0.4273 val acc:57.27%\n",
            "44/100 train loss:0.1051 train acc:89.25% val loss:0.3547 val acc:64.53%\n",
            "45/100 train loss:0.0997 train acc:89.79% val loss:0.3901 val acc:60.99%\n",
            "46/100 train loss:0.1014 train acc:89.62% val loss:0.4393 val acc:56.07%\n",
            "47/100 train loss:0.1016 train acc:89.60% val loss:0.4310 val acc:56.90%\n",
            "48/100 train loss:0.1003 train acc:89.73% val loss:0.3876 val acc:61.24%\n",
            "49/100 train loss:0.0927 train acc:90.49% val loss:0.2199 val acc:78.01%\n",
            "50/100 train loss:0.0978 train acc:89.98% val loss:0.4233 val acc:57.67%\n",
            "51/100 train loss:0.0890 train acc:90.86% val loss:0.5679 val acc:43.21%\n",
            "52/100 train loss:0.0925 train acc:90.51% val loss:0.3695 val acc:63.05%\n",
            "53/100 train loss:0.0936 train acc:90.41% val loss:0.4277 val acc:57.23%\n",
            "54/100 train loss:0.0936 train acc:90.40% val loss:0.3502 val acc:64.98%\n",
            "55/100 train loss:0.0898 train acc:90.78% val loss:0.3818 val acc:61.82%\n",
            "56/100 train loss:0.0905 train acc:90.71% val loss:0.4192 val acc:58.08%\n",
            "57/100 train loss:0.0903 train acc:90.73% val loss:0.3887 val acc:61.13%\n",
            "58/100 train loss:0.0893 train acc:90.84% val loss:0.3418 val acc:65.82%\n",
            "59/100 train loss:0.0973 train acc:90.03% val loss:0.3442 val acc:65.58%\n",
            "60/100 train loss:0.0898 train acc:90.78% val loss:0.4499 val acc:55.01%\n",
            "61/100 train loss:0.0851 train acc:91.25% val loss:0.3941 val acc:60.59%\n",
            "62/100 train loss:0.0857 train acc:91.19% val loss:0.3701 val acc:62.99%\n",
            "63/100 train loss:0.0821 train acc:91.55% val loss:0.4205 val acc:57.95%\n",
            "64/100 train loss:0.0854 train acc:91.22% val loss:0.3870 val acc:61.30%\n",
            "65/100 train loss:0.0855 train acc:91.22% val loss:0.3933 val acc:60.67%\n",
            "66/100 train loss:0.0821 train acc:91.55% val loss:0.4122 val acc:58.78%\n",
            "67/100 train loss:0.0858 train acc:91.18% val loss:0.3989 val acc:60.11%\n",
            "68/100 train loss:0.0840 train acc:91.36% val loss:0.3862 val acc:61.38%\n",
            "69/100 train loss:0.0796 train acc:91.80% val loss:0.3962 val acc:60.38%\n",
            "70/100 train loss:0.0833 train acc:91.43% val loss:0.4059 val acc:59.41%\n",
            "71/100 train loss:0.0816 train acc:91.60% val loss:0.2922 val acc:70.78%\n",
            "72/100 train loss:0.0767 train acc:92.09% val loss:0.3459 val acc:65.41%\n",
            "73/100 train loss:0.0785 train acc:91.91% val loss:0.4106 val acc:58.94%\n",
            "74/100 train loss:0.0779 train acc:91.98% val loss:0.3813 val acc:61.87%\n",
            "75/100 train loss:0.0770 train acc:92.07% val loss:0.3402 val acc:65.98%\n",
            "76/100 train loss:0.0790 train acc:91.86% val loss:0.3519 val acc:64.81%\n",
            "77/100 train loss:0.0819 train acc:91.57% val loss:0.3356 val acc:66.44%\n",
            "78/100 train loss:0.0753 train acc:92.24% val loss:0.3632 val acc:63.68%\n",
            "79/100 train loss:0.0794 train acc:91.82% val loss:0.4183 val acc:58.17%\n",
            "80/100 train loss:0.0754 train acc:92.22% val loss:0.3620 val acc:63.80%\n",
            "81/100 train loss:0.0802 train acc:91.74% val loss:0.4157 val acc:58.43%\n",
            "82/100 train loss:0.0772 train acc:92.04% val loss:0.4167 val acc:58.33%\n",
            "83/100 train loss:0.0731 train acc:92.46% val loss:0.3747 val acc:62.53%\n",
            "84/100 train loss:0.0724 train acc:92.52% val loss:0.3909 val acc:60.91%\n",
            "85/100 train loss:0.0724 train acc:92.52% val loss:0.3724 val acc:62.76%\n",
            "86/100 train loss:0.0735 train acc:92.42% val loss:0.1778 val acc:82.22%\n",
            "87/100 train loss:0.0770 train acc:92.06% val loss:0.4350 val acc:56.50%\n",
            "88/100 train loss:0.0724 train acc:92.53% val loss:0.3887 val acc:61.13%\n",
            "89/100 train loss:0.0727 train acc:92.49% val loss:0.3372 val acc:66.28%\n",
            "90/100 train loss:0.0791 train acc:91.85% val loss:0.3384 val acc:66.16%\n",
            "91/100 train loss:0.0705 train acc:92.71% val loss:0.3725 val acc:62.75%\n",
            "92/100 train loss:0.0745 train acc:92.31% val loss:0.3676 val acc:63.24%\n",
            "93/100 train loss:0.0732 train acc:92.44% val loss:0.4155 val acc:58.45%\n",
            "94/100 train loss:0.0751 train acc:92.25% val loss:0.3595 val acc:64.05%\n",
            "95/100 train loss:0.0673 train acc:93.03% val loss:0.3819 val acc:61.81%\n",
            "96/100 train loss:0.0708 train acc:92.69% val loss:0.3585 val acc:64.15%\n",
            "97/100 train loss:0.0735 train acc:92.41% val loss:0.3812 val acc:61.88%\n",
            "98/100 train loss:0.0698 train acc:92.79% val loss:0.3805 val acc:61.95%\n",
            "99/100 train loss:0.0707 train acc:92.69% val loss:0.3872 val acc:61.28%\n",
            "100/100 train loss:0.0665 train acc:93.12% val loss:0.3615 val acc:63.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models import mbv2_ca\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE/task3/mobile_ca_pretrain'\n",
        "os.makedirs(my_save_path,exist_ok=True)\n",
        "\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        aug=False\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                       \n",
        "                      )\n",
        "model = mbv2_ca(in_c=3, num_classes=1).to(device)\n",
        "\n",
        "weights = torch.load('mbv2_ca.pth')\n",
        "model.load_state_dict(weights, strict=False)\n",
        "pretrained_weights = model.features[0][0].weight\n",
        "model.features[0][0] = nn.Conv2d(4, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "model.features[0][0].weight.data.normal_(0, 0.001)\n",
        "model.features[0][0].weight.data[:, :3, :, :] = pretrained_weights\n",
        "\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  # if correct_val > best_acc:\n",
        "  #   best_acc = correct_val\n",
        "  #   torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "  #                                             \"mobile-ca{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96xcXlahuB53",
        "outputId": "159d9212-87df-4106-ebe9-d0baa79d498e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5191 train acc:47.29% val loss:0.4214 val acc:57.86%\n",
            "2/100 train loss:0.3619 train acc:63.57% val loss:0.4953 val acc:50.47%\n",
            "3/100 train loss:0.2869 train acc:71.07% val loss:0.4049 val acc:59.51%\n",
            "4/100 train loss:0.2364 train acc:76.13% val loss:0.4278 val acc:57.22%\n",
            "5/100 train loss:0.1912 train acc:80.65% val loss:0.4136 val acc:58.64%\n",
            "6/100 train loss:0.1400 train acc:85.76% val loss:0.3892 val acc:61.08%\n",
            "7/100 train loss:0.1176 train acc:88.01% val loss:0.4462 val acc:55.38%\n",
            "8/100 train loss:0.1159 train acc:88.18% val loss:0.4038 val acc:59.62%\n",
            "9/100 train loss:0.1003 train acc:89.73% val loss:0.4520 val acc:54.80%\n",
            "10/100 train loss:0.1032 train acc:89.44% val loss:0.4278 val acc:57.22%\n",
            "11/100 train loss:0.0978 train acc:89.98% val loss:0.4825 val acc:51.75%\n",
            "12/100 train loss:0.0941 train acc:90.35% val loss:0.4588 val acc:54.12%\n",
            "13/100 train loss:0.0936 train acc:90.40% val loss:0.4088 val acc:59.12%\n",
            "14/100 train loss:0.0966 train acc:90.10% val loss:0.4415 val acc:55.85%\n",
            "15/100 train loss:0.0893 train acc:90.84% val loss:0.4531 val acc:54.69%\n",
            "16/100 train loss:0.0853 train acc:91.23% val loss:0.4765 val acc:52.35%\n",
            "17/100 train loss:0.0816 train acc:91.60% val loss:0.4409 val acc:55.91%\n",
            "18/100 train loss:0.0749 train acc:92.27% val loss:0.4680 val acc:53.20%\n",
            "19/100 train loss:0.0741 train acc:92.35% val loss:0.4466 val acc:55.34%\n",
            "20/100 train loss:0.0703 train acc:92.73% val loss:0.4581 val acc:54.19%\n",
            "21/100 train loss:0.0714 train acc:92.63% val loss:0.4363 val acc:56.37%\n",
            "22/100 train loss:0.0656 train acc:93.20% val loss:0.4701 val acc:52.99%\n",
            "23/100 train loss:0.0702 train acc:92.74% val loss:0.4339 val acc:56.61%\n",
            "24/100 train loss:0.0710 train acc:92.66% val loss:0.4514 val acc:54.86%\n",
            "25/100 train loss:0.0634 train acc:93.43% val loss:0.4310 val acc:56.90%\n",
            "26/100 train loss:0.0588 train acc:93.88% val loss:0.4391 val acc:56.09%\n",
            "27/100 train loss:0.0592 train acc:93.84% val loss:0.4420 val acc:55.80%\n",
            "28/100 train loss:0.0563 train acc:94.13% val loss:0.4592 val acc:54.08%\n",
            "29/100 train loss:0.0604 train acc:93.72% val loss:0.4673 val acc:53.27%\n",
            "30/100 train loss:0.0548 train acc:94.28% val loss:0.4611 val acc:53.89%\n",
            "31/100 train loss:0.0548 train acc:94.28% val loss:0.4284 val acc:57.16%\n",
            "32/100 train loss:0.0594 train acc:93.83% val loss:0.4131 val acc:58.69%\n",
            "33/100 train loss:0.0606 train acc:93.71% val loss:0.4223 val acc:57.77%\n",
            "34/100 train loss:0.0587 train acc:93.89% val loss:0.4628 val acc:53.72%\n",
            "35/100 train loss:0.0570 train acc:94.06% val loss:0.4247 val acc:57.53%\n",
            "36/100 train loss:0.0545 train acc:94.31% val loss:0.4561 val acc:54.39%\n",
            "37/100 train loss:0.0595 train acc:93.81% val loss:0.4428 val acc:55.72%\n",
            "38/100 train loss:0.0517 train acc:94.59% val loss:0.4570 val acc:54.30%\n",
            "39/100 train loss:0.0534 train acc:94.43% val loss:0.3870 val acc:61.30%\n",
            "40/100 train loss:0.0552 train acc:94.24% val loss:0.4284 val acc:57.16%\n",
            "41/100 train loss:0.0543 train acc:94.33% val loss:0.4557 val acc:54.43%\n",
            "42/100 train loss:0.0475 train acc:95.01% val loss:0.4640 val acc:53.60%\n",
            "43/100 train loss:0.0511 train acc:94.66% val loss:0.4338 val acc:56.62%\n",
            "44/100 train loss:0.0483 train acc:94.93% val loss:0.4135 val acc:58.65%\n",
            "45/100 train loss:0.0494 train acc:94.82% val loss:0.4297 val acc:57.03%\n",
            "46/100 train loss:0.0527 train acc:94.49% val loss:0.4552 val acc:54.48%\n",
            "47/100 train loss:0.0517 train acc:94.59% val loss:0.4533 val acc:54.67%\n",
            "48/100 train loss:0.0511 train acc:94.65% val loss:0.4391 val acc:56.09%\n",
            "49/100 train loss:0.0477 train acc:94.99% val loss:0.4034 val acc:59.66%\n",
            "50/100 train loss:0.0444 train acc:95.32% val loss:0.4695 val acc:53.05%\n",
            "51/100 train loss:0.0469 train acc:95.07% val loss:0.4639 val acc:53.61%\n",
            "52/100 train loss:0.0478 train acc:94.98% val loss:0.4185 val acc:58.15%\n",
            "53/100 train loss:0.0471 train acc:95.06% val loss:0.4399 val acc:56.01%\n",
            "54/100 train loss:0.0451 train acc:95.26% val loss:0.4328 val acc:56.72%\n",
            "55/100 train loss:0.0438 train acc:95.38% val loss:0.4502 val acc:54.98%\n",
            "56/100 train loss:0.0400 train acc:95.76% val loss:0.4268 val acc:57.32%\n",
            "57/100 train loss:0.0437 train acc:95.39% val loss:0.4402 val acc:55.98%\n",
            "58/100 train loss:0.0422 train acc:95.54% val loss:0.4250 val acc:57.50%\n",
            "59/100 train loss:0.0439 train acc:95.38% val loss:0.3372 val acc:66.28%\n",
            "60/100 train loss:0.0496 train acc:94.80% val loss:0.4016 val acc:59.84%\n",
            "61/100 train loss:0.0522 train acc:94.54% val loss:0.3947 val acc:60.53%\n",
            "62/100 train loss:0.0494 train acc:94.82% val loss:0.3885 val acc:61.15%\n",
            "63/100 train loss:0.0470 train acc:95.06% val loss:0.4711 val acc:52.89%\n",
            "64/100 train loss:0.0450 train acc:95.27% val loss:0.4117 val acc:58.83%\n",
            "65/100 train loss:0.0433 train acc:95.43% val loss:0.3994 val acc:60.06%\n",
            "66/100 train loss:0.0407 train acc:95.69% val loss:0.4140 val acc:58.60%\n",
            "67/100 train loss:0.0449 train acc:95.27% val loss:0.4008 val acc:59.92%\n",
            "68/100 train loss:0.0482 train acc:94.94% val loss:0.4018 val acc:59.82%\n",
            "69/100 train loss:0.0463 train acc:95.14% val loss:0.3859 val acc:61.41%\n",
            "70/100 train loss:0.0481 train acc:94.95% val loss:0.4669 val acc:53.31%\n",
            "71/100 train loss:0.0457 train acc:95.19% val loss:0.4493 val acc:55.07%\n",
            "72/100 train loss:0.0442 train acc:95.35% val loss:0.4607 val acc:53.93%\n",
            "73/100 train loss:0.0462 train acc:95.15% val loss:0.4305 val acc:56.95%\n",
            "74/100 train loss:0.0432 train acc:95.44% val loss:0.4438 val acc:55.62%\n",
            "75/100 train loss:0.0439 train acc:95.37% val loss:0.4309 val acc:56.91%\n",
            "76/100 train loss:0.0400 train acc:95.77% val loss:0.4344 val acc:56.56%\n",
            "77/100 train loss:0.0419 train acc:95.57% val loss:0.4394 val acc:56.06%\n",
            "78/100 train loss:0.0374 train acc:96.02% val loss:0.4035 val acc:59.65%\n",
            "79/100 train loss:0.0439 train acc:95.37% val loss:0.4297 val acc:57.03%\n",
            "80/100 train loss:0.0424 train acc:95.52% val loss:0.4185 val acc:58.15%\n",
            "81/100 train loss:0.0387 train acc:95.89% val loss:0.4002 val acc:59.98%\n",
            "82/100 train loss:0.0403 train acc:95.73% val loss:0.3896 val acc:61.04%\n",
            "83/100 train loss:0.0439 train acc:95.37% val loss:0.4443 val acc:55.57%\n",
            "84/100 train loss:0.0416 train acc:95.60% val loss:0.4087 val acc:59.13%\n",
            "85/100 train loss:0.0379 train acc:95.97% val loss:0.4275 val acc:57.25%\n",
            "86/100 train loss:0.0394 train acc:95.83% val loss:0.4034 val acc:59.66%\n",
            "87/100 train loss:0.0416 train acc:95.60% val loss:0.3909 val acc:60.91%\n",
            "88/100 train loss:0.0485 train acc:94.92% val loss:0.3989 val acc:60.11%\n",
            "89/100 train loss:0.0405 train acc:95.71% val loss:0.4139 val acc:58.61%\n",
            "90/100 train loss:0.0451 train acc:95.25% val loss:0.4417 val acc:55.83%\n",
            "91/100 train loss:0.0469 train acc:95.07% val loss:0.4610 val acc:53.90%\n",
            "92/100 train loss:0.0438 train acc:95.39% val loss:0.4636 val acc:53.64%\n",
            "93/100 train loss:0.0427 train acc:95.50% val loss:0.4483 val acc:55.17%\n",
            "94/100 train loss:0.0404 train acc:95.73% val loss:0.4433 val acc:55.67%\n",
            "95/100 train loss:0.0381 train acc:95.96% val loss:0.4131 val acc:58.69%\n",
            "96/100 train loss:0.0392 train acc:95.85% val loss:0.4295 val acc:57.05%\n",
            "97/100 train loss:0.0356 train acc:96.20% val loss:0.4615 val acc:53.85%\n",
            "98/100 train loss:0.0381 train acc:95.95% val loss:0.4480 val acc:55.20%\n",
            "99/100 train loss:0.0378 train acc:95.98% val loss:0.3902 val acc:60.98%\n",
            "100/100 train loss:0.0392 train acc:95.84% val loss:0.4147 val acc:58.53%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def computeScoreType1(gt, _est):\n",
        "  gt = gt.cpu().data.numpy()\n",
        "  _est = _est.cpu().data.numpy()\n",
        "  est = copy.deepcopy(_est)\n",
        "  assert (len(gt) == len(est))\n",
        "  # if all(x == -1 for x in est):\n",
        "  #   return 0\n",
        "  indicator_f = est > -1\n",
        "  ec = np.exp(-(np.abs(gt - est) / gt)) * indicator_f\n",
        "  score = np.sum(ec) / len(gt)\n",
        "  return score\n",
        "\n",
        "def myLoss(est, gt):\n",
        "  ec = 1 - torch.exp(-(torch.abs(gt - est) / gt))\n",
        "  score = torch.sum(ec) / len(gt)\n",
        "\n",
        "  return score\n",
        "\n",
        "def train_image(model, train_loader, optimizer, device, criterion = nn.L1Loss()):\n",
        "  model.train()\n",
        "  loss_train = 0.0\n",
        "  correct_train = 0.0\n",
        "  num_train = len(train_loader)\n",
        "  for batch_idx, (audio, target) in enumerate(train_loader):\n",
        "    audio = audio.to(device)\n",
        "    target = target.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model.forward(audio)\n",
        "    loss = criterion(outputs, target)\n",
        "    loss.backward()\n",
        "    #nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_train += loss.item() * audio.shape[0]\n",
        "    correct_train += computeScoreType1(target, outputs) * audio.shape[0]\n",
        "\n",
        "    \n",
        "    \n",
        "  \n",
        "  return loss_train, correct_train\n",
        "\n",
        "\n",
        "def evaluate_image(model, testloader, device, criterion = nn.L1Loss()):\n",
        "  model.eval()\n",
        "  loss_test = 0\n",
        "  correct_test=0\n",
        "  num_val = len(testloader)\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (audio, target) in enumerate(testloader):\n",
        "      audio = audio.to(device)\n",
        "      target = target.to(device)\n",
        "      outputs = model.forward(audio)\n",
        "      loss = criterion(outputs, target)\n",
        "      loss_test += loss.item() * audio.shape[0]\n",
        "      correct_test += computeScoreType1(target, outputs) * audio.shape[0]\n",
        "  return loss_test, correct_test\n",
        "\n"
      ],
      "metadata": {
        "id": "5Nesx3FeK8R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models import mbv2_ca\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE/task5/mobile_ca_pretrain'\n",
        "os.makedirs(my_save_path,exist_ok=True)\n",
        "\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 5e-4\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        aug=True,\n",
        "                        label_name=['width at the top', 'width at the bottom', 'height']\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                      label_name=['width at the top', 'width at the bottom', 'height']\n",
        "                      )\n",
        "model = mbv2_ca(in_c=3, num_classes=3).to(device)\n",
        "\n",
        "weights = torch.load('mbv2_ca.pth')\n",
        "model.load_state_dict(weights, strict=False)\n",
        "pretrained_weights = model.features[0][0].weight\n",
        "model.features[0][0] = nn.Conv2d(4, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "model.features[0][0].weight.data.normal_(0, 0.001)\n",
        "model.features[0][0].weight.data[:, :3, :, :] = pretrained_weights\n",
        "\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, 1/3 * loss_train/num_train, 1/3 * 100 * correct_train/num_train,\n",
        "      1/3 * loss_val/num_val, 1/3 * 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              \"mobile-ca{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5MwFfEboARi",
        "outputId": "85c316eb-6b07-4d49-f026-eacb34b28a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5191 train acc:47.74% val loss:0.3703 val acc:62.97%\n",
            "2/100 train loss:0.3801 train acc:61.75% val loss:0.1942 val acc:80.58%\n",
            "3/100 train loss:0.3148 train acc:68.28% val loss:0.1948 val acc:80.52%\n",
            "4/100 train loss:0.2495 train acc:74.81% val loss:0.2460 val acc:75.40%\n",
            "5/100 train loss:0.1953 train acc:80.24% val loss:0.2543 val acc:74.57%\n",
            "6/100 train loss:0.1549 train acc:84.27% val loss:0.1505 val acc:84.95%\n",
            "7/100 train loss:0.1448 train acc:85.28% val loss:0.2035 val acc:79.65%\n",
            "8/100 train loss:0.1432 train acc:85.45% val loss:0.1455 val acc:85.45%\n",
            "9/100 train loss:0.1411 train acc:85.65% val loss:0.2312 val acc:76.88%\n",
            "10/100 train loss:0.1365 train acc:86.11% val loss:0.2112 val acc:78.88%\n",
            "11/100 train loss:0.1275 train acc:87.01% val loss:0.2316 val acc:76.84%\n",
            "12/100 train loss:0.1295 train acc:86.81% val loss:0.1937 val acc:80.63%\n",
            "13/100 train loss:0.1273 train acc:87.04% val loss:0.2103 val acc:78.97%\n",
            "14/100 train loss:0.1235 train acc:87.41% val loss:0.1881 val acc:81.19%\n",
            "15/100 train loss:0.1242 train acc:87.35% val loss:0.1772 val acc:82.28%\n",
            "16/100 train loss:0.1236 train acc:87.41% val loss:0.2344 val acc:76.56%\n",
            "17/100 train loss:0.1214 train acc:87.62% val loss:0.2058 val acc:79.42%\n",
            "18/100 train loss:0.1189 train acc:87.87% val loss:0.1736 val acc:82.64%\n",
            "19/100 train loss:0.1153 train acc:88.23% val loss:0.1843 val acc:81.57%\n",
            "20/100 train loss:0.1123 train acc:88.53% val loss:0.1736 val acc:82.64%\n",
            "21/100 train loss:0.1050 train acc:89.27% val loss:0.2534 val acc:74.66%\n",
            "22/100 train loss:0.0985 train acc:89.91% val loss:0.1754 val acc:82.46%\n",
            "23/100 train loss:0.0966 train acc:90.11% val loss:0.1754 val acc:82.46%\n",
            "24/100 train loss:0.0976 train acc:90.00% val loss:0.2119 val acc:78.81%\n",
            "25/100 train loss:0.0904 train acc:90.72% val loss:0.1829 val acc:81.71%\n",
            "26/100 train loss:0.0876 train acc:91.00% val loss:0.2065 val acc:79.35%\n",
            "27/100 train loss:0.0883 train acc:90.94% val loss:0.1911 val acc:80.89%\n",
            "28/100 train loss:0.0801 train acc:91.75% val loss:0.1934 val acc:80.66%\n",
            "29/100 train loss:0.0773 train acc:92.04% val loss:0.1595 val acc:84.05%\n",
            "30/100 train loss:0.0780 train acc:91.96% val loss:0.1756 val acc:82.44%\n",
            "31/100 train loss:0.0756 train acc:92.20% val loss:0.1583 val acc:84.17%\n",
            "32/100 train loss:0.0756 train acc:92.20% val loss:0.1845 val acc:81.55%\n",
            "33/100 train loss:0.0734 train acc:92.43% val loss:0.1935 val acc:80.65%\n",
            "34/100 train loss:0.0734 train acc:92.42% val loss:0.1998 val acc:80.02%\n",
            "35/100 train loss:0.0751 train acc:92.25% val loss:0.1754 val acc:82.46%\n",
            "36/100 train loss:0.0727 train acc:92.49% val loss:0.1718 val acc:82.82%\n",
            "37/100 train loss:0.0687 train acc:92.90% val loss:0.1940 val acc:80.60%\n",
            "38/100 train loss:0.0676 train acc:93.00% val loss:0.1783 val acc:82.17%\n",
            "39/100 train loss:0.0671 train acc:93.06% val loss:0.1848 val acc:81.52%\n",
            "40/100 train loss:0.0661 train acc:93.15% val loss:0.1823 val acc:81.77%\n",
            "41/100 train loss:0.0656 train acc:93.21% val loss:0.1786 val acc:82.14%\n",
            "42/100 train loss:0.0628 train acc:93.48% val loss:0.1878 val acc:81.22%\n",
            "43/100 train loss:0.0644 train acc:93.32% val loss:0.1927 val acc:80.73%\n",
            "44/100 train loss:0.0646 train acc:93.30% val loss:0.1910 val acc:80.90%\n",
            "45/100 train loss:0.0633 train acc:93.43% val loss:0.1883 val acc:81.17%\n",
            "46/100 train loss:0.0606 train acc:93.71% val loss:0.1761 val acc:82.39%\n",
            "47/100 train loss:0.0577 train acc:94.00% val loss:0.1694 val acc:83.06%\n",
            "48/100 train loss:0.0610 train acc:93.66% val loss:0.1638 val acc:83.62%\n",
            "49/100 train loss:0.0575 train acc:94.01% val loss:0.1848 val acc:81.52%\n",
            "50/100 train loss:0.0564 train acc:94.12% val loss:0.1899 val acc:81.01%\n",
            "51/100 train loss:0.0559 train acc:94.18% val loss:0.1790 val acc:82.10%\n",
            "52/100 train loss:0.0572 train acc:94.04% val loss:0.1656 val acc:83.44%\n",
            "53/100 train loss:0.0534 train acc:94.42% val loss:0.1786 val acc:82.14%\n",
            "54/100 train loss:0.0530 train acc:94.47% val loss:0.1745 val acc:82.55%\n",
            "55/100 train loss:0.0557 train acc:94.19% val loss:0.1896 val acc:81.04%\n",
            "56/100 train loss:0.0521 train acc:94.55% val loss:0.1907 val acc:80.93%\n",
            "57/100 train loss:0.0542 train acc:94.34% val loss:0.1760 val acc:82.40%\n",
            "58/100 train loss:0.0520 train acc:94.57% val loss:0.1901 val acc:80.99%\n",
            "59/100 train loss:0.0540 train acc:94.36% val loss:0.1805 val acc:81.95%\n",
            "60/100 train loss:0.0502 train acc:94.74% val loss:0.1937 val acc:80.63%\n",
            "61/100 train loss:0.0507 train acc:94.69% val loss:0.1773 val acc:82.27%\n",
            "62/100 train loss:0.0505 train acc:94.71% val loss:0.2085 val acc:79.15%\n",
            "63/100 train loss:0.0502 train acc:94.74% val loss:0.1926 val acc:80.74%\n",
            "64/100 train loss:0.0493 train acc:94.84% val loss:0.1887 val acc:81.13%\n",
            "65/100 train loss:0.0492 train acc:94.84% val loss:0.1748 val acc:82.52%\n",
            "66/100 train loss:0.0497 train acc:94.79% val loss:0.1863 val acc:81.37%\n",
            "67/100 train loss:0.0485 train acc:94.91% val loss:0.1932 val acc:80.68%\n",
            "68/100 train loss:0.0486 train acc:94.90% val loss:0.1935 val acc:80.65%\n",
            "69/100 train loss:0.0465 train acc:95.12% val loss:0.1870 val acc:81.30%\n",
            "70/100 train loss:0.0478 train acc:94.98% val loss:0.1748 val acc:82.52%\n",
            "71/100 train loss:0.0466 train acc:95.10% val loss:0.1872 val acc:81.28%\n",
            "72/100 train loss:0.0456 train acc:95.20% val loss:0.1847 val acc:81.53%\n",
            "73/100 train loss:0.0489 train acc:94.87% val loss:0.1798 val acc:82.02%\n",
            "74/100 train loss:0.0440 train acc:95.36% val loss:0.2025 val acc:79.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75/100 train loss:0.0441 train acc:95.35% val loss:0.1960 val acc:80.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/100 train loss:0.0438 train acc:95.39% val loss:0.1575 val acc:84.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "77/100 train loss:0.0455 train acc:95.21% val loss:0.1782 val acc:82.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78/100 train loss:0.0422 train acc:95.54% val loss:0.1924 val acc:80.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/100 train loss:0.0450 train acc:95.26% val loss:0.1798 val acc:82.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/100 train loss:0.0428 train acc:95.49% val loss:0.1841 val acc:81.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81/100 train loss:0.0416 train acc:95.60% val loss:0.1984 val acc:80.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82/100 train loss:0.0405 train acc:95.71% val loss:0.1802 val acc:81.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83/100 train loss:0.0414 train acc:95.63% val loss:0.1854 val acc:81.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84/100 train loss:0.0428 train acc:95.49% val loss:0.1776 val acc:82.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85/100 train loss:0.0455 train acc:95.21% val loss:0.1666 val acc:83.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "86/100 train loss:0.0430 train acc:95.47% val loss:0.1573 val acc:84.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87/100 train loss:0.0455 train acc:95.21% val loss:0.1785 val acc:82.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88/100 train loss:0.0426 train acc:95.50% val loss:0.2001 val acc:79.99%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89/100 train loss:0.0409 train acc:95.67% val loss:0.2002 val acc:79.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/100 train loss:0.0441 train acc:95.36% val loss:0.1637 val acc:83.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91/100 train loss:0.0461 train acc:95.16% val loss:0.1951 val acc:80.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92/100 train loss:0.0484 train acc:94.92% val loss:0.1847 val acc:81.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93/100 train loss:0.0444 train acc:95.32% val loss:0.1776 val acc:82.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/100 train loss:0.0415 train acc:95.61% val loss:0.1839 val acc:81.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95/100 train loss:0.0418 train acc:95.58% val loss:0.1959 val acc:80.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96/100 train loss:0.0430 train acc:95.46% val loss:0.1787 val acc:82.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97/100 train loss:0.0411 train acc:95.65% val loss:0.1913 val acc:80.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/100 train loss:0.0383 train acc:95.94% val loss:0.1682 val acc:83.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99/100 train loss:0.0394 train acc:95.82% val loss:0.1980 val acc:80.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62eed2f680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 train loss:0.0415 train acc:95.62% val loss:0.1757 val acc:82.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models import mbv2_ca\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE/task5/mobile_ca_pretrain'\n",
        "os.makedirs(my_save_path,exist_ok=True)\n",
        "\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 5e-4\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        aug=True,\n",
        "                        label_name=['width at the top', 'width at the bottom', 'height']\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                      label_name=['width at the top', 'width at the bottom', 'height']\n",
        "                      )\n",
        "model = mbv2_ca(in_c=3, num_classes=3).to(device)\n",
        "\n",
        "weights = torch.load('mbv2_ca.pth')\n",
        "model.load_state_dict(weights, strict=False)\n",
        "pretrained_weights = model.features[0][0].weight\n",
        "model.features[0][0] = nn.Conv2d(4, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "model.features[0][0].weight.data.normal_(0, 0.001)\n",
        "model.features[0][0].weight.data[:, :3, :, :] = pretrained_weights\n",
        "\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, 1/3 * loss_train/num_train, 1/3 * 100 * correct_train/num_train,\n",
        "      1/3 * loss_val/num_val, 1/3 * 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              \"mobile-ca{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ],
      "metadata": {
        "id": "915Yu7hdKd6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models import mbv2_ca\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE/task4/mobile_ca_pretrain'\n",
        "os.makedirs(my_save_path,exist_ok=True)\n",
        "\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        aug=True,\n",
        "                        label_name=['container mass']\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                      label_name=['container mass']\n",
        "                       \n",
        "                      )\n",
        "model = mbv2_ca(in_c=3, num_classes=1).to(device)\n",
        "\n",
        "weights = torch.load('mbv2_ca.pth')\n",
        "model.load_state_dict(weights, strict=False)\n",
        "pretrained_weights = model.features[0][0].weight\n",
        "model.features[0][0] = nn.Conv2d(4, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "model.features[0][0].weight.data.normal_(0, 0.001)\n",
        "model.features[0][0].weight.data[:, :3, :, :] = pretrained_weights\n",
        "\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=2,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              \"mobile-ca{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ],
      "metadata": {
        "id": "B0nsAdwDqHzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dimension for capacity"
      ],
      "metadata": {
        "id": "xS9sne-VAyMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TkB3WE6WEebW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MBV2_CA_dimen(nn.Module):\n",
        "    def __init__(self, dimension, in_c=4, num_classes=1, width_mult=1.):\n",
        "        super(MBV2_CA_dimen, self).__init__()\n",
        "        # setting of inverted residual blocks\n",
        "        self.cfgs = [\n",
        "            # t, c, n, s\n",
        "            [1,  16, 1, 1],\n",
        "            [6,  24, 2, 2],\n",
        "            [6,  32, 3, 2],\n",
        "            [6,  64, 4, 2],\n",
        "            [6,  96, 3, 1],\n",
        "            [6, 160, 3, 2],\n",
        "            [6, 320, 1, 1],\n",
        "        ]\n",
        "\n",
        "        # building first layer\n",
        "        input_channel = _make_divisible(32 * width_mult, 4 if width_mult == 0.1 else 8)\n",
        "        layers = [conv_3x3_bn(in_c, input_channel, 2)]\n",
        "        # building inverted residual blocks\n",
        "        block = InvertedResidual\n",
        "        for t, c, n, s in self.cfgs:\n",
        "            output_channel = _make_divisible(c * width_mult, 4 if width_mult == 0.1 else 8)\n",
        "            for i in range(n):\n",
        "                layers.append(block(input_channel, output_channel, s if i == 0 else 1, t))\n",
        "                input_channel = output_channel\n",
        "        self.features = nn.Sequential(*layers)\n",
        "        # building last several layers\n",
        "        output_channel = _make_divisible(1280 * width_mult, 4 if width_mult == 0.1 else 8) if width_mult > 1.0 else 1280\n",
        "        self.conv = conv_1x1_bn(input_channel, output_channel)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier1 = nn.Sequential(\n",
        "                nn.Dropout(0.1),\n",
        "                nn.Linear(output_channel+3, num_classes)\n",
        "                )\n",
        "\n",
        "        self._initialize_weights()\n",
        "        \n",
        "        self.dimension = dimension\n",
        "\n",
        "    def forward(self, x):\n",
        "        dimensions = self.dimension(x)\n",
        "        x = self.features(x)\n",
        "        \n",
        "        x = self.conv(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.cat((x, dimensions), dim=1)\n",
        "\n",
        "        x = self.classifier1(x)\n",
        "\n",
        "        return x\n",
        "    \n",
        "    def extract(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.avgpool(x)\n",
        "        feature = x.view(x.size(0), -1)\n",
        "        x = self.classifier(feature)\n",
        "\n",
        "        return feature, x\n",
        "\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            #print(m)\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                #print(m.weight.size())\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "                m.bias.data.zero_()"
      ],
      "metadata": {
        "id": "ndbCbyj5qo54"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models import mbv2_ca\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE/task3/dimension_trans'\n",
        "os.makedirs(my_save_path,exist_ok=True)\n",
        "\n",
        "bs = 10\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        aug=True\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                       \n",
        "                      )\n",
        "dimension = mbv2_ca(in_c=4, num_classes=3)\n",
        "dimension.load_state_dict(torch.load('/content/drive/MyDrive/COSRMAL_CHALLENGE/task5/mobile_ca_pretrain/mobile-ca256.63.pth'))\n",
        "model = MBV2_CA_dimen(dimension, in_c=4, num_classes=1)\n",
        "\n",
        "for param in model.dimension.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "p_to = '/content/drive/MyDrive/COSRMAL_CHALLENGE/task3/mobile_ca_pretrain/mobile-ca82.22.pth'\n",
        "model.load_state_dict(torch.load(p_to), strict=False)\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              \"mobile-ca{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ],
      "metadata": {
        "id": "i0YmK2a7Bdux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc0c1b0-7e1d-42f3-f635-294e892eabc8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.4332 train acc:56.43% val loss:0.5024 val acc:49.76%\n",
            "2/100 train loss:0.2397 train acc:75.79% val loss:0.3770 val acc:62.30%\n",
            "3/100 train loss:0.2042 train acc:79.34% val loss:0.3255 val acc:67.45%\n",
            "4/100 train loss:0.1960 train acc:80.17% val loss:0.4310 val acc:56.90%\n",
            "5/100 train loss:0.1841 train acc:81.35% val loss:0.4596 val acc:54.04%\n",
            "6/100 train loss:0.1681 train acc:82.95% val loss:0.4172 val acc:58.28%\n",
            "7/100 train loss:0.1650 train acc:83.26% val loss:0.3691 val acc:63.09%\n",
            "8/100 train loss:0.1580 train acc:83.97% val loss:0.4113 val acc:58.87%\n",
            "9/100 train loss:0.1497 train acc:84.79% val loss:0.4202 val acc:57.98%\n",
            "10/100 train loss:0.1433 train acc:85.44% val loss:0.3437 val acc:65.63%\n",
            "11/100 train loss:0.1413 train acc:85.63% val loss:0.3409 val acc:65.91%\n",
            "12/100 train loss:0.1378 train acc:85.98% val loss:0.4311 val acc:56.89%\n",
            "13/100 train loss:0.1327 train acc:86.49% val loss:0.4313 val acc:56.87%\n",
            "14/100 train loss:0.1315 train acc:86.62% val loss:0.3382 val acc:66.18%\n",
            "15/100 train loss:0.1285 train acc:86.91% val loss:0.3612 val acc:63.88%\n",
            "16/100 train loss:0.1253 train acc:87.23% val loss:0.4190 val acc:58.10%\n",
            "17/100 train loss:0.1312 train acc:86.64% val loss:0.3350 val acc:66.50%\n",
            "18/100 train loss:0.1228 train acc:87.48% val loss:0.3383 val acc:66.17%\n",
            "19/100 train loss:0.1201 train acc:87.76% val loss:0.3918 val acc:60.82%\n",
            "20/100 train loss:0.1233 train acc:87.44% val loss:0.2913 val acc:70.87%\n",
            "21/100 train loss:0.1189 train acc:87.87% val loss:0.4363 val acc:56.37%\n",
            "22/100 train loss:0.1145 train acc:88.31% val loss:0.3750 val acc:62.50%\n",
            "23/100 train loss:0.1165 train acc:88.11% val loss:0.3659 val acc:63.41%\n",
            "24/100 train loss:0.1187 train acc:87.90% val loss:0.3467 val acc:65.33%\n",
            "25/100 train loss:0.1135 train acc:88.41% val loss:0.3560 val acc:64.40%\n",
            "26/100 train loss:0.1105 train acc:88.72% val loss:0.3876 val acc:61.24%\n",
            "27/100 train loss:0.1088 train acc:88.88% val loss:0.3736 val acc:62.64%\n",
            "28/100 train loss:0.1100 train acc:88.77% val loss:0.3627 val acc:63.73%\n",
            "29/100 train loss:0.1062 train acc:89.14% val loss:0.4494 val acc:55.06%\n",
            "30/100 train loss:0.1036 train acc:89.40% val loss:0.3841 val acc:61.59%\n",
            "31/100 train loss:0.0973 train acc:90.03% val loss:0.3873 val acc:61.27%\n",
            "32/100 train loss:0.1029 train acc:89.47% val loss:0.3995 val acc:60.05%\n",
            "33/100 train loss:0.1022 train acc:89.54% val loss:0.4178 val acc:58.22%\n",
            "34/100 train loss:0.1002 train acc:89.74% val loss:0.4254 val acc:57.46%\n",
            "35/100 train loss:0.0973 train acc:90.03% val loss:0.3741 val acc:62.59%\n",
            "36/100 train loss:0.0970 train acc:90.06% val loss:0.3920 val acc:60.80%\n",
            "37/100 train loss:0.0998 train acc:89.78% val loss:0.3905 val acc:60.95%\n",
            "38/100 train loss:0.0982 train acc:89.94% val loss:0.3663 val acc:63.37%\n",
            "39/100 train loss:0.0999 train acc:89.77% val loss:0.3874 val acc:61.26%\n",
            "40/100 train loss:0.0988 train acc:89.89% val loss:0.4214 val acc:57.86%\n",
            "41/100 train loss:0.0946 train acc:90.31% val loss:0.3560 val acc:64.40%\n",
            "42/100 train loss:0.0962 train acc:90.14% val loss:0.4427 val acc:55.73%\n",
            "43/100 train loss:0.0923 train acc:90.53% val loss:0.4244 val acc:57.56%\n",
            "44/100 train loss:0.0936 train acc:90.41% val loss:0.3752 val acc:62.48%\n",
            "45/100 train loss:0.0904 train acc:90.72% val loss:0.4106 val acc:58.94%\n",
            "46/100 train loss:0.0920 train acc:90.57% val loss:0.4288 val acc:57.12%\n",
            "47/100 train loss:0.0993 train acc:89.83% val loss:0.4491 val acc:55.09%\n",
            "48/100 train loss:0.0946 train acc:90.30% val loss:0.4462 val acc:55.38%\n",
            "49/100 train loss:0.0938 train acc:90.38% val loss:0.3478 val acc:65.22%\n",
            "50/100 train loss:0.0866 train acc:91.11% val loss:0.4837 val acc:51.63%\n",
            "51/100 train loss:0.0878 train acc:90.98% val loss:0.3681 val acc:63.19%\n",
            "52/100 train loss:0.0866 train acc:91.10% val loss:0.4180 val acc:58.20%\n",
            "53/100 train loss:0.0846 train acc:91.30% val loss:0.3901 val acc:60.99%\n",
            "54/100 train loss:0.0939 train acc:90.37% val loss:0.4095 val acc:59.05%\n",
            "55/100 train loss:0.0864 train acc:91.12% val loss:0.3978 val acc:60.22%\n",
            "56/100 train loss:0.0892 train acc:90.84% val loss:0.3977 val acc:60.23%\n",
            "57/100 train loss:0.0898 train acc:90.78% val loss:0.3854 val acc:61.46%\n",
            "58/100 train loss:0.0869 train acc:91.07% val loss:0.3410 val acc:65.90%\n",
            "59/100 train loss:0.0937 train acc:90.39% val loss:0.3985 val acc:60.15%\n",
            "60/100 train loss:0.0917 train acc:90.59% val loss:0.4580 val acc:54.20%\n",
            "61/100 train loss:0.0904 train acc:90.72% val loss:0.4057 val acc:59.43%\n",
            "62/100 train loss:0.0858 train acc:91.18% val loss:0.3958 val acc:60.42%\n",
            "63/100 train loss:0.0863 train acc:91.13% val loss:0.3656 val acc:63.44%\n",
            "64/100 train loss:0.0846 train acc:91.30% val loss:0.4116 val acc:58.84%\n",
            "65/100 train loss:0.0808 train acc:91.68% val loss:0.3768 val acc:62.32%\n",
            "66/100 train loss:0.0815 train acc:91.61% val loss:0.3838 val acc:61.62%\n",
            "67/100 train loss:0.0867 train acc:91.09% val loss:0.4288 val acc:57.12%\n",
            "68/100 train loss:0.0842 train acc:91.35% val loss:0.4194 val acc:58.06%\n",
            "69/100 train loss:0.0832 train acc:91.44% val loss:0.4137 val acc:58.63%\n",
            "70/100 train loss:0.0808 train acc:91.68% val loss:0.3760 val acc:62.40%\n",
            "71/100 train loss:0.0809 train acc:91.67% val loss:0.4148 val acc:58.52%\n",
            "72/100 train loss:0.0836 train acc:91.40% val loss:0.4036 val acc:59.64%\n",
            "73/100 train loss:0.0843 train acc:91.34% val loss:0.4080 val acc:59.20%\n",
            "74/100 train loss:0.0821 train acc:91.55% val loss:0.3531 val acc:64.69%\n",
            "75/100 train loss:0.0806 train acc:91.70% val loss:0.4194 val acc:58.06%\n",
            "76/100 train loss:0.0787 train acc:91.89% val loss:0.3307 val acc:66.93%\n",
            "77/100 train loss:0.0786 train acc:91.90% val loss:0.3948 val acc:60.52%\n",
            "78/100 train loss:0.0775 train acc:92.01% val loss:0.3612 val acc:63.88%\n",
            "79/100 train loss:0.0795 train acc:91.81% val loss:0.3728 val acc:62.72%\n",
            "80/100 train loss:0.0774 train acc:92.02% val loss:0.4213 val acc:57.87%\n",
            "81/100 train loss:0.0810 train acc:91.66% val loss:0.3366 val acc:66.34%\n",
            "82/100 train loss:0.0787 train acc:91.89% val loss:0.4249 val acc:57.51%\n",
            "83/100 train loss:0.0878 train acc:90.98% val loss:0.3634 val acc:63.66%\n",
            "84/100 train loss:0.0827 train acc:91.49% val loss:0.3955 val acc:60.45%\n",
            "85/100 train loss:0.0762 train acc:92.14% val loss:0.3518 val acc:64.82%\n",
            "86/100 train loss:0.0786 train acc:91.90% val loss:0.4174 val acc:58.26%\n",
            "87/100 train loss:0.0870 train acc:91.06% val loss:0.3840 val acc:61.60%\n",
            "88/100 train loss:0.0785 train acc:91.92% val loss:0.4239 val acc:57.61%\n",
            "89/100 train loss:0.0773 train acc:92.04% val loss:0.3693 val acc:63.07%\n",
            "90/100 train loss:0.0769 train acc:92.07% val loss:0.3786 val acc:62.14%\n",
            "91/100 train loss:0.0853 train acc:91.23% val loss:0.3746 val acc:62.54%\n",
            "92/100 train loss:0.0736 train acc:92.40% val loss:0.4392 val acc:56.08%\n",
            "93/100 train loss:0.0775 train acc:92.01% val loss:0.4010 val acc:59.90%\n",
            "94/100 train loss:0.0763 train acc:92.13% val loss:0.4381 val acc:56.19%\n",
            "95/100 train loss:0.0760 train acc:92.16% val loss:0.3735 val acc:62.65%\n",
            "96/100 train loss:0.0780 train acc:91.97% val loss:0.3179 val acc:68.21%\n",
            "97/100 train loss:0.0765 train acc:92.12% val loss:0.3874 val acc:61.26%\n",
            "98/100 train loss:0.0786 train acc:91.90% val loss:0.3225 val acc:67.75%\n",
            "99/100 train loss:0.0740 train acc:92.36% val loss:0.4029 val acc:59.71%\n",
            "100/100 train loss:0.0775 train acc:92.02% val loss:0.3969 val acc:60.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Gtcy1nx0GdE9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xTCST85Jf6sA",
        "ugrRquc7DAqt",
        "3buwods0G4bU",
        "5nEdFbrOkMnd",
        "xytYsQDyuV7I",
        "lkq1JglY8nRh",
        "JWvyZzfyDEwm",
        "GqsKRBKNiLuo",
        "05ZB_SJxvC8U",
        "UdNvv6DB8j93"
      ],
      "name": "task345.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}