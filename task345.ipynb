{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTCST85Jf6sA"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/COSRMAL_CHALLENGE/CORSMAL-Challenge-2022-Squids\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qzV3QqaG5Lv",
        "outputId": "e39f1768-4338-4061-a427-5bf048b25178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/COSRMAL_CHALLENGE/CORSMAL-Challenge-2022-Squids\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9ej-BmvgInY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0921e9-23a4-4ff9-a0fa-171d0fc7625f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import scipy\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import cv2\n",
        "import scipy.io.wavfile\n",
        "import time\n",
        "import IPython\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "import json\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms\n",
        "from dataset import MiniDataset\n",
        "from loss import computeScoreType1, myLoss\n",
        "from models import Net, effnetv2_xl, MobileNetV3_Large\n",
        "from helper import train_image, evaluate_image\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTQA8MKYgN1r"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD/crops_rgb_train.zip /content/crops_rgb_train.zip\n",
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD/crops_rgb_test.zip /content/crops_rgb_test.zip\n",
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD/crops_depth_train.zip /content/crops_depth_train.zip\n",
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD/crops_depth_test.zip /content/crops_depth_test.zip\n",
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD/labels_test.zip /content/labels_test.zip\n",
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD/labels_train.zip /content/labels_train.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GKjFsuRg8wX"
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/train',exist_ok=True)\n",
        "os.makedirs('/content/test',exist_ok=True)\n",
        "!unzip /content/crops_rgb_train.zip -d /content/train/\n",
        "!unzip /content/crops_rgb_test.zip -d /content/test/\n",
        "!unzip /content/crops_depth_train.zip -d /content/train/\n",
        "!unzip /content/crops_depth_test.zip -d /content/test/\n",
        "!unzip /content/labels_train.zip -d /content/train/\n",
        "!unzip /content/labels_test.zip -d /content/test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu049jOautFa",
        "outputId": "5d0d4ae5-9e16-4116-e928-e004a600fb26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2kxapxBc7_J"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugrRquc7DAqt"
      },
      "source": [
        "## Capacity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7ge09lVhZNY",
        "outputId": "e6ffa79b-2cf5-4e4d-ec58-297c4b6000fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/50 train loss:0.5427 train acc:31.11% val loss:0.5720 val acc:26.78%\n",
            "2/50 train loss:0.4562 train acc:48.15% val loss:0.4846 val acc:38.49%\n",
            "3/50 train loss:0.3094 train acc:69.06% val loss:0.3300 val acc:67.00%\n",
            "4/50 train loss:0.2892 train acc:71.08% val loss:0.3078 val acc:69.22%\n",
            "5/50 train loss:0.2902 train acc:70.98% val loss:0.3136 val acc:68.64%\n",
            "6/50 train loss:0.2866 train acc:71.34% val loss:0.3190 val acc:68.10%\n",
            "7/50 train loss:0.2842 train acc:71.58% val loss:0.3055 val acc:69.45%\n",
            "8/50 train loss:0.2883 train acc:71.17% val loss:0.3106 val acc:68.94%\n",
            "9/50 train loss:0.2878 train acc:71.22% val loss:0.3123 val acc:68.77%\n",
            "10/50 train loss:0.2875 train acc:71.25% val loss:0.3227 val acc:67.73%\n",
            "11/50 train loss:0.2860 train acc:71.40% val loss:0.3280 val acc:67.20%\n",
            "12/50 train loss:0.2822 train acc:71.78% val loss:0.3241 val acc:67.59%\n",
            "13/50 train loss:0.2841 train acc:71.59% val loss:0.3093 val acc:69.07%\n",
            "14/50 train loss:0.2835 train acc:71.65% val loss:0.3170 val acc:68.30%\n",
            "15/50 train loss:0.2819 train acc:71.81% val loss:0.2970 val acc:70.30%\n",
            "16/50 train loss:0.2795 train acc:72.05% val loss:0.3009 val acc:69.91%\n",
            "17/50 train loss:0.2811 train acc:71.89% val loss:0.2784 val acc:72.16%\n",
            "18/50 train loss:0.2796 train acc:72.04% val loss:0.2546 val acc:74.54%\n",
            "19/50 train loss:0.2710 train acc:72.90% val loss:0.2514 val acc:74.86%\n",
            "20/50 train loss:0.2632 train acc:73.68% val loss:0.2623 val acc:73.77%\n",
            "21/50 train loss:0.2486 train acc:75.14% val loss:0.2511 val acc:74.89%\n",
            "22/50 train loss:0.2391 train acc:76.09% val loss:0.2541 val acc:74.59%\n",
            "23/50 train loss:0.2295 train acc:77.05% val loss:0.2484 val acc:75.16%\n",
            "24/50 train loss:0.2156 train acc:78.44% val loss:0.2445 val acc:75.55%\n",
            "25/50 train loss:0.2117 train acc:78.83% val loss:0.2510 val acc:74.90%\n",
            "26/50 train loss:0.2049 train acc:79.51% val loss:0.2446 val acc:75.54%\n",
            "27/50 train loss:0.2025 train acc:79.75% val loss:0.2391 val acc:76.09%\n",
            "28/50 train loss:0.1977 train acc:80.23% val loss:0.2455 val acc:75.45%\n",
            "29/50 train loss:0.1950 train acc:80.50% val loss:0.2276 val acc:77.24%\n",
            "30/50 train loss:0.1874 train acc:81.26% val loss:0.2439 val acc:75.61%\n",
            "31/50 train loss:0.1846 train acc:81.54% val loss:0.2500 val acc:75.00%\n",
            "32/50 train loss:0.1814 train acc:81.86% val loss:0.2170 val acc:78.30%\n",
            "33/50 train loss:0.1772 train acc:82.28% val loss:0.2399 val acc:76.01%\n",
            "34/50 train loss:0.1730 train acc:82.70% val loss:0.2113 val acc:78.87%\n",
            "35/50 train loss:0.1670 train acc:83.30% val loss:0.2219 val acc:77.81%\n",
            "36/50 train loss:0.1560 train acc:84.40% val loss:0.2144 val acc:78.56%\n",
            "37/50 train loss:0.1521 train acc:84.79% val loss:0.2091 val acc:79.09%\n",
            "38/50 train loss:0.1467 train acc:85.33% val loss:0.2215 val acc:77.85%\n",
            "39/50 train loss:0.1413 train acc:85.87% val loss:0.1991 val acc:80.09%\n",
            "40/50 train loss:0.1392 train acc:86.08% val loss:0.1974 val acc:80.26%\n",
            "41/50 train loss:0.1346 train acc:86.54% val loss:0.2169 val acc:78.31%\n",
            "42/50 train loss:0.1313 train acc:86.87% val loss:0.2235 val acc:77.65%\n",
            "43/50 train loss:0.1261 train acc:87.39% val loss:0.2361 val acc:76.39%\n",
            "44/50 train loss:0.1220 train acc:87.80% val loss:0.2235 val acc:77.65%\n",
            "45/50 train loss:0.1216 train acc:87.84% val loss:0.2416 val acc:75.84%\n",
            "46/50 train loss:0.1205 train acc:87.95% val loss:0.2214 val acc:77.86%\n",
            "47/50 train loss:0.1122 train acc:88.78% val loss:0.1910 val acc:80.90%\n",
            "48/50 train loss:0.1136 train acc:88.64% val loss:0.2016 val acc:79.84%\n",
            "49/50 train loss:0.1125 train acc:88.75% val loss:0.1894 val acc:81.06%\n",
            "50/50 train loss:0.1070 train acc:89.30% val loss:0.1910 val acc:80.90%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 2\n",
        "train_split = 0.8\n",
        "lr = 1e-4\n",
        "epochs = 50\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb')\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                        '/content/test/labels', \n",
        "                        '/content/test/crops_depth',\n",
        "                        '/content/test/crops_rgb')\n",
        "model = effnetv2_xl(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  \n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train / num_train, 100 * correct_train/num_train,\n",
        "      loss_val /num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"XL-my{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB5uZuFlmZgS",
        "outputId": "7e2279bc-862e-4d90-afca-ad5edc9e722c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5963 train acc:24.71% val loss:0.5315 val acc:35.67%\n",
            "2/100 train loss:0.4706 train acc:38.27% val loss:0.7242 val acc:0.60%\n",
            "3/100 train loss:0.3704 train acc:55.41% val loss:0.3444 val acc:60.08%\n",
            "4/100 train loss:0.3108 train acc:65.45% val loss:0.4562 val acc:53.52%\n",
            "5/100 train loss:0.2637 train acc:72.20% val loss:0.2807 val acc:71.67%\n",
            "6/100 train loss:0.2341 train acc:75.72% val loss:0.4366 val acc:55.67%\n",
            "7/100 train loss:0.2190 train acc:77.07% val loss:0.2541 val acc:74.59%\n",
            "8/100 train loss:0.1995 train acc:79.21% val loss:0.2256 val acc:77.44%\n",
            "9/100 train loss:0.1982 train acc:79.42% val loss:0.3874 val acc:61.26%\n",
            "10/100 train loss:0.2175 train acc:77.48% val loss:0.5762 val acc:41.36%\n",
            "11/100 train loss:0.2191 train acc:77.38% val loss:0.2387 val acc:76.13%\n",
            "12/100 train loss:0.2662 train acc:72.18% val loss:0.2828 val acc:71.19%\n",
            "13/100 train loss:0.2357 train acc:75.66% val loss:0.5781 val acc:41.99%\n",
            "14/100 train loss:0.2013 train acc:79.18% val loss:0.2625 val acc:73.75%\n",
            "15/100 train loss:0.1889 train acc:80.45% val loss:0.2993 val acc:69.19%\n",
            "16/100 train loss:0.1938 train acc:79.96% val loss:0.3623 val acc:63.62%\n",
            "17/100 train loss:0.2068 train acc:78.61% val loss:0.2088 val acc:79.12%\n",
            "18/100 train loss:0.1971 train acc:79.57% val loss:0.2024 val acc:79.60%\n",
            "19/100 train loss:0.1821 train acc:81.11% val loss:0.2021 val acc:79.79%\n",
            "20/100 train loss:0.1735 train acc:81.99% val loss:0.1882 val acc:80.93%\n",
            "21/100 train loss:0.1667 train acc:82.61% val loss:0.1913 val acc:80.87%\n",
            "22/100 train loss:0.1554 train acc:83.82% val loss:0.1904 val acc:80.96%\n",
            "23/100 train loss:0.1610 train acc:83.24% val loss:0.2215 val acc:77.85%\n",
            "24/100 train loss:0.1554 train acc:83.81% val loss:0.1851 val acc:81.49%\n",
            "25/100 train loss:0.1617 train acc:83.18% val loss:0.6047 val acc:39.00%\n",
            "26/100 train loss:0.1587 train acc:83.48% val loss:0.1821 val acc:81.79%\n",
            "27/100 train loss:0.1960 train acc:79.71% val loss:0.2470 val acc:75.30%\n",
            "28/100 train loss:0.1934 train acc:79.94% val loss:0.1959 val acc:80.41%\n",
            "29/100 train loss:0.1795 train acc:81.39% val loss:0.1746 val acc:82.54%\n",
            "30/100 train loss:0.1712 train acc:82.23% val loss:0.1782 val acc:82.18%\n",
            "31/100 train loss:0.1726 train acc:82.03% val loss:0.1837 val acc:81.63%\n",
            "32/100 train loss:0.1603 train acc:83.33% val loss:0.1666 val acc:83.34%\n",
            "33/100 train loss:0.1667 train acc:82.67% val loss:0.1705 val acc:82.95%\n",
            "34/100 train loss:0.1573 train acc:83.64% val loss:0.1627 val acc:83.73%\n",
            "35/100 train loss:0.1495 train acc:84.40% val loss:0.1928 val acc:80.72%\n",
            "36/100 train loss:0.1510 train acc:84.21% val loss:0.2148 val acc:78.52%\n",
            "37/100 train loss:0.1688 train acc:82.43% val loss:0.1882 val acc:81.18%\n",
            "38/100 train loss:0.1495 train acc:84.40% val loss:0.1883 val acc:81.17%\n",
            "39/100 train loss:0.1473 train acc:84.63% val loss:0.1714 val acc:82.86%\n",
            "40/100 train loss:0.1596 train acc:83.36% val loss:0.1954 val acc:80.46%\n",
            "41/100 train loss:0.1575 train acc:83.58% val loss:0.1883 val acc:81.17%\n",
            "42/100 train loss:0.1516 train acc:84.17% val loss:0.1923 val acc:80.77%\n",
            "43/100 train loss:0.1442 train acc:84.92% val loss:0.2223 val acc:77.77%\n",
            "44/100 train loss:0.1600 train acc:83.32% val loss:0.1849 val acc:81.24%\n",
            "45/100 train loss:0.1435 train acc:85.01% val loss:0.1673 val acc:83.07%\n",
            "46/100 train loss:0.1494 train acc:84.41% val loss:0.1795 val acc:81.84%\n",
            "47/100 train loss:0.1571 train acc:83.65% val loss:0.2100 val acc:79.00%\n",
            "48/100 train loss:0.2046 train acc:78.79% val loss:0.2094 val acc:79.06%\n",
            "49/100 train loss:0.1716 train acc:82.18% val loss:0.1830 val acc:81.50%\n",
            "50/100 train loss:0.1737 train acc:81.92% val loss:0.2684 val acc:73.16%\n",
            "51/100 train loss:0.1845 train acc:80.86% val loss:0.2211 val acc:77.89%\n",
            "52/100 train loss:0.1867 train acc:80.62% val loss:0.1923 val acc:80.77%\n",
            "53/100 train loss:0.1679 train acc:82.53% val loss:0.1785 val acc:82.15%\n",
            "54/100 train loss:0.1646 train acc:82.87% val loss:0.2060 val acc:79.40%\n",
            "55/100 train loss:0.1666 train acc:82.69% val loss:0.3236 val acc:67.64%\n",
            "56/100 train loss:0.1510 train acc:84.26% val loss:0.2078 val acc:79.16%\n",
            "57/100 train loss:0.1572 train acc:83.64% val loss:0.1707 val acc:82.93%\n",
            "58/100 train loss:0.1594 train acc:83.37% val loss:0.1772 val acc:82.28%\n",
            "59/100 train loss:0.1408 train acc:85.18% val loss:0.1722 val acc:82.78%\n",
            "60/100 train loss:0.1452 train acc:84.68% val loss:0.1808 val acc:81.92%\n",
            "61/100 train loss:0.1396 train acc:85.33% val loss:0.2462 val acc:75.38%\n",
            "62/100 train loss:0.1593 train acc:83.26% val loss:0.2206 val acc:77.94%\n",
            "63/100 train loss:0.1627 train acc:82.93% val loss:0.1713 val acc:82.87%\n",
            "64/100 train loss:0.1574 train acc:83.55% val loss:0.1884 val acc:81.16%\n",
            "65/100 train loss:0.1531 train acc:83.96% val loss:0.1799 val acc:82.01%\n",
            "66/100 train loss:0.1447 train acc:84.71% val loss:0.1831 val acc:81.49%\n",
            "67/100 train loss:0.1410 train acc:85.21% val loss:0.1680 val acc:82.99%\n",
            "68/100 train loss:0.1471 train acc:84.53% val loss:0.2071 val acc:79.29%\n",
            "69/100 train loss:0.1653 train acc:82.61% val loss:0.1919 val acc:80.81%\n",
            "70/100 train loss:0.1579 train acc:83.37% val loss:0.1965 val acc:80.35%\n",
            "71/100 train loss:0.1546 train acc:83.59% val loss:0.1833 val acc:81.67%\n",
            "72/100 train loss:0.1434 train acc:84.73% val loss:0.1920 val acc:80.80%\n",
            "73/100 train loss:0.1482 train acc:84.23% val loss:0.1704 val acc:82.68%\n",
            "74/100 train loss:0.1528 train acc:83.77% val loss:0.2837 val acc:71.35%\n",
            "75/100 train loss:0.1509 train acc:84.07% val loss:0.3615 val acc:63.85%\n",
            "76/100 train loss:0.1481 train acc:84.41% val loss:0.1888 val acc:81.12%\n",
            "77/100 train loss:0.1395 train acc:85.36% val loss:0.1883 val acc:81.17%\n",
            "78/100 train loss:0.1397 train acc:85.20% val loss:0.1949 val acc:80.45%\n",
            "79/100 train loss:0.1394 train acc:85.23% val loss:0.1700 val acc:82.93%\n",
            "80/100 train loss:0.1421 train acc:85.00% val loss:0.1743 val acc:82.10%\n",
            "81/100 train loss:0.1388 train acc:85.35% val loss:0.2795 val acc:72.05%\n",
            "82/100 train loss:0.1547 train acc:83.70% val loss:0.1996 val acc:80.04%\n",
            "83/100 train loss:0.1622 train acc:82.75% val loss:0.2502 val acc:74.27%\n",
            "84/100 train loss:0.1525 train acc:84.04% val loss:0.1771 val acc:82.29%\n",
            "85/100 train loss:0.1539 train acc:83.84% val loss:0.3409 val acc:65.91%\n",
            "86/100 train loss:0.1569 train acc:83.59% val loss:0.1885 val acc:81.15%\n",
            "87/100 train loss:0.1492 train acc:84.21% val loss:0.1829 val acc:81.71%\n",
            "88/100 train loss:0.1454 train acc:84.57% val loss:0.1954 val acc:80.26%\n",
            "89/100 train loss:0.1469 train acc:84.47% val loss:0.1929 val acc:80.71%\n",
            "90/100 train loss:0.1408 train acc:85.02% val loss:0.1600 val acc:84.00%\n",
            "91/100 train loss:0.1395 train acc:85.22% val loss:0.1723 val acc:82.77%\n",
            "92/100 train loss:0.1376 train acc:85.46% val loss:0.1836 val acc:81.64%\n",
            "93/100 train loss:0.1364 train acc:85.52% val loss:0.1772 val acc:82.28%\n",
            "94/100 train loss:0.1490 train acc:84.25% val loss:0.2010 val acc:79.90%\n",
            "95/100 train loss:0.1571 train acc:83.58% val loss:0.1859 val acc:81.41%\n",
            "96/100 train loss:0.1430 train acc:84.93% val loss:0.1967 val acc:80.33%\n",
            "97/100 train loss:0.1502 train acc:84.26% val loss:0.1944 val acc:80.56%\n",
            "98/100 train loss:0.1397 train acc:85.12% val loss:0.1861 val acc:81.39%\n",
            "99/100 train loss:0.1457 train acc:84.53% val loss:0.1783 val acc:82.17%\n",
            "100/100 train loss:0.1393 train acc:85.20% val loss:0.1822 val acc:81.78%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb')\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                        '/content/test/labels', \n",
        "                        '/content/test/crops_depth',\n",
        "                        '/content/test/crops_rgb')\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3buwods0G4bU"
      },
      "source": [
        "## Mass estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJnFwsafG7AD",
        "outputId": "97997721-2cb3-4780-e19b-678d54305acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5667 train acc:37.74% val loss:0.5231 val acc:44.64%\n",
            "2/100 train loss:0.5083 train acc:43.19% val loss:0.5097 val acc:47.50%\n",
            "3/100 train loss:0.4908 train acc:46.11% val loss:0.5032 val acc:48.44%\n",
            "4/100 train loss:0.4784 train acc:47.61% val loss:0.4909 val acc:49.17%\n",
            "5/100 train loss:0.4683 train acc:49.29% val loss:0.4888 val acc:50.77%\n",
            "6/100 train loss:0.4605 train acc:51.14% val loss:0.4803 val acc:51.59%\n",
            "7/100 train loss:0.4529 train acc:52.43% val loss:0.4681 val acc:52.47%\n",
            "8/100 train loss:0.4413 train acc:53.27% val loss:0.4599 val acc:52.16%\n",
            "9/100 train loss:0.4282 train acc:54.98% val loss:0.4517 val acc:53.61%\n",
            "10/100 train loss:0.4172 train acc:55.60% val loss:0.4335 val acc:56.07%\n",
            "11/100 train loss:0.4110 train acc:56.66% val loss:0.4307 val acc:56.48%\n",
            "12/100 train loss:0.3991 train acc:58.20% val loss:0.4280 val acc:56.90%\n",
            "13/100 train loss:0.3940 train acc:59.06% val loss:0.4195 val acc:57.86%\n",
            "14/100 train loss:0.3837 train acc:60.33% val loss:0.4118 val acc:58.62%\n",
            "15/100 train loss:0.3765 train acc:60.94% val loss:0.4041 val acc:59.59%\n",
            "16/100 train loss:0.3742 train acc:61.17% val loss:0.4049 val acc:59.11%\n",
            "17/100 train loss:0.3729 train acc:61.36% val loss:0.4052 val acc:58.77%\n",
            "18/100 train loss:0.3744 train acc:61.32% val loss:0.4077 val acc:59.19%\n",
            "19/100 train loss:0.3735 train acc:61.62% val loss:0.3961 val acc:60.35%\n",
            "20/100 train loss:0.3737 train acc:61.55% val loss:0.3884 val acc:60.89%\n",
            "21/100 train loss:0.3696 train acc:62.09% val loss:0.4060 val acc:59.40%\n",
            "22/100 train loss:0.3627 train acc:62.89% val loss:0.3890 val acc:61.10%\n",
            "23/100 train loss:0.3587 train acc:63.19% val loss:0.3949 val acc:60.48%\n",
            "24/100 train loss:0.3529 train acc:63.71% val loss:0.3904 val acc:60.82%\n",
            "25/100 train loss:0.3438 train acc:64.63% val loss:0.3887 val acc:61.13%\n",
            "26/100 train loss:0.3453 train acc:64.57% val loss:0.3814 val acc:61.81%\n",
            "27/100 train loss:0.3367 train acc:65.32% val loss:0.3959 val acc:60.08%\n",
            "28/100 train loss:0.3372 train acc:65.30% val loss:0.3949 val acc:60.48%\n",
            "29/100 train loss:0.3315 train acc:65.85% val loss:0.3830 val acc:61.63%\n",
            "30/100 train loss:0.3278 train acc:66.22% val loss:0.3791 val acc:62.09%\n",
            "31/100 train loss:0.3326 train acc:65.84% val loss:0.3697 val acc:63.03%\n",
            "32/100 train loss:0.3314 train acc:65.98% val loss:0.3710 val acc:62.90%\n",
            "33/100 train loss:0.3211 train acc:66.97% val loss:0.3686 val acc:62.85%\n",
            "34/100 train loss:0.3289 train acc:66.24% val loss:0.3631 val acc:63.69%\n",
            "35/100 train loss:0.3285 train acc:66.37% val loss:0.3744 val acc:62.56%\n",
            "36/100 train loss:0.3204 train acc:67.23% val loss:0.3696 val acc:63.04%\n",
            "37/100 train loss:0.3166 train acc:67.56% val loss:0.3587 val acc:64.13%\n",
            "38/100 train loss:0.3162 train acc:67.52% val loss:0.3631 val acc:63.69%\n",
            "39/100 train loss:0.3130 train acc:67.89% val loss:0.3455 val acc:65.45%\n",
            "40/100 train loss:0.3173 train acc:67.46% val loss:0.3654 val acc:63.46%\n",
            "41/100 train loss:0.3175 train acc:67.41% val loss:0.3604 val acc:63.96%\n",
            "42/100 train loss:0.3077 train acc:68.35% val loss:0.3640 val acc:63.59%\n",
            "43/100 train loss:0.3039 train acc:68.69% val loss:0.3591 val acc:64.09%\n",
            "44/100 train loss:0.3007 train acc:69.01% val loss:0.3627 val acc:63.72%\n",
            "45/100 train loss:0.3027 train acc:68.85% val loss:0.3569 val acc:64.29%\n",
            "46/100 train loss:0.3045 train acc:68.64% val loss:0.3550 val acc:64.50%\n",
            "47/100 train loss:0.3103 train acc:68.09% val loss:0.3520 val acc:64.80%\n",
            "48/100 train loss:0.3057 train acc:68.57% val loss:0.3539 val acc:64.61%\n",
            "49/100 train loss:0.3009 train acc:68.99% val loss:0.3581 val acc:64.19%\n",
            "50/100 train loss:0.3064 train acc:68.40% val loss:0.3377 val acc:66.23%\n",
            "51/100 train loss:0.3074 train acc:68.29% val loss:0.3485 val acc:65.15%\n",
            "52/100 train loss:0.3016 train acc:68.86% val loss:0.3597 val acc:63.98%\n",
            "53/100 train loss:0.2974 train acc:69.27% val loss:0.3737 val acc:62.60%\n",
            "54/100 train loss:0.2955 train acc:69.44% val loss:0.3534 val acc:64.66%\n",
            "55/100 train loss:0.3014 train acc:68.85% val loss:0.3437 val acc:65.60%\n",
            "56/100 train loss:0.3045 train acc:68.56% val loss:0.3480 val acc:65.16%\n",
            "57/100 train loss:0.3006 train acc:69.03% val loss:0.3585 val acc:64.13%\n",
            "58/100 train loss:0.2900 train acc:70.08% val loss:0.3434 val acc:65.66%\n",
            "59/100 train loss:0.2921 train acc:69.88% val loss:0.3434 val acc:65.65%\n",
            "60/100 train loss:0.2860 train acc:70.49% val loss:0.3412 val acc:65.85%\n",
            "61/100 train loss:0.2897 train acc:70.11% val loss:0.3456 val acc:65.44%\n",
            "62/100 train loss:0.2887 train acc:70.21% val loss:0.3518 val acc:64.82%\n",
            "63/100 train loss:0.2926 train acc:69.86% val loss:0.3281 val acc:67.13%\n",
            "64/100 train loss:0.2881 train acc:70.31% val loss:0.3400 val acc:66.00%\n",
            "65/100 train loss:0.3019 train acc:68.93% val loss:0.3614 val acc:63.86%\n",
            "66/100 train loss:0.3058 train acc:68.69% val loss:0.3504 val acc:64.90%\n",
            "67/100 train loss:0.3199 train acc:67.28% val loss:0.3608 val acc:63.67%\n",
            "68/100 train loss:0.3105 train acc:68.22% val loss:0.3473 val acc:65.27%\n",
            "69/100 train loss:0.2998 train acc:69.24% val loss:0.3441 val acc:65.59%\n",
            "70/100 train loss:0.2947 train acc:69.81% val loss:0.3408 val acc:65.92%\n",
            "71/100 train loss:0.2930 train acc:69.98% val loss:0.3504 val acc:64.71%\n",
            "72/100 train loss:0.2880 train acc:70.50% val loss:0.3470 val acc:65.30%\n",
            "73/100 train loss:0.2943 train acc:69.89% val loss:0.3516 val acc:64.84%\n",
            "74/100 train loss:0.2911 train acc:70.14% val loss:0.3455 val acc:65.44%\n",
            "75/100 train loss:0.2834 train acc:70.94% val loss:0.3401 val acc:65.99%\n",
            "76/100 train loss:0.2842 train acc:70.83% val loss:0.3343 val acc:66.57%\n",
            "77/100 train loss:0.2796 train acc:71.25% val loss:0.3350 val acc:66.50%\n",
            "78/100 train loss:0.2782 train acc:71.40% val loss:0.3346 val acc:66.54%\n",
            "79/100 train loss:0.2847 train acc:70.76% val loss:0.3550 val acc:64.50%\n",
            "80/100 train loss:0.2857 train acc:70.69% val loss:0.3401 val acc:65.99%\n",
            "81/100 train loss:0.2863 train acc:70.65% val loss:0.3410 val acc:65.90%\n",
            "82/100 train loss:0.2875 train acc:70.55% val loss:0.3366 val acc:66.34%\n",
            "83/100 train loss:0.2910 train acc:70.16% val loss:0.3444 val acc:65.56%\n",
            "84/100 train loss:0.3066 train acc:68.63% val loss:0.3454 val acc:65.45%\n",
            "85/100 train loss:0.2990 train acc:69.40% val loss:0.3490 val acc:65.10%\n",
            "86/100 train loss:0.2963 train acc:69.67% val loss:0.3555 val acc:64.45%\n",
            "87/100 train loss:0.2876 train acc:70.53% val loss:0.3406 val acc:65.93%\n",
            "88/100 train loss:0.2905 train acc:70.26% val loss:0.3425 val acc:65.75%\n",
            "89/100 train loss:0.2902 train acc:70.29% val loss:0.3392 val acc:66.08%\n",
            "90/100 train loss:0.2866 train acc:70.64% val loss:0.3390 val acc:66.10%\n",
            "91/100 train loss:0.3093 train acc:68.34% val loss:0.3257 val acc:67.43%\n",
            "92/100 train loss:0.2923 train acc:70.09% val loss:0.3232 val acc:67.68%\n",
            "93/100 train loss:0.2931 train acc:69.99% val loss:0.3387 val acc:66.13%\n",
            "94/100 train loss:0.2909 train acc:70.21% val loss:0.3456 val acc:65.40%\n",
            "95/100 train loss:0.2834 train acc:70.98% val loss:0.3420 val acc:65.80%\n",
            "96/100 train loss:0.2823 train acc:71.09% val loss:0.3431 val acc:65.69%\n",
            "97/100 train loss:0.2799 train acc:71.32% val loss:0.3545 val acc:64.55%\n",
            "98/100 train loss:0.2785 train acc:71.47% val loss:0.3449 val acc:65.51%\n",
            "99/100 train loss:0.2772 train acc:71.59% val loss:0.3518 val acc:64.82%\n",
            "100/100 train loss:0.2788 train acc:71.37% val loss:0.3381 val acc:66.19%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-4\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        ['container mass']\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                      ['container mass']\n",
        "                       \n",
        "                      )\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-mass{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nEdFbrOkMnd"
      },
      "source": [
        "## height"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hkzm8FO9kPDI",
        "outputId": "9b161049-bee6-4212-d72d-6526797824b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5241 train acc:34.56% val loss:0.6423 val acc:14.70%\n",
            "2/100 train loss:0.3415 train acc:58.34% val loss:0.7800 val acc:0.76%\n",
            "3/100 train loss:0.2358 train acc:74.05% val loss:0.2700 val acc:72.25%\n",
            "4/100 train loss:0.1861 train acc:80.48% val loss:0.1998 val acc:80.02%\n",
            "5/100 train loss:0.1459 train acc:84.69% val loss:0.2061 val acc:79.39%\n",
            "6/100 train loss:0.1383 train acc:85.53% val loss:0.1615 val acc:83.85%\n",
            "7/100 train loss:0.1295 train acc:86.39% val loss:0.1569 val acc:84.31%\n",
            "8/100 train loss:0.1238 train acc:86.97% val loss:0.2292 val acc:77.08%\n",
            "9/100 train loss:0.1379 train acc:85.56% val loss:0.1402 val acc:85.98%\n",
            "10/100 train loss:0.1278 train acc:86.59% val loss:0.1362 val acc:86.38%\n",
            "11/100 train loss:0.1339 train acc:85.93% val loss:0.2093 val acc:78.79%\n",
            "12/100 train loss:0.1228 train acc:87.07% val loss:0.1471 val acc:85.29%\n",
            "13/100 train loss:0.1266 train acc:86.69% val loss:0.1381 val acc:86.19%\n",
            "14/100 train loss:0.1209 train acc:87.27% val loss:0.1244 val acc:87.56%\n",
            "15/100 train loss:0.1201 train acc:87.35% val loss:0.1354 val acc:86.46%\n",
            "16/100 train loss:0.1136 train acc:88.01% val loss:0.1188 val acc:88.12%\n",
            "17/100 train loss:0.1178 train acc:87.58% val loss:0.2634 val acc:73.66%\n",
            "18/100 train loss:0.1211 train acc:87.25% val loss:0.1261 val acc:87.39%\n",
            "19/100 train loss:0.1176 train acc:87.59% val loss:0.3015 val acc:69.85%\n",
            "20/100 train loss:0.1548 train acc:83.83% val loss:0.3131 val acc:68.69%\n",
            "21/100 train loss:0.1346 train acc:85.89% val loss:0.2235 val acc:77.65%\n",
            "22/100 train loss:0.1270 train acc:86.66% val loss:0.1492 val acc:85.08%\n",
            "23/100 train loss:0.1245 train acc:86.89% val loss:0.1352 val acc:86.48%\n",
            "24/100 train loss:0.1200 train acc:87.35% val loss:0.1427 val acc:85.73%\n",
            "25/100 train loss:0.1157 train acc:87.77% val loss:0.2118 val acc:78.82%\n",
            "26/100 train loss:0.1143 train acc:87.92% val loss:0.1445 val acc:85.55%\n",
            "27/100 train loss:0.1089 train acc:88.47% val loss:0.1456 val acc:85.36%\n",
            "28/100 train loss:0.1049 train acc:88.88% val loss:0.1193 val acc:88.07%\n",
            "29/100 train loss:0.1035 train acc:89.01% val loss:0.1186 val acc:88.00%\n",
            "30/100 train loss:0.1054 train acc:88.81% val loss:0.1440 val acc:85.33%\n",
            "31/100 train loss:0.1070 train acc:88.67% val loss:0.1440 val acc:85.60%\n",
            "32/100 train loss:0.1358 train acc:85.74% val loss:0.1711 val acc:82.70%\n",
            "33/100 train loss:0.1350 train acc:85.86% val loss:0.1409 val acc:85.91%\n",
            "34/100 train loss:0.1254 train acc:86.80% val loss:0.1227 val acc:87.73%\n",
            "35/100 train loss:0.1196 train acc:87.39% val loss:0.1438 val acc:85.17%\n",
            "36/100 train loss:0.1191 train acc:87.43% val loss:0.1303 val acc:86.97%\n",
            "37/100 train loss:0.1153 train acc:87.83% val loss:0.1279 val acc:87.21%\n",
            "38/100 train loss:0.1195 train acc:87.41% val loss:0.1378 val acc:86.15%\n",
            "39/100 train loss:0.1303 train acc:86.27% val loss:0.1314 val acc:86.86%\n",
            "40/100 train loss:0.1361 train acc:85.75% val loss:0.1690 val acc:82.92%\n",
            "41/100 train loss:0.1243 train acc:86.92% val loss:0.1464 val acc:85.19%\n",
            "42/100 train loss:0.1236 train acc:86.99% val loss:0.1392 val acc:86.08%\n",
            "43/100 train loss:0.1184 train acc:87.52% val loss:0.1453 val acc:85.47%\n",
            "44/100 train loss:0.1157 train acc:87.79% val loss:0.1671 val acc:83.29%\n",
            "45/100 train loss:0.1173 train acc:87.63% val loss:0.1390 val acc:86.10%\n",
            "46/100 train loss:0.1124 train acc:88.13% val loss:0.1494 val acc:85.06%\n",
            "47/100 train loss:0.1107 train acc:88.28% val loss:0.1522 val acc:84.78%\n",
            "48/100 train loss:0.1399 train acc:85.29% val loss:0.6164 val acc:38.14%\n",
            "49/100 train loss:0.1423 train acc:85.09% val loss:0.1362 val acc:86.38%\n",
            "50/100 train loss:0.1316 train acc:86.12% val loss:0.1478 val acc:85.22%\n",
            "51/100 train loss:0.1208 train acc:87.26% val loss:0.1339 val acc:86.61%\n",
            "52/100 train loss:0.1177 train acc:87.56% val loss:0.1248 val acc:87.52%\n",
            "53/100 train loss:0.1155 train acc:87.78% val loss:0.2297 val acc:77.03%\n",
            "54/100 train loss:0.1177 train acc:87.55% val loss:0.1887 val acc:81.13%\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-7e81e694cd58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m#start_time = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m   \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m   \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;31m#elapsed_time = time.time() - start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-ca1b4bac615a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mnum_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        ['height']\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                      ['height']\n",
        "                       \n",
        "                      )\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-height{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXoG_PAxwUDt"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xytYsQDyuV7I"
      },
      "source": [
        "## Width top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnNrMyZCuYNs",
        "outputId": "845dc971-1953-430d-eb05-cedfa0e24f96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5314 train acc:39.50% val loss:0.6005 val acc:23.41%\n",
            "2/100 train loss:0.2665 train acc:69.09% val loss:0.6406 val acc:34.77%\n",
            "3/100 train loss:0.1906 train acc:79.53% val loss:0.5340 val acc:44.57%\n",
            "4/100 train loss:0.1843 train acc:80.41% val loss:0.2215 val acc:77.22%\n",
            "5/100 train loss:0.1499 train acc:84.31% val loss:0.3014 val acc:69.86%\n",
            "6/100 train loss:0.1405 train acc:85.28% val loss:0.1717 val acc:82.83%\n",
            "7/100 train loss:0.1491 train acc:84.38% val loss:0.5779 val acc:42.21%\n",
            "8/100 train loss:0.1401 train acc:85.34% val loss:0.1335 val acc:86.65%\n",
            "9/100 train loss:0.1587 train acc:83.36% val loss:0.1406 val acc:85.94%\n",
            "10/100 train loss:0.1332 train acc:86.04% val loss:0.1495 val acc:85.05%\n",
            "11/100 train loss:0.1254 train acc:86.82% val loss:0.1280 val acc:87.20%\n",
            "12/100 train loss:0.1159 train acc:87.76% val loss:0.1435 val acc:85.65%\n",
            "13/100 train loss:0.1275 train acc:86.57% val loss:0.3790 val acc:62.10%\n",
            "14/100 train loss:0.1245 train acc:86.88% val loss:0.1282 val acc:87.18%\n",
            "15/100 train loss:0.1138 train acc:87.98% val loss:0.1412 val acc:85.88%\n",
            "16/100 train loss:0.1078 train acc:88.56% val loss:0.1372 val acc:86.28%\n",
            "17/100 train loss:0.1202 train acc:87.22% val loss:0.1621 val acc:83.79%\n",
            "18/100 train loss:0.1187 train acc:87.47% val loss:0.2359 val acc:75.97%\n",
            "19/100 train loss:0.1112 train acc:88.21% val loss:0.1293 val acc:86.84%\n",
            "20/100 train loss:0.1133 train acc:87.99% val loss:0.2723 val acc:71.22%\n",
            "21/100 train loss:0.1261 train acc:86.65% val loss:0.1262 val acc:87.38%\n",
            "22/100 train loss:0.1058 train acc:88.78% val loss:0.1322 val acc:86.78%\n",
            "23/100 train loss:0.1132 train acc:88.03% val loss:0.3227 val acc:66.47%\n",
            "24/100 train loss:0.1075 train acc:88.61% val loss:0.1343 val acc:86.57%\n",
            "25/100 train loss:0.0969 train acc:89.67% val loss:0.1684 val acc:82.99%\n",
            "26/100 train loss:0.0970 train acc:89.66% val loss:0.1599 val acc:83.85%\n",
            "27/100 train loss:0.1031 train acc:89.03% val loss:0.1458 val acc:85.42%\n",
            "28/100 train loss:0.1131 train acc:88.03% val loss:0.1513 val acc:84.87%\n",
            "29/100 train loss:0.1014 train acc:89.23% val loss:0.1291 val acc:86.89%\n",
            "30/100 train loss:0.1340 train acc:85.80% val loss:0.4019 val acc:56.89%\n",
            "31/100 train loss:0.1361 train acc:85.55% val loss:0.1337 val acc:86.63%\n",
            "32/100 train loss:0.1084 train acc:88.51% val loss:0.1286 val acc:86.86%\n",
            "33/100 train loss:0.1021 train acc:89.11% val loss:0.1194 val acc:88.06%\n",
            "34/100 train loss:0.1054 train acc:88.81% val loss:0.1329 val acc:86.71%\n",
            "35/100 train loss:0.0998 train acc:89.38% val loss:0.1228 val acc:87.72%\n",
            "36/100 train loss:0.1363 train acc:85.60% val loss:0.1738 val acc:82.62%\n",
            "37/100 train loss:0.1503 train acc:84.18% val loss:0.1562 val acc:84.38%\n",
            "38/100 train loss:0.1328 train acc:85.96% val loss:0.1898 val acc:80.61%\n",
            "39/100 train loss:0.1105 train acc:88.28% val loss:0.1690 val acc:82.68%\n",
            "40/100 train loss:0.1147 train acc:87.84% val loss:0.1493 val acc:85.07%\n",
            "41/100 train loss:0.1163 train acc:87.68% val loss:0.1567 val acc:84.33%\n",
            "42/100 train loss:0.1211 train acc:87.23% val loss:0.1283 val acc:87.17%\n",
            "43/100 train loss:0.1085 train acc:88.51% val loss:0.1348 val acc:86.52%\n",
            "44/100 train loss:0.1061 train acc:88.76% val loss:0.1325 val acc:86.75%\n",
            "45/100 train loss:0.1011 train acc:89.24% val loss:0.1213 val acc:87.87%\n",
            "46/100 train loss:0.0955 train acc:89.81% val loss:0.1253 val acc:87.47%\n",
            "47/100 train loss:0.0974 train acc:89.61% val loss:0.1312 val acc:86.88%\n",
            "48/100 train loss:0.0924 train acc:90.12% val loss:0.1418 val acc:85.13%\n",
            "49/100 train loss:0.0944 train acc:89.90% val loss:0.1188 val acc:88.12%\n",
            "50/100 train loss:0.0912 train acc:90.24% val loss:0.1297 val acc:87.03%\n",
            "51/100 train loss:0.0999 train acc:89.31% val loss:0.1122 val acc:88.78%\n",
            "52/100 train loss:0.1022 train acc:89.11% val loss:0.1342 val acc:86.58%\n",
            "53/100 train loss:0.1088 train acc:88.41% val loss:0.1725 val acc:82.40%\n",
            "54/100 train loss:0.1020 train acc:89.08% val loss:0.1380 val acc:86.20%\n",
            "55/100 train loss:0.0987 train acc:89.46% val loss:0.1606 val acc:83.94%\n",
            "56/100 train loss:0.0939 train acc:89.95% val loss:0.1345 val acc:86.55%\n",
            "57/100 train loss:0.1090 train acc:88.38% val loss:0.1417 val acc:85.83%\n",
            "58/100 train loss:0.1019 train acc:89.13% val loss:0.1222 val acc:87.51%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        ['width at the top']\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                      ['width at the top']\n",
        "                       \n",
        "                      )\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-wt{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkq1JglY8nRh"
      },
      "source": [
        "## Width bottom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ext8gXOE8j_m",
        "outputId": "62930783-738b-4a6e-bc18-6457a5a5d115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.4981 train acc:40.20% val loss:0.3756 val acc:55.33%\n",
            "2/100 train loss:0.2650 train acc:69.72% val loss:0.2494 val acc:73.34%\n",
            "3/100 train loss:0.2077 train acc:77.56% val loss:0.8076 val acc:1.79%\n",
            "4/100 train loss:0.1845 train acc:80.56% val loss:0.6332 val acc:34.38%\n",
            "5/100 train loss:0.1622 train acc:82.80% val loss:0.1551 val acc:84.49%\n",
            "6/100 train loss:0.1621 train acc:82.82% val loss:0.1393 val acc:85.95%\n",
            "7/100 train loss:0.1503 train acc:83.98% val loss:0.3631 val acc:61.43%\n",
            "8/100 train loss:0.1444 train acc:84.65% val loss:0.1260 val acc:87.15%\n",
            "9/100 train loss:0.1362 train acc:85.55% val loss:0.1376 val acc:86.24%\n",
            "10/100 train loss:0.1363 train acc:85.52% val loss:0.1353 val acc:86.47%\n",
            "11/100 train loss:0.1459 train acc:84.48% val loss:0.1963 val acc:80.37%\n",
            "12/100 train loss:0.1396 train acc:85.22% val loss:0.1243 val acc:87.30%\n",
            "13/100 train loss:0.1306 train acc:86.06% val loss:0.1328 val acc:86.59%\n",
            "14/100 train loss:0.1272 train acc:86.48% val loss:0.2046 val acc:77.95%\n",
            "15/100 train loss:0.1392 train acc:85.08% val loss:0.1315 val acc:86.85%\n",
            "16/100 train loss:0.1268 train acc:86.58% val loss:0.1172 val acc:88.28%\n",
            "17/100 train loss:0.1327 train acc:85.89% val loss:0.1627 val acc:83.44%\n",
            "18/100 train loss:0.1359 train acc:85.55% val loss:0.1752 val acc:81.43%\n",
            "19/100 train loss:0.1294 train acc:86.21% val loss:0.1632 val acc:83.68%\n",
            "20/100 train loss:0.1310 train acc:86.11% val loss:0.1362 val acc:84.22%\n",
            "21/100 train loss:0.1352 train acc:85.59% val loss:0.1211 val acc:87.89%\n",
            "22/100 train loss:0.1354 train acc:85.55% val loss:0.1589 val acc:84.11%\n",
            "23/100 train loss:0.1406 train acc:85.00% val loss:0.2322 val acc:76.78%\n",
            "24/100 train loss:0.1310 train acc:86.04% val loss:0.1540 val acc:84.60%\n",
            "25/100 train loss:0.1447 train acc:84.62% val loss:0.6835 val acc:13.30%\n",
            "26/100 train loss:0.1445 train acc:84.55% val loss:0.6294 val acc:37.06%\n",
            "27/100 train loss:0.1317 train acc:85.91% val loss:0.7050 val acc:15.54%\n",
            "28/100 train loss:0.1319 train acc:85.86% val loss:0.5432 val acc:43.67%\n",
            "29/100 train loss:0.1248 train acc:86.67% val loss:0.1651 val acc:83.49%\n",
            "30/100 train loss:0.1348 train acc:85.42% val loss:0.3342 val acc:66.02%\n",
            "31/100 train loss:0.1361 train acc:85.35% val loss:0.1875 val acc:81.25%\n",
            "32/100 train loss:0.1256 train acc:86.63% val loss:0.6280 val acc:37.20%\n",
            "33/100 train loss:0.1295 train acc:86.18% val loss:0.1229 val acc:87.32%\n",
            "34/100 train loss:0.1229 train acc:86.93% val loss:0.1565 val acc:83.92%\n",
            "35/100 train loss:0.1237 train acc:86.85% val loss:0.1237 val acc:87.63%\n",
            "36/100 train loss:0.1287 train acc:86.25% val loss:0.1559 val acc:83.35%\n",
            "37/100 train loss:0.1276 train acc:86.42% val loss:0.1565 val acc:84.35%\n",
            "38/100 train loss:0.1256 train acc:86.31% val loss:0.1143 val acc:88.57%\n",
            "39/100 train loss:0.1243 train acc:86.64% val loss:0.1381 val acc:86.19%\n",
            "40/100 train loss:0.1218 train acc:86.95% val loss:0.1229 val acc:87.50%\n",
            "41/100 train loss:0.1167 train acc:87.43% val loss:0.1374 val acc:85.46%\n",
            "42/100 train loss:0.1143 train acc:87.68% val loss:0.1345 val acc:86.11%\n",
            "43/100 train loss:0.1162 train acc:87.57% val loss:0.2172 val acc:74.91%\n",
            "44/100 train loss:0.1158 train acc:87.71% val loss:0.1540 val acc:84.39%\n",
            "45/100 train loss:0.1150 train acc:87.73% val loss:0.1286 val acc:87.14%\n",
            "46/100 train loss:0.1203 train acc:87.14% val loss:0.1126 val acc:88.74%\n",
            "47/100 train loss:0.1124 train acc:87.94% val loss:0.1566 val acc:83.24%\n",
            "48/100 train loss:0.1186 train acc:87.30% val loss:0.1392 val acc:85.83%\n",
            "49/100 train loss:0.1137 train acc:87.86% val loss:0.1494 val acc:85.06%\n",
            "50/100 train loss:0.1206 train acc:86.88% val loss:0.1878 val acc:81.22%\n",
            "51/100 train loss:0.1171 train acc:87.38% val loss:0.1438 val acc:84.97%\n",
            "52/100 train loss:0.1099 train acc:88.15% val loss:0.1315 val acc:86.85%\n",
            "53/100 train loss:0.1126 train acc:87.91% val loss:0.1739 val acc:82.14%\n",
            "54/100 train loss:0.1282 train acc:86.00% val loss:0.1264 val acc:87.36%\n",
            "55/100 train loss:0.1322 train acc:85.64% val loss:0.1625 val acc:83.75%\n",
            "56/100 train loss:0.1494 train acc:83.99% val loss:0.1423 val acc:85.77%\n",
            "57/100 train loss:0.1332 train acc:85.93% val loss:0.3976 val acc:56.28%\n",
            "58/100 train loss:0.1243 train acc:86.86% val loss:0.1976 val acc:80.24%\n",
            "59/100 train loss:0.1724 train acc:81.86% val loss:0.2362 val acc:75.91%\n",
            "60/100 train loss:0.1521 train acc:84.05% val loss:0.2994 val acc:68.97%\n",
            "61/100 train loss:0.1811 train acc:80.91% val loss:0.5832 val acc:41.31%\n",
            "62/100 train loss:0.1548 train acc:83.73% val loss:0.1563 val acc:83.98%\n",
            "63/100 train loss:0.1341 train acc:85.92% val loss:0.1256 val acc:87.44%\n",
            "64/100 train loss:0.1216 train acc:87.17% val loss:0.1696 val acc:83.04%\n",
            "65/100 train loss:0.1315 train acc:86.20% val loss:0.1204 val acc:87.96%\n",
            "66/100 train loss:0.1168 train acc:87.67% val loss:0.1139 val acc:88.61%\n",
            "67/100 train loss:0.1141 train acc:87.94% val loss:0.1132 val acc:88.68%\n",
            "68/100 train loss:0.1315 train acc:86.14% val loss:0.2196 val acc:77.57%\n",
            "69/100 train loss:0.1296 train acc:86.32% val loss:0.4459 val acc:54.62%\n",
            "70/100 train loss:0.1201 train acc:87.33% val loss:0.1396 val acc:85.85%\n",
            "71/100 train loss:0.1243 train acc:86.91% val loss:0.4837 val acc:50.76%\n",
            "72/100 train loss:0.1250 train acc:86.83% val loss:0.1410 val acc:85.90%\n",
            "73/100 train loss:0.1127 train acc:88.07% val loss:0.1330 val acc:86.70%\n",
            "74/100 train loss:0.1112 train acc:88.22% val loss:0.1270 val acc:87.30%\n",
            "75/100 train loss:0.1094 train acc:88.42% val loss:0.1289 val acc:87.01%\n",
            "76/100 train loss:0.1044 train acc:88.92% val loss:0.1183 val acc:88.17%\n",
            "77/100 train loss:0.1053 train acc:88.83% val loss:0.1064 val acc:89.36%\n",
            "78/100 train loss:0.1066 train acc:88.70% val loss:0.1175 val acc:88.25%\n",
            "79/100 train loss:0.0988 train acc:89.48% val loss:0.1192 val acc:88.08%\n",
            "80/100 train loss:0.1036 train acc:88.98% val loss:0.1255 val acc:87.45%\n",
            "81/100 train loss:0.0981 train acc:89.55% val loss:0.1194 val acc:88.06%\n",
            "82/100 train loss:0.0979 train acc:89.57% val loss:0.1257 val acc:87.35%\n",
            "83/100 train loss:0.0959 train acc:89.77% val loss:0.1095 val acc:89.05%\n",
            "84/100 train loss:0.0954 train acc:89.83% val loss:0.1280 val acc:87.20%\n",
            "85/100 train loss:0.0992 train acc:89.42% val loss:0.1392 val acc:86.08%\n",
            "86/100 train loss:0.1171 train acc:87.55% val loss:0.1314 val acc:86.60%\n",
            "87/100 train loss:0.1047 train acc:88.86% val loss:0.1129 val acc:88.71%\n",
            "88/100 train loss:0.1042 train acc:88.90% val loss:0.1233 val acc:87.35%\n",
            "89/100 train loss:0.1020 train acc:89.12% val loss:0.1079 val acc:89.21%\n",
            "90/100 train loss:0.0971 train acc:89.63% val loss:0.1083 val acc:89.17%\n",
            "91/100 train loss:0.1007 train acc:89.24% val loss:0.1148 val acc:88.52%\n",
            "92/100 train loss:0.1051 train acc:88.84% val loss:0.1005 val acc:89.95%\n",
            "93/100 train loss:0.1104 train acc:88.27% val loss:0.1218 val acc:87.73%\n",
            "94/100 train loss:0.1228 train acc:86.90% val loss:0.1530 val acc:84.70%\n",
            "95/100 train loss:0.1125 train acc:88.03% val loss:0.1242 val acc:87.58%\n",
            "96/100 train loss:0.1084 train acc:88.48% val loss:0.1205 val acc:87.95%\n",
            "97/100 train loss:0.1239 train acc:86.83% val loss:0.1313 val acc:86.87%\n",
            "98/100 train loss:0.1114 train acc:88.14% val loss:0.1260 val acc:87.40%\n",
            "99/100 train loss:0.1033 train acc:89.01% val loss:0.1099 val acc:88.89%\n",
            "100/100 train loss:0.1052 train acc:88.77% val loss:0.2345 val acc:76.55%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        ['width at the bottom']\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                      ['width at the bottom']\n",
        "                       \n",
        "                      )\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-wb{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer"
      ],
      "metadata": {
        "id": "JWvyZzfyDEwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb')\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                        '/content/test/labels', \n",
        "                        '/content/test/crops_depth',\n",
        "                        '/content/test/crops_rgb')\n",
        "model = MobileNetV3_Large(num_classes=1)\n",
        "pretrain = '/content/drive/MyDrive/COSRMAL_CHALLENGE/audios/RGBD/mobile-wt88.78.pth'\n",
        "model.load_state_dict(torch.load(pretrain))\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ],
      "metadata": {
        "id": "LhT4LV8BDGNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53bfa135-315a-4474-cb79-bf3a49259db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.3746 train acc:57.25% val loss:0.3028 val acc:68.45%\n",
            "2/100 train loss:0.2891 train acc:67.07% val loss:0.2930 val acc:70.70%\n",
            "3/100 train loss:0.2518 train acc:72.43% val loss:0.5375 val acc:41.42%\n",
            "4/100 train loss:0.2243 train acc:75.84% val loss:0.4622 val acc:53.36%\n",
            "5/100 train loss:0.2000 train acc:79.29% val loss:0.2390 val acc:76.10%\n",
            "6/100 train loss:0.1855 train acc:80.82% val loss:0.3805 val acc:61.11%\n",
            "7/100 train loss:0.1857 train acc:80.79% val loss:0.2686 val acc:73.14%\n",
            "8/100 train loss:0.1731 train acc:82.03% val loss:0.2466 val acc:75.34%\n",
            "9/100 train loss:0.1703 train acc:82.31% val loss:0.2486 val acc:75.14%\n",
            "10/100 train loss:0.1826 train acc:81.02% val loss:0.3201 val acc:67.99%\n",
            "11/100 train loss:0.1669 train acc:82.62% val loss:0.2178 val acc:78.22%\n",
            "12/100 train loss:0.1493 train acc:84.40% val loss:0.2141 val acc:78.34%\n",
            "13/100 train loss:0.1418 train acc:85.17% val loss:0.2774 val acc:72.26%\n",
            "14/100 train loss:0.1373 train acc:85.62% val loss:0.1745 val acc:82.55%\n",
            "15/100 train loss:0.1347 train acc:85.89% val loss:0.1759 val acc:82.41%\n",
            "16/100 train loss:0.1250 train acc:86.86% val loss:0.1758 val acc:82.42%\n",
            "17/100 train loss:0.1367 train acc:85.63% val loss:0.1946 val acc:80.54%\n",
            "18/100 train loss:0.1351 train acc:85.81% val loss:0.1841 val acc:81.59%\n",
            "19/100 train loss:0.1669 train acc:82.47% val loss:0.2173 val acc:78.27%\n",
            "20/100 train loss:0.1462 train acc:84.70% val loss:0.1907 val acc:80.93%\n",
            "21/100 train loss:0.1404 train acc:85.32% val loss:0.2368 val acc:76.32%\n",
            "22/100 train loss:0.1292 train acc:86.43% val loss:0.1759 val acc:82.41%\n",
            "23/100 train loss:0.1347 train acc:85.87% val loss:0.2115 val acc:78.69%\n",
            "24/100 train loss:0.1400 train acc:85.34% val loss:0.4032 val acc:59.68%\n",
            "25/100 train loss:0.1584 train acc:83.48% val loss:0.3096 val acc:69.04%\n",
            "26/100 train loss:0.1356 train acc:85.79% val loss:0.9540 val acc:4.60%\n",
            "27/100 train loss:0.1499 train acc:84.37% val loss:0.1767 val acc:82.33%\n",
            "28/100 train loss:0.1327 train acc:86.08% val loss:0.1661 val acc:83.39%\n",
            "29/100 train loss:0.1303 train acc:86.33% val loss:0.1596 val acc:83.82%\n",
            "30/100 train loss:0.1317 train acc:86.18% val loss:0.2065 val acc:79.35%\n",
            "31/100 train loss:0.1403 train acc:85.29% val loss:0.3059 val acc:69.41%\n",
            "32/100 train loss:0.1364 train acc:85.70% val loss:0.1844 val acc:81.12%\n",
            "33/100 train loss:0.1385 train acc:85.49% val loss:0.1873 val acc:81.27%\n",
            "34/100 train loss:0.1287 train acc:86.49% val loss:0.1694 val acc:83.06%\n",
            "35/100 train loss:0.1218 train acc:87.18% val loss:0.3677 val acc:63.23%\n",
            "36/100 train loss:0.1433 train acc:84.98% val loss:0.1463 val acc:85.37%\n",
            "37/100 train loss:0.1300 train acc:86.35% val loss:0.2236 val acc:77.64%\n",
            "38/100 train loss:0.1448 train acc:84.86% val loss:0.2030 val acc:79.70%\n",
            "39/100 train loss:0.1310 train acc:86.27% val loss:0.1863 val acc:81.37%\n",
            "40/100 train loss:0.1300 train acc:86.36% val loss:0.2112 val acc:78.88%\n",
            "41/100 train loss:0.1340 train acc:85.95% val loss:0.1748 val acc:82.52%\n",
            "42/100 train loss:0.1373 train acc:85.63% val loss:0.3486 val acc:65.14%\n",
            "43/100 train loss:0.1411 train acc:85.21% val loss:0.1590 val acc:84.10%\n",
            "44/100 train loss:0.1280 train acc:86.54% val loss:0.1849 val acc:81.51%\n",
            "45/100 train loss:0.1195 train acc:87.41% val loss:0.1460 val acc:85.40%\n",
            "46/100 train loss:0.1230 train acc:87.03% val loss:0.2895 val acc:71.05%\n",
            "47/100 train loss:0.1249 train acc:86.88% val loss:0.1461 val acc:85.39%\n",
            "48/100 train loss:0.1291 train acc:86.44% val loss:0.1956 val acc:80.44%\n",
            "49/100 train loss:0.1294 train acc:86.43% val loss:0.1640 val acc:83.60%\n",
            "50/100 train loss:0.1245 train acc:86.92% val loss:0.1554 val acc:84.46%\n",
            "51/100 train loss:0.1223 train acc:87.13% val loss:0.9799 val acc:2.01%\n",
            "52/100 train loss:0.1230 train acc:87.04% val loss:0.1692 val acc:83.08%\n",
            "53/100 train loss:0.1255 train acc:86.80% val loss:0.1918 val acc:80.82%\n",
            "54/100 train loss:0.1263 train acc:86.74% val loss:0.1606 val acc:83.94%\n",
            "55/100 train loss:0.1223 train acc:87.13% val loss:0.1611 val acc:83.89%\n",
            "56/100 train loss:0.1174 train acc:87.62% val loss:0.1517 val acc:84.83%\n",
            "57/100 train loss:0.1181 train acc:87.55% val loss:0.1618 val acc:83.82%\n",
            "58/100 train loss:0.1166 train acc:87.70% val loss:0.9663 val acc:3.37%\n",
            "59/100 train loss:0.1165 train acc:87.72% val loss:1.0000 val acc:0.00%\n",
            "60/100 train loss:0.1165 train acc:87.71% val loss:0.1878 val acc:81.22%\n",
            "61/100 train loss:0.1122 train acc:88.14% val loss:0.1930 val acc:80.70%\n",
            "62/100 train loss:0.1129 train acc:88.06% val loss:0.1784 val acc:82.16%\n",
            "63/100 train loss:0.1110 train acc:88.25% val loss:0.2866 val acc:71.34%\n",
            "64/100 train loss:0.1076 train acc:88.58% val loss:0.2465 val acc:75.35%\n",
            "65/100 train loss:0.1090 train acc:88.47% val loss:0.1620 val acc:83.80%\n",
            "66/100 train loss:0.1093 train acc:88.43% val loss:0.2970 val acc:70.30%\n",
            "67/100 train loss:0.1020 train acc:89.16% val loss:0.1807 val acc:81.80%\n",
            "68/100 train loss:0.0972 train acc:89.64% val loss:0.1855 val acc:81.45%\n",
            "69/100 train loss:0.0982 train acc:89.54% val loss:0.1555 val acc:84.45%\n",
            "70/100 train loss:0.1063 train acc:88.74% val loss:0.1683 val acc:83.17%\n",
            "71/100 train loss:0.1120 train acc:88.16% val loss:0.1663 val acc:83.37%\n",
            "72/100 train loss:0.1122 train acc:88.14% val loss:0.2364 val acc:76.36%\n",
            "73/100 train loss:0.1426 train acc:85.09% val loss:0.3598 val acc:64.02%\n",
            "74/100 train loss:0.1618 train acc:83.15% val loss:0.2017 val acc:79.83%\n",
            "75/100 train loss:0.1455 train acc:84.82% val loss:0.1715 val acc:82.56%\n",
            "76/100 train loss:0.1325 train acc:86.10% val loss:0.2077 val acc:79.23%\n",
            "77/100 train loss:0.1291 train acc:86.46% val loss:0.1949 val acc:80.51%\n",
            "78/100 train loss:0.1284 train acc:86.53% val loss:0.1663 val acc:83.37%\n",
            "79/100 train loss:0.1287 train acc:86.49% val loss:0.1602 val acc:83.98%\n",
            "80/100 train loss:0.1308 train acc:86.29% val loss:0.1658 val acc:83.42%\n",
            "81/100 train loss:0.1219 train acc:87.17% val loss:0.1675 val acc:83.25%\n",
            "82/100 train loss:0.1203 train acc:87.34% val loss:0.1475 val acc:85.25%\n",
            "83/100 train loss:0.1359 train acc:85.74% val loss:0.1603 val acc:83.97%\n",
            "84/100 train loss:0.1243 train acc:86.94% val loss:0.1520 val acc:84.80%\n",
            "85/100 train loss:0.1207 train acc:87.29% val loss:0.1536 val acc:84.19%\n",
            "86/100 train loss:0.1313 train acc:86.12% val loss:0.1694 val acc:83.06%\n",
            "87/100 train loss:0.1430 train acc:84.92% val loss:0.1827 val acc:81.73%\n",
            "88/100 train loss:0.1416 train acc:85.20% val loss:0.1586 val acc:84.14%\n",
            "89/100 train loss:0.1240 train acc:86.96% val loss:0.1517 val acc:84.83%\n",
            "90/100 train loss:0.1197 train acc:87.40% val loss:0.1615 val acc:83.85%\n",
            "91/100 train loss:0.1230 train acc:87.06% val loss:0.1519 val acc:84.81%\n",
            "92/100 train loss:0.1144 train acc:87.93% val loss:0.1434 val acc:85.66%\n",
            "93/100 train loss:0.1130 train acc:88.06% val loss:0.1550 val acc:84.50%\n",
            "94/100 train loss:0.1096 train acc:88.41% val loss:0.1555 val acc:84.45%\n",
            "95/100 train loss:0.1204 train acc:87.32% val loss:0.2165 val acc:78.35%\n",
            "96/100 train loss:0.1329 train acc:86.07% val loss:0.1952 val acc:80.24%\n",
            "97/100 train loss:0.1235 train acc:86.96% val loss:0.1524 val acc:84.76%\n",
            "98/100 train loss:0.1134 train acc:88.02% val loss:0.1394 val acc:86.06%\n",
            "99/100 train loss:0.1056 train acc:88.80% val loss:0.1385 val acc:86.15%\n",
            "100/100 train loss:0.1076 train acc:88.61% val loss:0.1366 val acc:86.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-4\n",
        "epochs = 200\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        ['container mass']\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                      ['container mass']          \n",
        "                      )\n",
        "model = MobileNetV3_Large(num_classes=1)\n",
        "pretrain = '/content/drive/MyDrive/COSRMAL_CHALLENGE/audios/RGBD/mobile-wt88.78.pth'\n",
        "model.load_state_dict(torch.load(pretrain))\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-mass{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57TzJw_TNFm-",
        "outputId": "df2a1b24-aa49-4ae1-8044-bdbd831f5cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "1/200 train loss:0.7068 train acc:28.62% val loss:0.6739 val acc:32.33%\n",
            "2/200 train loss:0.6874 train acc:30.53% val loss:0.6544 val acc:34.56%\n",
            "3/200 train loss:0.6820 train acc:31.10% val loss:0.6364 val acc:36.36%\n",
            "4/200 train loss:0.6744 train acc:31.85% val loss:0.6362 val acc:36.38%\n",
            "5/200 train loss:0.6648 train acc:32.74% val loss:0.6391 val acc:35.65%\n",
            "6/200 train loss:0.6571 train acc:33.54% val loss:0.6412 val acc:35.59%\n",
            "7/200 train loss:0.6421 train acc:35.06% val loss:0.6135 val acc:38.65%\n",
            "8/200 train loss:0.6359 train acc:35.60% val loss:0.6261 val acc:37.39%\n",
            "9/200 train loss:0.6373 train acc:35.43% val loss:0.5957 val acc:40.43%\n",
            "10/200 train loss:0.6311 train acc:36.15% val loss:0.6008 val acc:39.92%\n",
            "11/200 train loss:0.6232 train acc:36.84% val loss:0.5813 val acc:41.61%\n",
            "12/200 train loss:0.6133 train acc:37.92% val loss:0.5554 val acc:44.22%\n",
            "13/200 train loss:0.6044 train acc:38.81% val loss:0.5662 val acc:43.38%\n",
            "14/200 train loss:0.5993 train acc:39.37% val loss:0.5565 val acc:44.35%\n",
            "15/200 train loss:0.5899 train acc:40.26% val loss:0.5218 val acc:47.82%\n",
            "16/200 train loss:0.5834 train acc:40.99% val loss:0.4947 val acc:50.53%\n",
            "17/200 train loss:0.5674 train acc:42.63% val loss:0.4837 val acc:51.42%\n",
            "18/200 train loss:0.5427 train acc:45.08% val loss:0.4796 val acc:52.04%\n",
            "19/200 train loss:0.5205 train acc:47.31% val loss:0.4698 val acc:52.74%\n",
            "20/200 train loss:0.5144 train acc:47.88% val loss:0.4527 val acc:54.73%\n",
            "21/200 train loss:0.4992 train acc:49.44% val loss:0.4560 val acc:54.40%\n",
            "22/200 train loss:0.4914 train acc:50.21% val loss:0.4572 val acc:54.28%\n",
            "23/200 train loss:0.4863 train acc:50.71% val loss:0.4410 val acc:55.90%\n",
            "24/200 train loss:0.4782 train acc:51.55% val loss:0.4336 val acc:56.64%\n",
            "25/200 train loss:0.4772 train acc:51.63% val loss:0.4365 val acc:56.35%\n",
            "26/200 train loss:0.4744 train acc:51.92% val loss:0.4387 val acc:56.13%\n",
            "27/200 train loss:0.4679 train acc:52.58% val loss:0.4323 val acc:56.77%\n",
            "28/200 train loss:0.4606 train acc:53.29% val loss:0.4305 val acc:56.95%\n",
            "29/200 train loss:0.4624 train acc:53.12% val loss:0.4322 val acc:56.78%\n",
            "30/200 train loss:0.4536 train acc:54.00% val loss:0.4380 val acc:56.20%\n",
            "31/200 train loss:0.4536 train acc:54.00% val loss:0.4280 val acc:57.20%\n",
            "32/200 train loss:0.4464 train acc:54.73% val loss:0.4231 val acc:57.69%\n",
            "33/200 train loss:0.4517 train acc:54.19% val loss:0.4376 val acc:56.24%\n",
            "34/200 train loss:0.4480 train acc:54.56% val loss:0.4303 val acc:56.97%\n",
            "35/200 train loss:0.4490 train acc:54.47% val loss:0.4291 val acc:57.09%\n",
            "36/200 train loss:0.4375 train acc:55.61% val loss:0.4116 val acc:58.84%\n",
            "37/200 train loss:0.4373 train acc:55.63% val loss:0.4084 val acc:59.16%\n",
            "38/200 train loss:0.4375 train acc:55.61% val loss:0.4150 val acc:58.50%\n",
            "39/200 train loss:0.4318 train acc:56.18% val loss:0.4162 val acc:58.38%\n",
            "40/200 train loss:0.4331 train acc:56.04% val loss:0.4057 val acc:59.43%\n",
            "41/200 train loss:0.4368 train acc:55.65% val loss:0.4092 val acc:59.08%\n",
            "42/200 train loss:0.4353 train acc:55.83% val loss:0.4211 val acc:57.89%\n",
            "43/200 train loss:0.4351 train acc:55.85% val loss:0.4229 val acc:57.71%\n",
            "44/200 train loss:0.4446 train acc:54.45% val loss:0.4512 val acc:53.47%\n",
            "45/200 train loss:0.4022 train acc:58.85% val loss:0.4252 val acc:57.34%\n",
            "46/200 train loss:0.3625 train acc:63.05% val loss:0.3847 val acc:61.53%\n",
            "47/200 train loss:0.3424 train acc:65.01% val loss:0.3540 val acc:64.60%\n",
            "48/200 train loss:0.3440 train acc:64.90% val loss:0.3335 val acc:66.65%\n",
            "49/200 train loss:0.3261 train acc:66.71% val loss:0.3435 val acc:65.65%\n",
            "50/200 train loss:0.3202 train acc:67.33% val loss:0.3530 val acc:64.70%\n",
            "51/200 train loss:0.3247 train acc:66.87% val loss:0.3407 val acc:65.93%\n",
            "52/200 train loss:0.3080 train acc:68.57% val loss:0.3278 val acc:67.22%\n",
            "53/200 train loss:0.3019 train acc:69.17% val loss:0.3274 val acc:67.26%\n",
            "54/200 train loss:0.3003 train acc:69.33% val loss:0.3242 val acc:67.58%\n",
            "55/200 train loss:0.2846 train acc:70.90% val loss:0.3060 val acc:69.40%\n",
            "56/200 train loss:0.2879 train acc:70.57% val loss:0.2837 val acc:71.63%\n",
            "57/200 train loss:0.2823 train acc:71.12% val loss:0.2888 val acc:71.12%\n",
            "58/200 train loss:0.2729 train acc:72.06% val loss:0.2914 val acc:70.86%\n",
            "59/200 train loss:0.2762 train acc:71.73% val loss:0.2952 val acc:70.48%\n",
            "60/200 train loss:0.2721 train acc:72.14% val loss:0.3024 val acc:69.76%\n",
            "61/200 train loss:0.2601 train acc:73.35% val loss:0.2816 val acc:71.84%\n",
            "62/200 train loss:0.2611 train acc:73.25% val loss:0.2851 val acc:71.49%\n",
            "63/200 train loss:0.2621 train acc:73.15% val loss:0.2650 val acc:73.50%\n",
            "64/200 train loss:0.2667 train acc:72.68% val loss:0.2785 val acc:72.15%\n",
            "65/200 train loss:0.2516 train acc:74.20% val loss:0.2932 val acc:70.68%\n",
            "66/200 train loss:0.2482 train acc:74.52% val loss:0.2820 val acc:71.80%\n",
            "67/200 train loss:0.2594 train acc:73.42% val loss:0.2809 val acc:71.91%\n",
            "68/200 train loss:0.2576 train acc:73.61% val loss:0.2761 val acc:72.39%\n",
            "69/200 train loss:0.2633 train acc:73.04% val loss:0.2848 val acc:71.52%\n",
            "70/200 train loss:0.2587 train acc:73.47% val loss:0.2838 val acc:71.62%\n",
            "71/200 train loss:0.2588 train acc:73.46% val loss:0.3077 val acc:69.23%\n",
            "72/200 train loss:0.2515 train acc:74.20% val loss:0.3003 val acc:69.97%\n",
            "73/200 train loss:0.2435 train acc:75.02% val loss:0.2931 val acc:70.69%\n",
            "74/200 train loss:0.2397 train acc:75.39% val loss:0.3104 val acc:68.96%\n",
            "75/200 train loss:0.2466 train acc:74.69% val loss:0.3144 val acc:68.56%\n",
            "76/200 train loss:0.2514 train acc:74.22% val loss:0.3136 val acc:68.64%\n",
            "77/200 train loss:0.2467 train acc:74.68% val loss:0.3208 val acc:67.92%\n",
            "78/200 train loss:0.2486 train acc:74.50% val loss:0.2985 val acc:70.15%\n",
            "79/200 train loss:0.2422 train acc:75.14% val loss:0.2905 val acc:70.52%\n",
            "80/200 train loss:0.2332 train acc:76.05% val loss:0.3145 val acc:68.55%\n",
            "81/200 train loss:0.2272 train acc:76.65% val loss:0.2981 val acc:70.19%\n",
            "82/200 train loss:0.2283 train acc:76.53% val loss:0.3072 val acc:69.28%\n",
            "83/200 train loss:0.2308 train acc:76.28% val loss:0.3023 val acc:69.77%\n",
            "84/200 train loss:0.2302 train acc:76.34% val loss:0.3061 val acc:69.39%\n",
            "85/200 train loss:0.2328 train acc:76.08% val loss:0.2891 val acc:71.09%\n",
            "86/200 train loss:0.2401 train acc:75.36% val loss:0.2932 val acc:70.68%\n",
            "87/200 train loss:0.2218 train acc:77.17% val loss:0.2884 val acc:71.16%\n",
            "88/200 train loss:0.2281 train acc:76.56% val loss:0.2941 val acc:70.59%\n",
            "89/200 train loss:0.2255 train acc:76.81% val loss:0.3036 val acc:69.64%\n",
            "90/200 train loss:0.2223 train acc:77.13% val loss:0.2958 val acc:70.24%\n",
            "91/200 train loss:0.2266 train acc:76.70% val loss:0.3002 val acc:69.98%\n",
            "92/200 train loss:0.2348 train acc:75.87% val loss:0.2933 val acc:70.67%\n",
            "93/200 train loss:0.2266 train acc:76.68% val loss:0.2770 val acc:72.30%\n",
            "94/200 train loss:0.2211 train acc:77.23% val loss:0.3019 val acc:69.81%\n",
            "95/200 train loss:0.2242 train acc:76.95% val loss:0.2784 val acc:72.16%\n",
            "96/200 train loss:0.2190 train acc:77.46% val loss:0.2730 val acc:72.70%\n",
            "97/200 train loss:0.2237 train acc:76.99% val loss:0.2843 val acc:71.57%\n",
            "98/200 train loss:0.2152 train acc:77.84% val loss:0.2775 val acc:72.25%\n",
            "99/200 train loss:0.2165 train acc:77.71% val loss:0.2790 val acc:72.10%\n",
            "100/200 train loss:0.2178 train acc:77.59% val loss:0.2701 val acc:72.99%\n",
            "101/200 train loss:0.2139 train acc:77.97% val loss:0.2956 val acc:70.44%\n",
            "102/200 train loss:0.2220 train acc:77.16% val loss:0.2716 val acc:72.84%\n",
            "103/200 train loss:0.2157 train acc:77.79% val loss:0.2878 val acc:71.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentation"
      ],
      "metadata": {
        "id": "GqsKRBKNiLuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def randomlyAug(crop, depth, label, max_val=640):\n",
        "  h, w, c = crop.shape\n",
        "\n",
        "  if h >= w:\n",
        "    max_dim = h\n",
        "  else:\n",
        "    max_dim = w\n",
        "  max_rand = max_val / max_dim\n",
        "\n",
        "  rand_num = np.random.uniform(0.5,max_rand,1).item()\n",
        "\n",
        "  width = int(w * rand_num)\n",
        "  height = int(h * rand_num)\n",
        "  dim = (width, height)\n",
        "    \n",
        "  # resize image\n",
        "  crop = cv2.resize(crop, dim, interpolation = cv2.INTER_AREA)\n",
        "  depth = cv2.resize(depth, dim, interpolation = cv2.INTER_NEAREST)[:, :, np.newaxis]\n",
        "\n",
        "  label *= (height / h)\n",
        "\n",
        "  \n",
        "  \n",
        "  return crop, depth, label\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "def get_annotation(id,input,anno_path='/content/labels'):\n",
        "    anno = np.load(os.path.join(anno_path,'{:06d}.npy'.format(id)),allow_pickle=True).item()\n",
        "    return anno.get(input)\n",
        "    \n",
        "\n",
        "class MiniDataset(Dataset):\n",
        "    def __init__(self, base_p, label_f, depth, crops_rgb_f, aug=False, label_name=['container capacity']):\n",
        "      self.label_f = label_f #_f = folder\n",
        "      self.depth = depth\n",
        "      self.base = base_p\n",
        "      self.label_name = label_name\n",
        "      self.crops_rgb_f = crops_rgb_f\n",
        "      self.samples = os.listdir(crops_rgb_f)\n",
        "      self.ids = [ int(x.split('.')[0]) for x in self.samples]\n",
        "      self.transform = transforms.Compose([\n",
        "                                             transforms.Resize((320, 320)),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.ConvertImageDtype(torch.float),\n",
        "                                             ])\n",
        "      self.aug = aug\n",
        "    def __len__(self):\n",
        "      return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      id_ = self.ids[idx]\n",
        "        \n",
        "      # depth\n",
        "      depth = np.asarray(Image.open(os.path.join(self.depth,'{:06d}.png'.format(id_))))[:,:,np.newaxis]\n",
        "      \n",
        "      # rgb_cropped\n",
        "      crop = np.asarray(Image.open(os.path.join(self.crops_rgb_f,'{:06d}.png'.format(id_))))\n",
        "      # label\n",
        "      label = np.array([get_annotation(id_,name,os.path.join(self.base, 'labels')) for name in self.label_name])\n",
        "\n",
        "      if self.aug:\n",
        "          crop, depth, label = randomlyAug(crop, depth, label, max_val=640)\n",
        "\n",
        "      h, w, c = crop.shape\n",
        "\n",
        "      resX = 640 - h\n",
        "      resY = 640 - w\n",
        "\n",
        "      up = resX // 2\n",
        "      down = up\n",
        "      if resX % 2 != 0:\n",
        "        down +=1\n",
        "\n",
        "      left = resY // 2\n",
        "      right = left\n",
        "\n",
        "      if resY % 2 != 0:\n",
        "        left += 1\n",
        "\n",
        "      padding = transforms.Pad((left, up, right, down))\n",
        "\n",
        "    \n",
        "      image = Image.fromarray(np.concatenate((crop, depth), axis=2))\n",
        "      image = padding(image)\n",
        "      image = self.transform(image)\n",
        "      \n",
        "\n",
        "      return image, label"
      ],
      "metadata": {
        "id": "GCr38T3ViNPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        aug=True)\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                        '/content/test/labels', \n",
        "                        '/content/test/crops_depth',\n",
        "                        '/content/test/crops_rgb')\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-aug{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohku2D3FiTO7",
        "outputId": "2b932682-767d-49b6-b39a-8d2f57026098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.6046 train acc:21.23% val loss:0.5439 val acc:37.81%\n",
            "2/100 train loss:0.5463 train acc:29.05% val loss:0.3676 val acc:62.11%\n",
            "3/100 train loss:0.5021 train acc:38.07% val loss:0.3545 val acc:63.48%\n",
            "4/100 train loss:0.4593 train acc:44.55% val loss:0.3810 val acc:58.59%\n",
            "5/100 train loss:0.4084 train acc:52.29% val loss:0.3735 val acc:62.35%\n",
            "6/100 train loss:0.3723 train acc:58.19% val loss:0.3151 val acc:68.20%\n",
            "7/100 train loss:0.3370 train acc:62.11% val loss:0.2992 val acc:70.08%\n",
            "8/100 train loss:0.2984 train acc:67.44% val loss:0.7842 val acc:21.58%\n",
            "9/100 train loss:0.2751 train acc:71.59% val loss:0.2216 val acc:77.84%\n",
            "10/100 train loss:0.2663 train acc:72.74% val loss:0.4636 val acc:53.64%\n",
            "11/100 train loss:0.2620 train acc:73.17% val loss:0.2832 val acc:71.68%\n",
            "12/100 train loss:0.2506 train acc:74.30% val loss:0.2553 val acc:74.47%\n",
            "13/100 train loss:0.2387 train acc:75.49% val loss:0.2207 val acc:77.93%\n",
            "14/100 train loss:0.2356 train acc:75.80% val loss:0.2476 val acc:75.24%\n",
            "15/100 train loss:0.2332 train acc:76.04% val loss:0.2210 val acc:77.90%\n",
            "16/100 train loss:0.2267 train acc:76.69% val loss:0.2214 val acc:77.86%\n",
            "17/100 train loss:0.2355 train acc:75.81% val loss:0.2840 val acc:71.60%\n",
            "18/100 train loss:0.2350 train acc:75.87% val loss:0.2486 val acc:75.14%\n",
            "19/100 train loss:0.2407 train acc:75.29% val loss:0.8346 val acc:16.54%\n",
            "20/100 train loss:0.2324 train acc:76.12% val loss:0.2250 val acc:77.50%\n",
            "21/100 train loss:0.2243 train acc:76.93% val loss:0.2159 val acc:78.41%\n",
            "22/100 train loss:0.2242 train acc:76.95% val loss:0.9636 val acc:3.64%\n",
            "23/100 train loss:0.2566 train acc:73.70% val loss:0.2300 val acc:77.00%\n",
            "24/100 train loss:0.2322 train acc:76.14% val loss:0.2420 val acc:75.80%\n",
            "25/100 train loss:0.2221 train acc:77.16% val loss:0.5667 val acc:43.33%\n",
            "26/100 train loss:0.2240 train acc:76.96% val loss:0.2356 val acc:76.44%\n",
            "27/100 train loss:0.2214 train acc:77.23% val loss:0.2734 val acc:72.66%\n",
            "28/100 train loss:0.2466 train acc:74.71% val loss:0.2572 val acc:74.28%\n",
            "29/100 train loss:0.2562 train acc:73.74% val loss:0.2233 val acc:77.67%\n",
            "30/100 train loss:0.2362 train acc:75.74% val loss:0.2555 val acc:74.45%\n",
            "31/100 train loss:0.2310 train acc:76.26% val loss:0.4714 val acc:52.86%\n",
            "32/100 train loss:0.2384 train acc:75.53% val loss:0.2160 val acc:78.40%\n",
            "33/100 train loss:0.2316 train acc:76.21% val loss:0.2121 val acc:78.79%\n",
            "34/100 train loss:0.2242 train acc:76.95% val loss:0.3048 val acc:69.52%\n",
            "35/100 train loss:0.2474 train acc:74.62% val loss:0.2977 val acc:70.23%\n",
            "36/100 train loss:0.2319 train acc:76.17% val loss:0.2512 val acc:74.88%\n",
            "37/100 train loss:0.2319 train acc:76.17% val loss:0.2719 val acc:72.81%\n",
            "38/100 train loss:0.2220 train acc:77.17% val loss:0.8565 val acc:14.35%\n",
            "39/100 train loss:0.2181 train acc:77.56% val loss:0.2584 val acc:74.16%\n",
            "40/100 train loss:0.2291 train acc:76.45% val loss:0.2074 val acc:79.26%\n",
            "41/100 train loss:0.2227 train acc:77.09% val loss:0.2467 val acc:75.33%\n",
            "42/100 train loss:0.2299 train acc:76.37% val loss:0.2422 val acc:75.78%\n",
            "43/100 train loss:0.2159 train acc:77.78% val loss:0.2253 val acc:77.47%\n",
            "44/100 train loss:0.2152 train acc:77.84% val loss:0.2333 val acc:76.67%\n",
            "45/100 train loss:0.2146 train acc:77.90% val loss:0.2057 val acc:79.43%\n",
            "46/100 train loss:0.2144 train acc:77.92% val loss:0.3882 val acc:60.89%\n",
            "47/100 train loss:0.2197 train acc:77.39% val loss:0.2234 val acc:77.66%\n",
            "48/100 train loss:0.2185 train acc:77.52% val loss:0.2487 val acc:75.13%\n",
            "49/100 train loss:0.2109 train acc:78.27% val loss:0.2591 val acc:74.09%\n",
            "50/100 train loss:0.2056 train acc:78.80% val loss:0.2225 val acc:77.75%\n",
            "51/100 train loss:0.2026 train acc:79.10% val loss:0.2538 val acc:74.62%\n",
            "52/100 train loss:0.2047 train acc:78.90% val loss:0.8094 val acc:19.06%\n",
            "53/100 train loss:0.2106 train acc:78.31% val loss:0.2193 val acc:77.54%\n",
            "54/100 train loss:0.2066 train acc:78.71% val loss:0.2126 val acc:78.74%\n",
            "55/100 train loss:0.1983 train acc:79.54% val loss:0.2434 val acc:75.66%\n",
            "56/100 train loss:0.1978 train acc:79.59% val loss:0.2151 val acc:78.49%\n",
            "57/100 train loss:0.2041 train acc:78.95% val loss:0.2419 val acc:75.81%\n",
            "58/100 train loss:0.2177 train acc:77.60% val loss:0.2445 val acc:75.55%\n",
            "59/100 train loss:0.2056 train acc:78.81% val loss:0.2280 val acc:77.20%\n",
            "60/100 train loss:0.2018 train acc:79.18% val loss:0.6748 val acc:32.52%\n",
            "61/100 train loss:0.1960 train acc:79.76% val loss:0.4527 val acc:54.73%\n",
            "62/100 train loss:0.2148 train acc:77.89% val loss:0.2585 val acc:74.15%\n",
            "63/100 train loss:0.2054 train acc:78.83% val loss:0.9043 val acc:9.57%\n",
            "64/100 train loss:0.2280 train acc:76.56% val loss:0.2308 val acc:76.92%\n",
            "65/100 train loss:0.2182 train acc:77.55% val loss:0.7865 val acc:21.35%\n",
            "66/100 train loss:0.2069 train acc:78.68% val loss:0.2431 val acc:75.69%\n",
            "67/100 train loss:0.2040 train acc:78.96% val loss:0.2715 val acc:72.85%\n",
            "68/100 train loss:0.2033 train acc:79.04% val loss:0.2269 val acc:77.04%\n",
            "69/100 train loss:0.1977 train acc:79.60% val loss:0.7976 val acc:20.24%\n",
            "70/100 train loss:0.1978 train acc:79.59% val loss:0.2292 val acc:77.08%\n",
            "71/100 train loss:0.1972 train acc:79.65% val loss:0.2414 val acc:75.86%\n",
            "72/100 train loss:0.1977 train acc:79.59% val loss:0.2264 val acc:77.36%\n",
            "73/100 train loss:0.1917 train acc:80.19% val loss:0.2749 val acc:72.51%\n",
            "74/100 train loss:0.1955 train acc:79.81% val loss:0.2208 val acc:77.92%\n",
            "75/100 train loss:0.1885 train acc:80.51% val loss:0.2195 val acc:78.05%\n",
            "76/100 train loss:0.1900 train acc:80.37% val loss:0.2212 val acc:77.88%\n",
            "77/100 train loss:0.1824 train acc:81.12% val loss:0.2279 val acc:77.21%\n",
            "78/100 train loss:0.1833 train acc:81.03% val loss:0.2107 val acc:78.93%\n",
            "79/100 train loss:0.1885 train acc:80.51% val loss:0.2068 val acc:79.32%\n",
            "80/100 train loss:0.1820 train acc:81.16% val loss:0.2369 val acc:76.31%\n",
            "81/100 train loss:0.1804 train acc:81.32% val loss:0.2037 val acc:79.63%\n",
            "82/100 train loss:0.1748 train acc:81.88% val loss:0.2188 val acc:78.12%\n",
            "83/100 train loss:0.1706 train acc:82.30% val loss:0.2087 val acc:79.13%\n",
            "84/100 train loss:0.1734 train acc:82.02% val loss:0.2063 val acc:79.37%\n",
            "85/100 train loss:0.1697 train acc:82.40% val loss:0.2048 val acc:79.52%\n",
            "86/100 train loss:0.1728 train acc:82.08% val loss:0.2046 val acc:79.54%\n",
            "87/100 train loss:0.1739 train acc:81.98% val loss:0.4171 val acc:58.29%\n",
            "88/100 train loss:0.1716 train acc:82.20% val loss:0.2027 val acc:79.73%\n",
            "89/100 train loss:0.1669 train acc:82.67% val loss:0.1968 val acc:80.32%\n",
            "90/100 train loss:0.1653 train acc:82.84% val loss:0.2143 val acc:78.57%\n",
            "91/100 train loss:0.1724 train acc:82.13% val loss:0.1985 val acc:80.15%\n",
            "92/100 train loss:0.1708 train acc:82.28% val loss:0.3389 val acc:66.11%\n",
            "93/100 train loss:0.1712 train acc:82.24% val loss:0.2134 val acc:78.66%\n",
            "94/100 train loss:0.1724 train acc:82.12% val loss:0.2136 val acc:78.64%\n",
            "95/100 train loss:0.1675 train acc:82.61% val loss:0.2046 val acc:79.54%\n",
            "96/100 train loss:0.1705 train acc:82.31% val loss:0.2372 val acc:76.28%\n",
            "97/100 train loss:0.1606 train acc:83.30% val loss:0.2429 val acc:75.71%\n",
            "98/100 train loss:0.1671 train acc:82.66% val loss:0.1977 val acc:80.23%\n",
            "99/100 train loss:0.1634 train acc:83.02% val loss:0.2464 val acc:75.36%\n",
            "100/100 train loss:0.1637 train acc:83.00% val loss:0.2215 val acc:77.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XMeJoFiYlBuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MobileCA"
      ],
      "metadata": {
        "id": "05ZB_SJxvC8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from models import mbv2_ca\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        aug=True\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                       \n",
        "                      )\n",
        "model = mbv2_ca(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-ca{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fonuDUPEvEcn",
        "outputId": "bc1b45e7-b41c-4ebd-e199-62e8f8aaf10b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5660 train acc:42.75% val loss:0.6299 val acc:37.01%\n",
            "2/100 train loss:0.4838 train acc:50.99% val loss:0.5819 val acc:41.81%\n",
            "3/100 train loss:0.4136 train acc:58.01% val loss:0.3188 val acc:68.12%\n",
            "4/100 train loss:0.3301 train acc:66.36% val loss:0.4220 val acc:57.80%\n",
            "5/100 train loss:0.2672 train acc:72.65% val loss:0.7110 val acc:28.90%\n",
            "6/100 train loss:0.2441 train acc:74.96% val loss:0.2595 val acc:74.05%\n",
            "7/100 train loss:0.2269 train acc:76.67% val loss:0.3324 val acc:66.76%\n",
            "8/100 train loss:0.2166 train acc:77.71% val loss:0.2413 val acc:75.87%\n",
            "9/100 train loss:0.2116 train acc:78.21% val loss:0.2650 val acc:73.50%\n",
            "10/100 train loss:0.2103 train acc:78.33% val loss:0.2533 val acc:74.67%\n",
            "11/100 train loss:0.2008 train acc:79.29% val loss:0.2437 val acc:75.63%\n",
            "12/100 train loss:0.1962 train acc:79.75% val loss:0.3192 val acc:68.08%\n",
            "13/100 train loss:0.1909 train acc:80.27% val loss:0.2448 val acc:75.52%\n",
            "14/100 train loss:0.1920 train acc:80.16% val loss:0.2338 val acc:76.62%\n",
            "15/100 train loss:0.1828 train acc:81.08% val loss:0.2105 val acc:78.95%\n",
            "16/100 train loss:0.1809 train acc:81.27% val loss:0.7148 val acc:28.52%\n",
            "17/100 train loss:0.1836 train acc:81.01% val loss:0.2230 val acc:77.70%\n",
            "18/100 train loss:0.1767 train acc:81.69% val loss:0.2086 val acc:79.14%\n",
            "19/100 train loss:0.1761 train acc:81.76% val loss:0.4881 val acc:51.19%\n",
            "20/100 train loss:0.1709 train acc:82.28% val loss:0.2206 val acc:77.94%\n",
            "21/100 train loss:0.1733 train acc:82.03% val loss:0.2323 val acc:76.77%\n",
            "22/100 train loss:0.1671 train acc:82.65% val loss:0.4433 val acc:55.67%\n",
            "23/100 train loss:0.1692 train acc:82.45% val loss:0.2057 val acc:79.43%\n",
            "24/100 train loss:0.1621 train acc:83.16% val loss:0.2222 val acc:77.78%\n",
            "25/100 train loss:0.1606 train acc:83.31% val loss:0.2371 val acc:76.29%\n",
            "26/100 train loss:0.1639 train acc:82.97% val loss:0.2079 val acc:79.21%\n",
            "27/100 train loss:0.1522 train acc:84.14% val loss:0.2291 val acc:77.09%\n",
            "28/100 train loss:0.1564 train acc:83.73% val loss:0.2453 val acc:75.47%\n",
            "29/100 train loss:0.1533 train acc:84.04% val loss:0.2450 val acc:75.50%\n",
            "30/100 train loss:0.1492 train acc:84.45% val loss:0.1954 val acc:80.46%\n",
            "31/100 train loss:0.1444 train acc:84.92% val loss:0.7269 val acc:27.31%\n",
            "32/100 train loss:0.1504 train acc:84.33% val loss:0.2266 val acc:77.34%\n",
            "33/100 train loss:0.1463 train acc:84.73% val loss:0.1988 val acc:80.12%\n",
            "34/100 train loss:0.1462 train acc:84.75% val loss:0.1965 val acc:80.35%\n",
            "35/100 train loss:0.1380 train acc:85.57% val loss:0.2228 val acc:77.72%\n",
            "36/100 train loss:0.1442 train acc:84.94% val loss:0.2181 val acc:78.19%\n",
            "37/100 train loss:0.1441 train acc:84.95% val loss:0.2105 val acc:78.95%\n",
            "38/100 train loss:0.1479 train acc:84.57% val loss:0.2509 val acc:74.91%\n",
            "39/100 train loss:0.1364 train acc:85.72% val loss:0.2156 val acc:78.44%\n",
            "40/100 train loss:0.1387 train acc:85.50% val loss:0.2051 val acc:79.49%\n",
            "41/100 train loss:0.1323 train acc:86.13% val loss:0.1871 val acc:81.29%\n",
            "42/100 train loss:0.1310 train acc:86.26% val loss:0.1863 val acc:81.37%\n",
            "43/100 train loss:0.1343 train acc:85.93% val loss:0.6400 val acc:36.00%\n",
            "44/100 train loss:0.1327 train acc:86.09% val loss:0.2088 val acc:79.12%\n",
            "45/100 train loss:0.1324 train acc:86.12% val loss:0.1840 val acc:81.60%\n",
            "46/100 train loss:0.1318 train acc:86.19% val loss:0.1849 val acc:81.51%\n",
            "47/100 train loss:0.1279 train acc:86.57% val loss:0.2130 val acc:78.70%\n",
            "48/100 train loss:0.1301 train acc:86.36% val loss:0.1857 val acc:81.43%\n",
            "49/100 train loss:0.1287 train acc:86.49% val loss:0.1983 val acc:80.17%\n",
            "50/100 train loss:0.1247 train acc:86.89% val loss:0.1950 val acc:80.50%\n",
            "51/100 train loss:0.1211 train acc:87.25% val loss:0.2282 val acc:77.18%\n",
            "52/100 train loss:0.1177 train acc:87.59% val loss:0.2161 val acc:78.39%\n",
            "53/100 train loss:0.1218 train acc:87.18% val loss:0.1777 val acc:82.23%\n",
            "54/100 train loss:0.1262 train acc:86.75% val loss:0.1814 val acc:81.86%\n",
            "55/100 train loss:0.1166 train acc:87.71% val loss:0.1847 val acc:81.53%\n",
            "56/100 train loss:0.1124 train acc:88.12% val loss:0.1826 val acc:81.74%\n",
            "57/100 train loss:0.1214 train acc:87.23% val loss:0.1876 val acc:81.24%\n",
            "58/100 train loss:0.1150 train acc:87.86% val loss:0.2286 val acc:77.14%\n",
            "59/100 train loss:0.1129 train acc:88.07% val loss:0.1940 val acc:80.60%\n",
            "60/100 train loss:0.1155 train acc:87.82% val loss:0.2117 val acc:78.83%\n",
            "61/100 train loss:0.1150 train acc:87.86% val loss:0.1892 val acc:81.08%\n",
            "62/100 train loss:0.1091 train acc:88.45% val loss:0.1894 val acc:81.06%\n",
            "63/100 train loss:0.1064 train acc:88.73% val loss:0.3647 val acc:63.53%\n",
            "64/100 train loss:0.1136 train acc:88.00% val loss:0.1842 val acc:81.58%\n",
            "65/100 train loss:0.1092 train acc:88.45% val loss:0.1900 val acc:81.00%\n",
            "66/100 train loss:0.1101 train acc:88.36% val loss:0.6476 val acc:35.24%\n",
            "67/100 train loss:0.1065 train acc:88.72% val loss:0.1955 val acc:80.45%\n",
            "68/100 train loss:0.1069 train acc:88.68% val loss:0.1709 val acc:82.91%\n",
            "69/100 train loss:0.1080 train acc:88.56% val loss:0.1835 val acc:81.65%\n",
            "70/100 train loss:0.1046 train acc:88.90% val loss:0.1831 val acc:81.69%\n",
            "71/100 train loss:0.1079 train acc:88.58% val loss:0.1729 val acc:82.71%\n",
            "72/100 train loss:0.1050 train acc:88.86% val loss:0.4923 val acc:50.77%\n",
            "73/100 train loss:0.1035 train acc:89.01% val loss:0.1993 val acc:80.07%\n",
            "74/100 train loss:0.1024 train acc:89.12% val loss:0.1854 val acc:81.46%\n",
            "75/100 train loss:0.1024 train acc:89.13% val loss:0.1601 val acc:83.99%\n",
            "76/100 train loss:0.1050 train acc:88.87% val loss:0.4991 val acc:50.09%\n",
            "77/100 train loss:0.1027 train acc:89.09% val loss:0.1732 val acc:82.68%\n",
            "78/100 train loss:0.1050 train acc:88.86% val loss:0.1895 val acc:81.05%\n",
            "79/100 train loss:0.1005 train acc:89.32% val loss:0.1826 val acc:81.74%\n",
            "80/100 train loss:0.0989 train acc:89.48% val loss:0.1798 val acc:82.02%\n",
            "81/100 train loss:0.1030 train acc:89.06% val loss:0.1806 val acc:81.94%\n",
            "82/100 train loss:0.0978 train acc:89.59% val loss:0.1746 val acc:82.54%\n",
            "83/100 train loss:0.0961 train acc:89.76% val loss:0.1795 val acc:82.05%\n",
            "84/100 train loss:0.0954 train acc:89.82% val loss:0.1801 val acc:81.99%\n",
            "85/100 train loss:0.0956 train acc:89.81% val loss:0.1732 val acc:82.68%\n",
            "86/100 train loss:0.0947 train acc:89.89% val loss:0.2104 val acc:78.96%\n",
            "87/100 train loss:0.0983 train acc:89.53% val loss:0.1881 val acc:81.19%\n",
            "88/100 train loss:0.0953 train acc:89.83% val loss:0.1674 val acc:83.26%\n",
            "89/100 train loss:0.0996 train acc:89.40% val loss:0.1705 val acc:82.95%\n",
            "90/100 train loss:0.0946 train acc:89.90% val loss:0.1678 val acc:83.22%\n",
            "91/100 train loss:0.0934 train acc:90.03% val loss:0.1990 val acc:80.10%\n",
            "92/100 train loss:0.0964 train acc:89.72% val loss:0.1803 val acc:81.97%\n",
            "93/100 train loss:0.0949 train acc:89.87% val loss:0.1666 val acc:83.34%\n",
            "94/100 train loss:0.0946 train acc:89.91% val loss:0.1737 val acc:82.63%\n",
            "95/100 train loss:0.0932 train acc:90.05% val loss:0.1810 val acc:81.90%\n",
            "96/100 train loss:0.0962 train acc:89.75% val loss:0.1763 val acc:82.37%\n",
            "97/100 train loss:0.0957 train acc:89.80% val loss:0.1709 val acc:82.91%\n",
            "98/100 train loss:0.0914 train acc:90.22% val loss:0.1803 val acc:81.97%\n",
            "99/100 train loss:0.0943 train acc:89.94% val loss:0.2515 val acc:74.85%\n",
            "100/100 train loss:0.0982 train acc:89.54% val loss:0.1662 val acc:83.38%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xTCST85Jf6sA",
        "ugrRquc7DAqt",
        "3buwods0G4bU",
        "5nEdFbrOkMnd",
        "xytYsQDyuV7I",
        "lkq1JglY8nRh",
        "JWvyZzfyDEwm"
      ],
      "name": "task345.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}