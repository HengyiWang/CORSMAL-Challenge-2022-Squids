{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTCST85Jf6sA"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v9ej-BmvgInY"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import scipy.io.wavfile\n",
        "import time\n",
        "import IPython\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "import json\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms\n",
        "from dataset import MiniDataset\n",
        "from loss import computeScoreType1, myLoss\n",
        "from models import Net, effnetv2_xl, MobileNetV3_Large\n",
        "from helper import train_image, evaluate_image\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BTQA8MKYgN1r"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD/crops_rgb_train.zip /content/crops_rgb_train.zip\n",
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD/crops_rgb_test.zip /content/crops_rgb_test.zip\n",
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD/crops_depth_train.zip /content/crops_depth_train.zip\n",
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD/crops_depth_test.zip /content/crops_depth_test.zip\n",
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD/labels_test.zip /content/labels_test.zip\n",
        "!cp /content/drive/MyDrive/COSRMAL_CHALLENGE/RGBD/labels_train.zip /content/labels_train.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GKjFsuRg8wX",
        "outputId": "f26187d9-6154-46b3-e151-077a1e596539"
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/train',exist_ok=True)\n",
        "os.makedirs('/content/test',exist_ok=True)\n",
        "!unzip /content/crops_rgb_train.zip -d /content/train/\n",
        "!unzip /content/crops_rgb_test.zip -d /content/test/\n",
        "!unzip /content/crops_depth_train.zip -d /content/train/\n",
        "!unzip /content/crops_depth_test.zip -d /content/test/\n",
        "!unzip /content/labels_train.zip -d /content/train/\n",
        "!unzip /content/labels_test.zip -d /content/test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2kxapxBc7_J"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Capacity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7ge09lVhZNY",
        "outputId": "e6ffa79b-2cf5-4e4d-ec58-297c4b6000fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/50 train loss:0.5427 train acc:31.11% val loss:0.5720 val acc:26.78%\n",
            "2/50 train loss:0.4562 train acc:48.15% val loss:0.4846 val acc:38.49%\n",
            "3/50 train loss:0.3094 train acc:69.06% val loss:0.3300 val acc:67.00%\n",
            "4/50 train loss:0.2892 train acc:71.08% val loss:0.3078 val acc:69.22%\n",
            "5/50 train loss:0.2902 train acc:70.98% val loss:0.3136 val acc:68.64%\n",
            "6/50 train loss:0.2866 train acc:71.34% val loss:0.3190 val acc:68.10%\n",
            "7/50 train loss:0.2842 train acc:71.58% val loss:0.3055 val acc:69.45%\n",
            "8/50 train loss:0.2883 train acc:71.17% val loss:0.3106 val acc:68.94%\n",
            "9/50 train loss:0.2878 train acc:71.22% val loss:0.3123 val acc:68.77%\n",
            "10/50 train loss:0.2875 train acc:71.25% val loss:0.3227 val acc:67.73%\n",
            "11/50 train loss:0.2860 train acc:71.40% val loss:0.3280 val acc:67.20%\n",
            "12/50 train loss:0.2822 train acc:71.78% val loss:0.3241 val acc:67.59%\n",
            "13/50 train loss:0.2841 train acc:71.59% val loss:0.3093 val acc:69.07%\n",
            "14/50 train loss:0.2835 train acc:71.65% val loss:0.3170 val acc:68.30%\n",
            "15/50 train loss:0.2819 train acc:71.81% val loss:0.2970 val acc:70.30%\n",
            "16/50 train loss:0.2795 train acc:72.05% val loss:0.3009 val acc:69.91%\n",
            "17/50 train loss:0.2811 train acc:71.89% val loss:0.2784 val acc:72.16%\n",
            "18/50 train loss:0.2796 train acc:72.04% val loss:0.2546 val acc:74.54%\n",
            "19/50 train loss:0.2710 train acc:72.90% val loss:0.2514 val acc:74.86%\n",
            "20/50 train loss:0.2632 train acc:73.68% val loss:0.2623 val acc:73.77%\n",
            "21/50 train loss:0.2486 train acc:75.14% val loss:0.2511 val acc:74.89%\n",
            "22/50 train loss:0.2391 train acc:76.09% val loss:0.2541 val acc:74.59%\n",
            "23/50 train loss:0.2295 train acc:77.05% val loss:0.2484 val acc:75.16%\n",
            "24/50 train loss:0.2156 train acc:78.44% val loss:0.2445 val acc:75.55%\n",
            "25/50 train loss:0.2117 train acc:78.83% val loss:0.2510 val acc:74.90%\n",
            "26/50 train loss:0.2049 train acc:79.51% val loss:0.2446 val acc:75.54%\n",
            "27/50 train loss:0.2025 train acc:79.75% val loss:0.2391 val acc:76.09%\n",
            "28/50 train loss:0.1977 train acc:80.23% val loss:0.2455 val acc:75.45%\n",
            "29/50 train loss:0.1950 train acc:80.50% val loss:0.2276 val acc:77.24%\n",
            "30/50 train loss:0.1874 train acc:81.26% val loss:0.2439 val acc:75.61%\n",
            "31/50 train loss:0.1846 train acc:81.54% val loss:0.2500 val acc:75.00%\n",
            "32/50 train loss:0.1814 train acc:81.86% val loss:0.2170 val acc:78.30%\n",
            "33/50 train loss:0.1772 train acc:82.28% val loss:0.2399 val acc:76.01%\n",
            "34/50 train loss:0.1730 train acc:82.70% val loss:0.2113 val acc:78.87%\n",
            "35/50 train loss:0.1670 train acc:83.30% val loss:0.2219 val acc:77.81%\n",
            "36/50 train loss:0.1560 train acc:84.40% val loss:0.2144 val acc:78.56%\n",
            "37/50 train loss:0.1521 train acc:84.79% val loss:0.2091 val acc:79.09%\n",
            "38/50 train loss:0.1467 train acc:85.33% val loss:0.2215 val acc:77.85%\n",
            "39/50 train loss:0.1413 train acc:85.87% val loss:0.1991 val acc:80.09%\n",
            "40/50 train loss:0.1392 train acc:86.08% val loss:0.1974 val acc:80.26%\n",
            "41/50 train loss:0.1346 train acc:86.54% val loss:0.2169 val acc:78.31%\n",
            "42/50 train loss:0.1313 train acc:86.87% val loss:0.2235 val acc:77.65%\n",
            "43/50 train loss:0.1261 train acc:87.39% val loss:0.2361 val acc:76.39%\n",
            "44/50 train loss:0.1220 train acc:87.80% val loss:0.2235 val acc:77.65%\n",
            "45/50 train loss:0.1216 train acc:87.84% val loss:0.2416 val acc:75.84%\n",
            "46/50 train loss:0.1205 train acc:87.95% val loss:0.2214 val acc:77.86%\n",
            "47/50 train loss:0.1122 train acc:88.78% val loss:0.1910 val acc:80.90%\n",
            "48/50 train loss:0.1136 train acc:88.64% val loss:0.2016 val acc:79.84%\n",
            "49/50 train loss:0.1125 train acc:88.75% val loss:0.1894 val acc:81.06%\n",
            "50/50 train loss:0.1070 train acc:89.30% val loss:0.1910 val acc:80.90%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 2\n",
        "train_split = 0.8\n",
        "lr = 1e-4\n",
        "epochs = 50\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb')\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                        '/content/test/labels', \n",
        "                        '/content/test/crops_depth',\n",
        "                        '/content/test/crops_rgb')\n",
        "model = effnetv2_xl(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  \n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train / num_train, 100 * correct_train/num_train,\n",
        "      loss_val /num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"XL-my{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB5uZuFlmZgS",
        "outputId": "7e2279bc-862e-4d90-afca-ad5edc9e722c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5963 train acc:24.71% val loss:0.5315 val acc:35.67%\n",
            "2/100 train loss:0.4706 train acc:38.27% val loss:0.7242 val acc:0.60%\n",
            "3/100 train loss:0.3704 train acc:55.41% val loss:0.3444 val acc:60.08%\n",
            "4/100 train loss:0.3108 train acc:65.45% val loss:0.4562 val acc:53.52%\n",
            "5/100 train loss:0.2637 train acc:72.20% val loss:0.2807 val acc:71.67%\n",
            "6/100 train loss:0.2341 train acc:75.72% val loss:0.4366 val acc:55.67%\n",
            "7/100 train loss:0.2190 train acc:77.07% val loss:0.2541 val acc:74.59%\n",
            "8/100 train loss:0.1995 train acc:79.21% val loss:0.2256 val acc:77.44%\n",
            "9/100 train loss:0.1982 train acc:79.42% val loss:0.3874 val acc:61.26%\n",
            "10/100 train loss:0.2175 train acc:77.48% val loss:0.5762 val acc:41.36%\n",
            "11/100 train loss:0.2191 train acc:77.38% val loss:0.2387 val acc:76.13%\n",
            "12/100 train loss:0.2662 train acc:72.18% val loss:0.2828 val acc:71.19%\n",
            "13/100 train loss:0.2357 train acc:75.66% val loss:0.5781 val acc:41.99%\n",
            "14/100 train loss:0.2013 train acc:79.18% val loss:0.2625 val acc:73.75%\n",
            "15/100 train loss:0.1889 train acc:80.45% val loss:0.2993 val acc:69.19%\n",
            "16/100 train loss:0.1938 train acc:79.96% val loss:0.3623 val acc:63.62%\n",
            "17/100 train loss:0.2068 train acc:78.61% val loss:0.2088 val acc:79.12%\n",
            "18/100 train loss:0.1971 train acc:79.57% val loss:0.2024 val acc:79.60%\n",
            "19/100 train loss:0.1821 train acc:81.11% val loss:0.2021 val acc:79.79%\n",
            "20/100 train loss:0.1735 train acc:81.99% val loss:0.1882 val acc:80.93%\n",
            "21/100 train loss:0.1667 train acc:82.61% val loss:0.1913 val acc:80.87%\n",
            "22/100 train loss:0.1554 train acc:83.82% val loss:0.1904 val acc:80.96%\n",
            "23/100 train loss:0.1610 train acc:83.24% val loss:0.2215 val acc:77.85%\n",
            "24/100 train loss:0.1554 train acc:83.81% val loss:0.1851 val acc:81.49%\n",
            "25/100 train loss:0.1617 train acc:83.18% val loss:0.6047 val acc:39.00%\n",
            "26/100 train loss:0.1587 train acc:83.48% val loss:0.1821 val acc:81.79%\n",
            "27/100 train loss:0.1960 train acc:79.71% val loss:0.2470 val acc:75.30%\n",
            "28/100 train loss:0.1934 train acc:79.94% val loss:0.1959 val acc:80.41%\n",
            "29/100 train loss:0.1795 train acc:81.39% val loss:0.1746 val acc:82.54%\n",
            "30/100 train loss:0.1712 train acc:82.23% val loss:0.1782 val acc:82.18%\n",
            "31/100 train loss:0.1726 train acc:82.03% val loss:0.1837 val acc:81.63%\n",
            "32/100 train loss:0.1603 train acc:83.33% val loss:0.1666 val acc:83.34%\n",
            "33/100 train loss:0.1667 train acc:82.67% val loss:0.1705 val acc:82.95%\n",
            "34/100 train loss:0.1573 train acc:83.64% val loss:0.1627 val acc:83.73%\n",
            "35/100 train loss:0.1495 train acc:84.40% val loss:0.1928 val acc:80.72%\n",
            "36/100 train loss:0.1510 train acc:84.21% val loss:0.2148 val acc:78.52%\n",
            "37/100 train loss:0.1688 train acc:82.43% val loss:0.1882 val acc:81.18%\n",
            "38/100 train loss:0.1495 train acc:84.40% val loss:0.1883 val acc:81.17%\n",
            "39/100 train loss:0.1473 train acc:84.63% val loss:0.1714 val acc:82.86%\n",
            "40/100 train loss:0.1596 train acc:83.36% val loss:0.1954 val acc:80.46%\n",
            "41/100 train loss:0.1575 train acc:83.58% val loss:0.1883 val acc:81.17%\n",
            "42/100 train loss:0.1516 train acc:84.17% val loss:0.1923 val acc:80.77%\n",
            "43/100 train loss:0.1442 train acc:84.92% val loss:0.2223 val acc:77.77%\n",
            "44/100 train loss:0.1600 train acc:83.32% val loss:0.1849 val acc:81.24%\n",
            "45/100 train loss:0.1435 train acc:85.01% val loss:0.1673 val acc:83.07%\n",
            "46/100 train loss:0.1494 train acc:84.41% val loss:0.1795 val acc:81.84%\n",
            "47/100 train loss:0.1571 train acc:83.65% val loss:0.2100 val acc:79.00%\n",
            "48/100 train loss:0.2046 train acc:78.79% val loss:0.2094 val acc:79.06%\n",
            "49/100 train loss:0.1716 train acc:82.18% val loss:0.1830 val acc:81.50%\n",
            "50/100 train loss:0.1737 train acc:81.92% val loss:0.2684 val acc:73.16%\n",
            "51/100 train loss:0.1845 train acc:80.86% val loss:0.2211 val acc:77.89%\n",
            "52/100 train loss:0.1867 train acc:80.62% val loss:0.1923 val acc:80.77%\n",
            "53/100 train loss:0.1679 train acc:82.53% val loss:0.1785 val acc:82.15%\n",
            "54/100 train loss:0.1646 train acc:82.87% val loss:0.2060 val acc:79.40%\n",
            "55/100 train loss:0.1666 train acc:82.69% val loss:0.3236 val acc:67.64%\n",
            "56/100 train loss:0.1510 train acc:84.26% val loss:0.2078 val acc:79.16%\n",
            "57/100 train loss:0.1572 train acc:83.64% val loss:0.1707 val acc:82.93%\n",
            "58/100 train loss:0.1594 train acc:83.37% val loss:0.1772 val acc:82.28%\n",
            "59/100 train loss:0.1408 train acc:85.18% val loss:0.1722 val acc:82.78%\n",
            "60/100 train loss:0.1452 train acc:84.68% val loss:0.1808 val acc:81.92%\n",
            "61/100 train loss:0.1396 train acc:85.33% val loss:0.2462 val acc:75.38%\n",
            "62/100 train loss:0.1593 train acc:83.26% val loss:0.2206 val acc:77.94%\n",
            "63/100 train loss:0.1627 train acc:82.93% val loss:0.1713 val acc:82.87%\n",
            "64/100 train loss:0.1574 train acc:83.55% val loss:0.1884 val acc:81.16%\n",
            "65/100 train loss:0.1531 train acc:83.96% val loss:0.1799 val acc:82.01%\n",
            "66/100 train loss:0.1447 train acc:84.71% val loss:0.1831 val acc:81.49%\n",
            "67/100 train loss:0.1410 train acc:85.21% val loss:0.1680 val acc:82.99%\n",
            "68/100 train loss:0.1471 train acc:84.53% val loss:0.2071 val acc:79.29%\n",
            "69/100 train loss:0.1653 train acc:82.61% val loss:0.1919 val acc:80.81%\n",
            "70/100 train loss:0.1579 train acc:83.37% val loss:0.1965 val acc:80.35%\n",
            "71/100 train loss:0.1546 train acc:83.59% val loss:0.1833 val acc:81.67%\n",
            "72/100 train loss:0.1434 train acc:84.73% val loss:0.1920 val acc:80.80%\n",
            "73/100 train loss:0.1482 train acc:84.23% val loss:0.1704 val acc:82.68%\n",
            "74/100 train loss:0.1528 train acc:83.77% val loss:0.2837 val acc:71.35%\n",
            "75/100 train loss:0.1509 train acc:84.07% val loss:0.3615 val acc:63.85%\n",
            "76/100 train loss:0.1481 train acc:84.41% val loss:0.1888 val acc:81.12%\n",
            "77/100 train loss:0.1395 train acc:85.36% val loss:0.1883 val acc:81.17%\n",
            "78/100 train loss:0.1397 train acc:85.20% val loss:0.1949 val acc:80.45%\n",
            "79/100 train loss:0.1394 train acc:85.23% val loss:0.1700 val acc:82.93%\n",
            "80/100 train loss:0.1421 train acc:85.00% val loss:0.1743 val acc:82.10%\n",
            "81/100 train loss:0.1388 train acc:85.35% val loss:0.2795 val acc:72.05%\n",
            "82/100 train loss:0.1547 train acc:83.70% val loss:0.1996 val acc:80.04%\n",
            "83/100 train loss:0.1622 train acc:82.75% val loss:0.2502 val acc:74.27%\n",
            "84/100 train loss:0.1525 train acc:84.04% val loss:0.1771 val acc:82.29%\n",
            "85/100 train loss:0.1539 train acc:83.84% val loss:0.3409 val acc:65.91%\n",
            "86/100 train loss:0.1569 train acc:83.59% val loss:0.1885 val acc:81.15%\n",
            "87/100 train loss:0.1492 train acc:84.21% val loss:0.1829 val acc:81.71%\n",
            "88/100 train loss:0.1454 train acc:84.57% val loss:0.1954 val acc:80.26%\n",
            "89/100 train loss:0.1469 train acc:84.47% val loss:0.1929 val acc:80.71%\n",
            "90/100 train loss:0.1408 train acc:85.02% val loss:0.1600 val acc:84.00%\n",
            "91/100 train loss:0.1395 train acc:85.22% val loss:0.1723 val acc:82.77%\n",
            "92/100 train loss:0.1376 train acc:85.46% val loss:0.1836 val acc:81.64%\n",
            "93/100 train loss:0.1364 train acc:85.52% val loss:0.1772 val acc:82.28%\n",
            "94/100 train loss:0.1490 train acc:84.25% val loss:0.2010 val acc:79.90%\n",
            "95/100 train loss:0.1571 train acc:83.58% val loss:0.1859 val acc:81.41%\n",
            "96/100 train loss:0.1430 train acc:84.93% val loss:0.1967 val acc:80.33%\n",
            "97/100 train loss:0.1502 train acc:84.26% val loss:0.1944 val acc:80.56%\n",
            "98/100 train loss:0.1397 train acc:85.12% val loss:0.1861 val acc:81.39%\n",
            "99/100 train loss:0.1457 train acc:84.53% val loss:0.1783 val acc:82.17%\n",
            "100/100 train loss:0.1393 train acc:85.20% val loss:0.1822 val acc:81.78%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb')\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                        '/content/test/labels', \n",
        "                        '/content/test/crops_depth',\n",
        "                        '/content/test/crops_rgb')\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3buwods0G4bU"
      },
      "source": [
        "## Mass estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJnFwsafG7AD",
        "outputId": "97997721-2cb3-4780-e19b-678d54305acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5667 train acc:37.74% val loss:0.5231 val acc:44.64%\n",
            "2/100 train loss:0.5083 train acc:43.19% val loss:0.5097 val acc:47.50%\n",
            "3/100 train loss:0.4908 train acc:46.11% val loss:0.5032 val acc:48.44%\n",
            "4/100 train loss:0.4784 train acc:47.61% val loss:0.4909 val acc:49.17%\n",
            "5/100 train loss:0.4683 train acc:49.29% val loss:0.4888 val acc:50.77%\n",
            "6/100 train loss:0.4605 train acc:51.14% val loss:0.4803 val acc:51.59%\n",
            "7/100 train loss:0.4529 train acc:52.43% val loss:0.4681 val acc:52.47%\n",
            "8/100 train loss:0.4413 train acc:53.27% val loss:0.4599 val acc:52.16%\n",
            "9/100 train loss:0.4282 train acc:54.98% val loss:0.4517 val acc:53.61%\n",
            "10/100 train loss:0.4172 train acc:55.60% val loss:0.4335 val acc:56.07%\n",
            "11/100 train loss:0.4110 train acc:56.66% val loss:0.4307 val acc:56.48%\n",
            "12/100 train loss:0.3991 train acc:58.20% val loss:0.4280 val acc:56.90%\n",
            "13/100 train loss:0.3940 train acc:59.06% val loss:0.4195 val acc:57.86%\n",
            "14/100 train loss:0.3837 train acc:60.33% val loss:0.4118 val acc:58.62%\n",
            "15/100 train loss:0.3765 train acc:60.94% val loss:0.4041 val acc:59.59%\n",
            "16/100 train loss:0.3742 train acc:61.17% val loss:0.4049 val acc:59.11%\n",
            "17/100 train loss:0.3729 train acc:61.36% val loss:0.4052 val acc:58.77%\n",
            "18/100 train loss:0.3744 train acc:61.32% val loss:0.4077 val acc:59.19%\n",
            "19/100 train loss:0.3735 train acc:61.62% val loss:0.3961 val acc:60.35%\n",
            "20/100 train loss:0.3737 train acc:61.55% val loss:0.3884 val acc:60.89%\n",
            "21/100 train loss:0.3696 train acc:62.09% val loss:0.4060 val acc:59.40%\n",
            "22/100 train loss:0.3627 train acc:62.89% val loss:0.3890 val acc:61.10%\n",
            "23/100 train loss:0.3587 train acc:63.19% val loss:0.3949 val acc:60.48%\n",
            "24/100 train loss:0.3529 train acc:63.71% val loss:0.3904 val acc:60.82%\n",
            "25/100 train loss:0.3438 train acc:64.63% val loss:0.3887 val acc:61.13%\n",
            "26/100 train loss:0.3453 train acc:64.57% val loss:0.3814 val acc:61.81%\n",
            "27/100 train loss:0.3367 train acc:65.32% val loss:0.3959 val acc:60.08%\n",
            "28/100 train loss:0.3372 train acc:65.30% val loss:0.3949 val acc:60.48%\n",
            "29/100 train loss:0.3315 train acc:65.85% val loss:0.3830 val acc:61.63%\n",
            "30/100 train loss:0.3278 train acc:66.22% val loss:0.3791 val acc:62.09%\n",
            "31/100 train loss:0.3326 train acc:65.84% val loss:0.3697 val acc:63.03%\n",
            "32/100 train loss:0.3314 train acc:65.98% val loss:0.3710 val acc:62.90%\n",
            "33/100 train loss:0.3211 train acc:66.97% val loss:0.3686 val acc:62.85%\n",
            "34/100 train loss:0.3289 train acc:66.24% val loss:0.3631 val acc:63.69%\n",
            "35/100 train loss:0.3285 train acc:66.37% val loss:0.3744 val acc:62.56%\n",
            "36/100 train loss:0.3204 train acc:67.23% val loss:0.3696 val acc:63.04%\n",
            "37/100 train loss:0.3166 train acc:67.56% val loss:0.3587 val acc:64.13%\n",
            "38/100 train loss:0.3162 train acc:67.52% val loss:0.3631 val acc:63.69%\n",
            "39/100 train loss:0.3130 train acc:67.89% val loss:0.3455 val acc:65.45%\n",
            "40/100 train loss:0.3173 train acc:67.46% val loss:0.3654 val acc:63.46%\n",
            "41/100 train loss:0.3175 train acc:67.41% val loss:0.3604 val acc:63.96%\n",
            "42/100 train loss:0.3077 train acc:68.35% val loss:0.3640 val acc:63.59%\n",
            "43/100 train loss:0.3039 train acc:68.69% val loss:0.3591 val acc:64.09%\n",
            "44/100 train loss:0.3007 train acc:69.01% val loss:0.3627 val acc:63.72%\n",
            "45/100 train loss:0.3027 train acc:68.85% val loss:0.3569 val acc:64.29%\n",
            "46/100 train loss:0.3045 train acc:68.64% val loss:0.3550 val acc:64.50%\n",
            "47/100 train loss:0.3103 train acc:68.09% val loss:0.3520 val acc:64.80%\n",
            "48/100 train loss:0.3057 train acc:68.57% val loss:0.3539 val acc:64.61%\n",
            "49/100 train loss:0.3009 train acc:68.99% val loss:0.3581 val acc:64.19%\n",
            "50/100 train loss:0.3064 train acc:68.40% val loss:0.3377 val acc:66.23%\n",
            "51/100 train loss:0.3074 train acc:68.29% val loss:0.3485 val acc:65.15%\n",
            "52/100 train loss:0.3016 train acc:68.86% val loss:0.3597 val acc:63.98%\n",
            "53/100 train loss:0.2974 train acc:69.27% val loss:0.3737 val acc:62.60%\n",
            "54/100 train loss:0.2955 train acc:69.44% val loss:0.3534 val acc:64.66%\n",
            "55/100 train loss:0.3014 train acc:68.85% val loss:0.3437 val acc:65.60%\n",
            "56/100 train loss:0.3045 train acc:68.56% val loss:0.3480 val acc:65.16%\n",
            "57/100 train loss:0.3006 train acc:69.03% val loss:0.3585 val acc:64.13%\n",
            "58/100 train loss:0.2900 train acc:70.08% val loss:0.3434 val acc:65.66%\n",
            "59/100 train loss:0.2921 train acc:69.88% val loss:0.3434 val acc:65.65%\n",
            "60/100 train loss:0.2860 train acc:70.49% val loss:0.3412 val acc:65.85%\n",
            "61/100 train loss:0.2897 train acc:70.11% val loss:0.3456 val acc:65.44%\n",
            "62/100 train loss:0.2887 train acc:70.21% val loss:0.3518 val acc:64.82%\n",
            "63/100 train loss:0.2926 train acc:69.86% val loss:0.3281 val acc:67.13%\n",
            "64/100 train loss:0.2881 train acc:70.31% val loss:0.3400 val acc:66.00%\n",
            "65/100 train loss:0.3019 train acc:68.93% val loss:0.3614 val acc:63.86%\n",
            "66/100 train loss:0.3058 train acc:68.69% val loss:0.3504 val acc:64.90%\n",
            "67/100 train loss:0.3199 train acc:67.28% val loss:0.3608 val acc:63.67%\n",
            "68/100 train loss:0.3105 train acc:68.22% val loss:0.3473 val acc:65.27%\n",
            "69/100 train loss:0.2998 train acc:69.24% val loss:0.3441 val acc:65.59%\n",
            "70/100 train loss:0.2947 train acc:69.81% val loss:0.3408 val acc:65.92%\n",
            "71/100 train loss:0.2930 train acc:69.98% val loss:0.3504 val acc:64.71%\n",
            "72/100 train loss:0.2880 train acc:70.50% val loss:0.3470 val acc:65.30%\n",
            "73/100 train loss:0.2943 train acc:69.89% val loss:0.3516 val acc:64.84%\n",
            "74/100 train loss:0.2911 train acc:70.14% val loss:0.3455 val acc:65.44%\n",
            "75/100 train loss:0.2834 train acc:70.94% val loss:0.3401 val acc:65.99%\n",
            "76/100 train loss:0.2842 train acc:70.83% val loss:0.3343 val acc:66.57%\n",
            "77/100 train loss:0.2796 train acc:71.25% val loss:0.3350 val acc:66.50%\n",
            "78/100 train loss:0.2782 train acc:71.40% val loss:0.3346 val acc:66.54%\n",
            "79/100 train loss:0.2847 train acc:70.76% val loss:0.3550 val acc:64.50%\n",
            "80/100 train loss:0.2857 train acc:70.69% val loss:0.3401 val acc:65.99%\n",
            "81/100 train loss:0.2863 train acc:70.65% val loss:0.3410 val acc:65.90%\n",
            "82/100 train loss:0.2875 train acc:70.55% val loss:0.3366 val acc:66.34%\n",
            "83/100 train loss:0.2910 train acc:70.16% val loss:0.3444 val acc:65.56%\n",
            "84/100 train loss:0.3066 train acc:68.63% val loss:0.3454 val acc:65.45%\n",
            "85/100 train loss:0.2990 train acc:69.40% val loss:0.3490 val acc:65.10%\n",
            "86/100 train loss:0.2963 train acc:69.67% val loss:0.3555 val acc:64.45%\n",
            "87/100 train loss:0.2876 train acc:70.53% val loss:0.3406 val acc:65.93%\n",
            "88/100 train loss:0.2905 train acc:70.26% val loss:0.3425 val acc:65.75%\n",
            "89/100 train loss:0.2902 train acc:70.29% val loss:0.3392 val acc:66.08%\n",
            "90/100 train loss:0.2866 train acc:70.64% val loss:0.3390 val acc:66.10%\n",
            "91/100 train loss:0.3093 train acc:68.34% val loss:0.3257 val acc:67.43%\n",
            "92/100 train loss:0.2923 train acc:70.09% val loss:0.3232 val acc:67.68%\n",
            "93/100 train loss:0.2931 train acc:69.99% val loss:0.3387 val acc:66.13%\n",
            "94/100 train loss:0.2909 train acc:70.21% val loss:0.3456 val acc:65.40%\n",
            "95/100 train loss:0.2834 train acc:70.98% val loss:0.3420 val acc:65.80%\n",
            "96/100 train loss:0.2823 train acc:71.09% val loss:0.3431 val acc:65.69%\n",
            "97/100 train loss:0.2799 train acc:71.32% val loss:0.3545 val acc:64.55%\n",
            "98/100 train loss:0.2785 train acc:71.47% val loss:0.3449 val acc:65.51%\n",
            "99/100 train loss:0.2772 train acc:71.59% val loss:0.3518 val acc:64.82%\n",
            "100/100 train loss:0.2788 train acc:71.37% val loss:0.3381 val acc:66.19%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-4\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        ['container mass']\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                      ['container mass']\n",
        "                       \n",
        "                      )\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-mass{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nEdFbrOkMnd"
      },
      "source": [
        "## height"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hkzm8FO9kPDI",
        "outputId": "9b161049-bee6-4212-d72d-6526797824b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5241 train acc:34.56% val loss:0.6423 val acc:14.70%\n",
            "2/100 train loss:0.3415 train acc:58.34% val loss:0.7800 val acc:0.76%\n",
            "3/100 train loss:0.2358 train acc:74.05% val loss:0.2700 val acc:72.25%\n",
            "4/100 train loss:0.1861 train acc:80.48% val loss:0.1998 val acc:80.02%\n",
            "5/100 train loss:0.1459 train acc:84.69% val loss:0.2061 val acc:79.39%\n",
            "6/100 train loss:0.1383 train acc:85.53% val loss:0.1615 val acc:83.85%\n",
            "7/100 train loss:0.1295 train acc:86.39% val loss:0.1569 val acc:84.31%\n",
            "8/100 train loss:0.1238 train acc:86.97% val loss:0.2292 val acc:77.08%\n",
            "9/100 train loss:0.1379 train acc:85.56% val loss:0.1402 val acc:85.98%\n",
            "10/100 train loss:0.1278 train acc:86.59% val loss:0.1362 val acc:86.38%\n",
            "11/100 train loss:0.1339 train acc:85.93% val loss:0.2093 val acc:78.79%\n",
            "12/100 train loss:0.1228 train acc:87.07% val loss:0.1471 val acc:85.29%\n",
            "13/100 train loss:0.1266 train acc:86.69% val loss:0.1381 val acc:86.19%\n",
            "14/100 train loss:0.1209 train acc:87.27% val loss:0.1244 val acc:87.56%\n",
            "15/100 train loss:0.1201 train acc:87.35% val loss:0.1354 val acc:86.46%\n",
            "16/100 train loss:0.1136 train acc:88.01% val loss:0.1188 val acc:88.12%\n",
            "17/100 train loss:0.1178 train acc:87.58% val loss:0.2634 val acc:73.66%\n",
            "18/100 train loss:0.1211 train acc:87.25% val loss:0.1261 val acc:87.39%\n",
            "19/100 train loss:0.1176 train acc:87.59% val loss:0.3015 val acc:69.85%\n",
            "20/100 train loss:0.1548 train acc:83.83% val loss:0.3131 val acc:68.69%\n",
            "21/100 train loss:0.1346 train acc:85.89% val loss:0.2235 val acc:77.65%\n",
            "22/100 train loss:0.1270 train acc:86.66% val loss:0.1492 val acc:85.08%\n",
            "23/100 train loss:0.1245 train acc:86.89% val loss:0.1352 val acc:86.48%\n",
            "24/100 train loss:0.1200 train acc:87.35% val loss:0.1427 val acc:85.73%\n",
            "25/100 train loss:0.1157 train acc:87.77% val loss:0.2118 val acc:78.82%\n",
            "26/100 train loss:0.1143 train acc:87.92% val loss:0.1445 val acc:85.55%\n",
            "27/100 train loss:0.1089 train acc:88.47% val loss:0.1456 val acc:85.36%\n",
            "28/100 train loss:0.1049 train acc:88.88% val loss:0.1193 val acc:88.07%\n",
            "29/100 train loss:0.1035 train acc:89.01% val loss:0.1186 val acc:88.00%\n",
            "30/100 train loss:0.1054 train acc:88.81% val loss:0.1440 val acc:85.33%\n",
            "31/100 train loss:0.1070 train acc:88.67% val loss:0.1440 val acc:85.60%\n",
            "32/100 train loss:0.1358 train acc:85.74% val loss:0.1711 val acc:82.70%\n",
            "33/100 train loss:0.1350 train acc:85.86% val loss:0.1409 val acc:85.91%\n",
            "34/100 train loss:0.1254 train acc:86.80% val loss:0.1227 val acc:87.73%\n",
            "35/100 train loss:0.1196 train acc:87.39% val loss:0.1438 val acc:85.17%\n",
            "36/100 train loss:0.1191 train acc:87.43% val loss:0.1303 val acc:86.97%\n",
            "37/100 train loss:0.1153 train acc:87.83% val loss:0.1279 val acc:87.21%\n",
            "38/100 train loss:0.1195 train acc:87.41% val loss:0.1378 val acc:86.15%\n",
            "39/100 train loss:0.1303 train acc:86.27% val loss:0.1314 val acc:86.86%\n",
            "40/100 train loss:0.1361 train acc:85.75% val loss:0.1690 val acc:82.92%\n",
            "41/100 train loss:0.1243 train acc:86.92% val loss:0.1464 val acc:85.19%\n",
            "42/100 train loss:0.1236 train acc:86.99% val loss:0.1392 val acc:86.08%\n",
            "43/100 train loss:0.1184 train acc:87.52% val loss:0.1453 val acc:85.47%\n",
            "44/100 train loss:0.1157 train acc:87.79% val loss:0.1671 val acc:83.29%\n",
            "45/100 train loss:0.1173 train acc:87.63% val loss:0.1390 val acc:86.10%\n",
            "46/100 train loss:0.1124 train acc:88.13% val loss:0.1494 val acc:85.06%\n",
            "47/100 train loss:0.1107 train acc:88.28% val loss:0.1522 val acc:84.78%\n",
            "48/100 train loss:0.1399 train acc:85.29% val loss:0.6164 val acc:38.14%\n",
            "49/100 train loss:0.1423 train acc:85.09% val loss:0.1362 val acc:86.38%\n",
            "50/100 train loss:0.1316 train acc:86.12% val loss:0.1478 val acc:85.22%\n",
            "51/100 train loss:0.1208 train acc:87.26% val loss:0.1339 val acc:86.61%\n",
            "52/100 train loss:0.1177 train acc:87.56% val loss:0.1248 val acc:87.52%\n",
            "53/100 train loss:0.1155 train acc:87.78% val loss:0.2297 val acc:77.03%\n",
            "54/100 train loss:0.1177 train acc:87.55% val loss:0.1887 val acc:81.13%\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-7e81e694cd58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m#start_time = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m   \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m   \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;31m#elapsed_time = time.time() - start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-ca1b4bac615a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mnum_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        ['height']\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                      ['height']\n",
        "                       \n",
        "                      )\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-height{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXoG_PAxwUDt"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xytYsQDyuV7I"
      },
      "source": [
        "## Width top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnNrMyZCuYNs",
        "outputId": "845dc971-1953-430d-eb05-cedfa0e24f96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.5314 train acc:39.50% val loss:0.6005 val acc:23.41%\n",
            "2/100 train loss:0.2665 train acc:69.09% val loss:0.6406 val acc:34.77%\n",
            "3/100 train loss:0.1906 train acc:79.53% val loss:0.5340 val acc:44.57%\n",
            "4/100 train loss:0.1843 train acc:80.41% val loss:0.2215 val acc:77.22%\n",
            "5/100 train loss:0.1499 train acc:84.31% val loss:0.3014 val acc:69.86%\n",
            "6/100 train loss:0.1405 train acc:85.28% val loss:0.1717 val acc:82.83%\n",
            "7/100 train loss:0.1491 train acc:84.38% val loss:0.5779 val acc:42.21%\n",
            "8/100 train loss:0.1401 train acc:85.34% val loss:0.1335 val acc:86.65%\n",
            "9/100 train loss:0.1587 train acc:83.36% val loss:0.1406 val acc:85.94%\n",
            "10/100 train loss:0.1332 train acc:86.04% val loss:0.1495 val acc:85.05%\n",
            "11/100 train loss:0.1254 train acc:86.82% val loss:0.1280 val acc:87.20%\n",
            "12/100 train loss:0.1159 train acc:87.76% val loss:0.1435 val acc:85.65%\n",
            "13/100 train loss:0.1275 train acc:86.57% val loss:0.3790 val acc:62.10%\n",
            "14/100 train loss:0.1245 train acc:86.88% val loss:0.1282 val acc:87.18%\n",
            "15/100 train loss:0.1138 train acc:87.98% val loss:0.1412 val acc:85.88%\n",
            "16/100 train loss:0.1078 train acc:88.56% val loss:0.1372 val acc:86.28%\n",
            "17/100 train loss:0.1202 train acc:87.22% val loss:0.1621 val acc:83.79%\n",
            "18/100 train loss:0.1187 train acc:87.47% val loss:0.2359 val acc:75.97%\n",
            "19/100 train loss:0.1112 train acc:88.21% val loss:0.1293 val acc:86.84%\n",
            "20/100 train loss:0.1133 train acc:87.99% val loss:0.2723 val acc:71.22%\n",
            "21/100 train loss:0.1261 train acc:86.65% val loss:0.1262 val acc:87.38%\n",
            "22/100 train loss:0.1058 train acc:88.78% val loss:0.1322 val acc:86.78%\n",
            "23/100 train loss:0.1132 train acc:88.03% val loss:0.3227 val acc:66.47%\n",
            "24/100 train loss:0.1075 train acc:88.61% val loss:0.1343 val acc:86.57%\n",
            "25/100 train loss:0.0969 train acc:89.67% val loss:0.1684 val acc:82.99%\n",
            "26/100 train loss:0.0970 train acc:89.66% val loss:0.1599 val acc:83.85%\n",
            "27/100 train loss:0.1031 train acc:89.03% val loss:0.1458 val acc:85.42%\n",
            "28/100 train loss:0.1131 train acc:88.03% val loss:0.1513 val acc:84.87%\n",
            "29/100 train loss:0.1014 train acc:89.23% val loss:0.1291 val acc:86.89%\n",
            "30/100 train loss:0.1340 train acc:85.80% val loss:0.4019 val acc:56.89%\n",
            "31/100 train loss:0.1361 train acc:85.55% val loss:0.1337 val acc:86.63%\n",
            "32/100 train loss:0.1084 train acc:88.51% val loss:0.1286 val acc:86.86%\n",
            "33/100 train loss:0.1021 train acc:89.11% val loss:0.1194 val acc:88.06%\n",
            "34/100 train loss:0.1054 train acc:88.81% val loss:0.1329 val acc:86.71%\n",
            "35/100 train loss:0.0998 train acc:89.38% val loss:0.1228 val acc:87.72%\n",
            "36/100 train loss:0.1363 train acc:85.60% val loss:0.1738 val acc:82.62%\n",
            "37/100 train loss:0.1503 train acc:84.18% val loss:0.1562 val acc:84.38%\n",
            "38/100 train loss:0.1328 train acc:85.96% val loss:0.1898 val acc:80.61%\n",
            "39/100 train loss:0.1105 train acc:88.28% val loss:0.1690 val acc:82.68%\n",
            "40/100 train loss:0.1147 train acc:87.84% val loss:0.1493 val acc:85.07%\n",
            "41/100 train loss:0.1163 train acc:87.68% val loss:0.1567 val acc:84.33%\n",
            "42/100 train loss:0.1211 train acc:87.23% val loss:0.1283 val acc:87.17%\n",
            "43/100 train loss:0.1085 train acc:88.51% val loss:0.1348 val acc:86.52%\n",
            "44/100 train loss:0.1061 train acc:88.76% val loss:0.1325 val acc:86.75%\n",
            "45/100 train loss:0.1011 train acc:89.24% val loss:0.1213 val acc:87.87%\n",
            "46/100 train loss:0.0955 train acc:89.81% val loss:0.1253 val acc:87.47%\n",
            "47/100 train loss:0.0974 train acc:89.61% val loss:0.1312 val acc:86.88%\n",
            "48/100 train loss:0.0924 train acc:90.12% val loss:0.1418 val acc:85.13%\n",
            "49/100 train loss:0.0944 train acc:89.90% val loss:0.1188 val acc:88.12%\n",
            "50/100 train loss:0.0912 train acc:90.24% val loss:0.1297 val acc:87.03%\n",
            "51/100 train loss:0.0999 train acc:89.31% val loss:0.1122 val acc:88.78%\n",
            "52/100 train loss:0.1022 train acc:89.11% val loss:0.1342 val acc:86.58%\n",
            "53/100 train loss:0.1088 train acc:88.41% val loss:0.1725 val acc:82.40%\n",
            "54/100 train loss:0.1020 train acc:89.08% val loss:0.1380 val acc:86.20%\n",
            "55/100 train loss:0.0987 train acc:89.46% val loss:0.1606 val acc:83.94%\n",
            "56/100 train loss:0.0939 train acc:89.95% val loss:0.1345 val acc:86.55%\n",
            "57/100 train loss:0.1090 train acc:88.38% val loss:0.1417 val acc:85.83%\n",
            "58/100 train loss:0.1019 train acc:89.13% val loss:0.1222 val acc:87.51%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        ['width at the top']\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                      ['width at the top']\n",
        "                       \n",
        "                      )\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-wt{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkq1JglY8nRh"
      },
      "source": [
        "## Width bottom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ext8gXOE8j_m",
        "outputId": "62930783-738b-4a6e-bc18-6457a5a5d115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "1/100 train loss:0.4981 train acc:40.20% val loss:0.3756 val acc:55.33%\n",
            "2/100 train loss:0.2650 train acc:69.72% val loss:0.2494 val acc:73.34%\n",
            "3/100 train loss:0.2077 train acc:77.56% val loss:0.8076 val acc:1.79%\n",
            "4/100 train loss:0.1845 train acc:80.56% val loss:0.6332 val acc:34.38%\n",
            "5/100 train loss:0.1622 train acc:82.80% val loss:0.1551 val acc:84.49%\n",
            "6/100 train loss:0.1621 train acc:82.82% val loss:0.1393 val acc:85.95%\n",
            "7/100 train loss:0.1503 train acc:83.98% val loss:0.3631 val acc:61.43%\n",
            "8/100 train loss:0.1444 train acc:84.65% val loss:0.1260 val acc:87.15%\n",
            "9/100 train loss:0.1362 train acc:85.55% val loss:0.1376 val acc:86.24%\n",
            "10/100 train loss:0.1363 train acc:85.52% val loss:0.1353 val acc:86.47%\n",
            "11/100 train loss:0.1459 train acc:84.48% val loss:0.1963 val acc:80.37%\n",
            "12/100 train loss:0.1396 train acc:85.22% val loss:0.1243 val acc:87.30%\n",
            "13/100 train loss:0.1306 train acc:86.06% val loss:0.1328 val acc:86.59%\n",
            "14/100 train loss:0.1272 train acc:86.48% val loss:0.2046 val acc:77.95%\n",
            "15/100 train loss:0.1392 train acc:85.08% val loss:0.1315 val acc:86.85%\n",
            "16/100 train loss:0.1268 train acc:86.58% val loss:0.1172 val acc:88.28%\n",
            "17/100 train loss:0.1327 train acc:85.89% val loss:0.1627 val acc:83.44%\n",
            "18/100 train loss:0.1359 train acc:85.55% val loss:0.1752 val acc:81.43%\n",
            "19/100 train loss:0.1294 train acc:86.21% val loss:0.1632 val acc:83.68%\n",
            "20/100 train loss:0.1310 train acc:86.11% val loss:0.1362 val acc:84.22%\n",
            "21/100 train loss:0.1352 train acc:85.59% val loss:0.1211 val acc:87.89%\n",
            "22/100 train loss:0.1354 train acc:85.55% val loss:0.1589 val acc:84.11%\n",
            "23/100 train loss:0.1406 train acc:85.00% val loss:0.2322 val acc:76.78%\n",
            "24/100 train loss:0.1310 train acc:86.04% val loss:0.1540 val acc:84.60%\n",
            "25/100 train loss:0.1447 train acc:84.62% val loss:0.6835 val acc:13.30%\n",
            "26/100 train loss:0.1445 train acc:84.55% val loss:0.6294 val acc:37.06%\n",
            "27/100 train loss:0.1317 train acc:85.91% val loss:0.7050 val acc:15.54%\n",
            "28/100 train loss:0.1319 train acc:85.86% val loss:0.5432 val acc:43.67%\n",
            "29/100 train loss:0.1248 train acc:86.67% val loss:0.1651 val acc:83.49%\n",
            "30/100 train loss:0.1348 train acc:85.42% val loss:0.3342 val acc:66.02%\n",
            "31/100 train loss:0.1361 train acc:85.35% val loss:0.1875 val acc:81.25%\n",
            "32/100 train loss:0.1256 train acc:86.63% val loss:0.6280 val acc:37.20%\n",
            "33/100 train loss:0.1295 train acc:86.18% val loss:0.1229 val acc:87.32%\n",
            "34/100 train loss:0.1229 train acc:86.93% val loss:0.1565 val acc:83.92%\n",
            "35/100 train loss:0.1237 train acc:86.85% val loss:0.1237 val acc:87.63%\n",
            "36/100 train loss:0.1287 train acc:86.25% val loss:0.1559 val acc:83.35%\n",
            "37/100 train loss:0.1276 train acc:86.42% val loss:0.1565 val acc:84.35%\n",
            "38/100 train loss:0.1256 train acc:86.31% val loss:0.1143 val acc:88.57%\n",
            "39/100 train loss:0.1243 train acc:86.64% val loss:0.1381 val acc:86.19%\n",
            "40/100 train loss:0.1218 train acc:86.95% val loss:0.1229 val acc:87.50%\n",
            "41/100 train loss:0.1167 train acc:87.43% val loss:0.1374 val acc:85.46%\n",
            "42/100 train loss:0.1143 train acc:87.68% val loss:0.1345 val acc:86.11%\n",
            "43/100 train loss:0.1162 train acc:87.57% val loss:0.2172 val acc:74.91%\n",
            "44/100 train loss:0.1158 train acc:87.71% val loss:0.1540 val acc:84.39%\n",
            "45/100 train loss:0.1150 train acc:87.73% val loss:0.1286 val acc:87.14%\n",
            "46/100 train loss:0.1203 train acc:87.14% val loss:0.1126 val acc:88.74%\n",
            "47/100 train loss:0.1124 train acc:87.94% val loss:0.1566 val acc:83.24%\n",
            "48/100 train loss:0.1186 train acc:87.30% val loss:0.1392 val acc:85.83%\n",
            "49/100 train loss:0.1137 train acc:87.86% val loss:0.1494 val acc:85.06%\n",
            "50/100 train loss:0.1206 train acc:86.88% val loss:0.1878 val acc:81.22%\n",
            "51/100 train loss:0.1171 train acc:87.38% val loss:0.1438 val acc:84.97%\n",
            "52/100 train loss:0.1099 train acc:88.15% val loss:0.1315 val acc:86.85%\n",
            "53/100 train loss:0.1126 train acc:87.91% val loss:0.1739 val acc:82.14%\n",
            "54/100 train loss:0.1282 train acc:86.00% val loss:0.1264 val acc:87.36%\n",
            "55/100 train loss:0.1322 train acc:85.64% val loss:0.1625 val acc:83.75%\n",
            "56/100 train loss:0.1494 train acc:83.99% val loss:0.1423 val acc:85.77%\n",
            "57/100 train loss:0.1332 train acc:85.93% val loss:0.3976 val acc:56.28%\n",
            "58/100 train loss:0.1243 train acc:86.86% val loss:0.1976 val acc:80.24%\n",
            "59/100 train loss:0.1724 train acc:81.86% val loss:0.2362 val acc:75.91%\n",
            "60/100 train loss:0.1521 train acc:84.05% val loss:0.2994 val acc:68.97%\n",
            "61/100 train loss:0.1811 train acc:80.91% val loss:0.5832 val acc:41.31%\n",
            "62/100 train loss:0.1548 train acc:83.73% val loss:0.1563 val acc:83.98%\n",
            "63/100 train loss:0.1341 train acc:85.92% val loss:0.1256 val acc:87.44%\n",
            "64/100 train loss:0.1216 train acc:87.17% val loss:0.1696 val acc:83.04%\n",
            "65/100 train loss:0.1315 train acc:86.20% val loss:0.1204 val acc:87.96%\n",
            "66/100 train loss:0.1168 train acc:87.67% val loss:0.1139 val acc:88.61%\n",
            "67/100 train loss:0.1141 train acc:87.94% val loss:0.1132 val acc:88.68%\n",
            "68/100 train loss:0.1315 train acc:86.14% val loss:0.2196 val acc:77.57%\n",
            "69/100 train loss:0.1296 train acc:86.32% val loss:0.4459 val acc:54.62%\n",
            "70/100 train loss:0.1201 train acc:87.33% val loss:0.1396 val acc:85.85%\n",
            "71/100 train loss:0.1243 train acc:86.91% val loss:0.4837 val acc:50.76%\n",
            "72/100 train loss:0.1250 train acc:86.83% val loss:0.1410 val acc:85.90%\n",
            "73/100 train loss:0.1127 train acc:88.07% val loss:0.1330 val acc:86.70%\n",
            "74/100 train loss:0.1112 train acc:88.22% val loss:0.1270 val acc:87.30%\n",
            "75/100 train loss:0.1094 train acc:88.42% val loss:0.1289 val acc:87.01%\n",
            "76/100 train loss:0.1044 train acc:88.92% val loss:0.1183 val acc:88.17%\n",
            "77/100 train loss:0.1053 train acc:88.83% val loss:0.1064 val acc:89.36%\n",
            "78/100 train loss:0.1066 train acc:88.70% val loss:0.1175 val acc:88.25%\n",
            "79/100 train loss:0.0988 train acc:89.48% val loss:0.1192 val acc:88.08%\n",
            "80/100 train loss:0.1036 train acc:88.98% val loss:0.1255 val acc:87.45%\n",
            "81/100 train loss:0.0981 train acc:89.55% val loss:0.1194 val acc:88.06%\n",
            "82/100 train loss:0.0979 train acc:89.57% val loss:0.1257 val acc:87.35%\n",
            "83/100 train loss:0.0959 train acc:89.77% val loss:0.1095 val acc:89.05%\n",
            "84/100 train loss:0.0954 train acc:89.83% val loss:0.1280 val acc:87.20%\n",
            "85/100 train loss:0.0992 train acc:89.42% val loss:0.1392 val acc:86.08%\n",
            "86/100 train loss:0.1171 train acc:87.55% val loss:0.1314 val acc:86.60%\n",
            "87/100 train loss:0.1047 train acc:88.86% val loss:0.1129 val acc:88.71%\n",
            "88/100 train loss:0.1042 train acc:88.90% val loss:0.1233 val acc:87.35%\n",
            "89/100 train loss:0.1020 train acc:89.12% val loss:0.1079 val acc:89.21%\n",
            "90/100 train loss:0.0971 train acc:89.63% val loss:0.1083 val acc:89.17%\n",
            "91/100 train loss:0.1007 train acc:89.24% val loss:0.1148 val acc:88.52%\n",
            "92/100 train loss:0.1051 train acc:88.84% val loss:0.1005 val acc:89.95%\n",
            "93/100 train loss:0.1104 train acc:88.27% val loss:0.1218 val acc:87.73%\n",
            "94/100 train loss:0.1228 train acc:86.90% val loss:0.1530 val acc:84.70%\n",
            "95/100 train loss:0.1125 train acc:88.03% val loss:0.1242 val acc:87.58%\n",
            "96/100 train loss:0.1084 train acc:88.48% val loss:0.1205 val acc:87.95%\n",
            "97/100 train loss:0.1239 train acc:86.83% val loss:0.1313 val acc:86.87%\n",
            "98/100 train loss:0.1114 train acc:88.14% val loss:0.1260 val acc:87.40%\n",
            "99/100 train loss:0.1033 train acc:89.01% val loss:0.1099 val acc:88.89%\n",
            "100/100 train loss:0.1052 train acc:88.77% val loss:0.2345 val acc:76.55%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "my_save_path = '/content/drive/MyDrive/COSRMAL_CHALLENGE'\n",
        "bs = 30\n",
        "train_split = 0.8\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "train_set = MiniDataset('/content/train/',\n",
        "                        '/content/train/labels', \n",
        "                        '/content/train/crops_depth',\n",
        "                        '/content/train/crops_rgb',\n",
        "                        ['width at the bottom']\n",
        "                        )\n",
        "val_set = MiniDataset('/content/test/',\n",
        "                      '/content/test/labels', \n",
        "                      '/content/test/crops_depth',\n",
        "                      '/content/test/crops_rgb',\n",
        "                      ['width at the bottom']\n",
        "                       \n",
        "                      )\n",
        "model = MobileNetV3_Large(num_classes=1).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_acc = 0\n",
        "\n",
        "num_train = len(train_set)\n",
        "num_val = len(val_set)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader   = DataLoader(train_set,\n",
        "                            batch_size=bs,\n",
        "                            shuffle=True,\n",
        "                            num_workers=1,\n",
        "                            drop_last=True)\n",
        "val_loader   = DataLoader(val_set,\n",
        "                          batch_size=bs,\n",
        "                          shuffle=True,\n",
        "                          num_workers=1)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  #start_time = time.time()\n",
        "  loss_train, correct_train = train_image(model, train_loader, optimizer, device, criterion = myLoss)\n",
        "  loss_val, correct_val = evaluate_image(model, val_loader, device, myLoss)\n",
        "  #elapsed_time = time.time() - start_time\n",
        "  print(\"{}/{} train loss:{:.4f} train acc:{:.2f}% val loss:{:.4f} val acc:{:.2f}%\".format(\n",
        "      epoch+1,epochs, loss_train/num_train, 100 * correct_train/num_train,\n",
        "      loss_val/num_val, 100 * correct_val/num_val))\n",
        "  \n",
        "\n",
        "  # if loss_val < best_loss:\n",
        "  #   best_loss = loss_val\n",
        "  #   torch.save(model, os.path.join(base_path, 'audios', \"bl-efficient-xl.pth\"))\n",
        "  \n",
        "  if correct_val > best_acc:\n",
        "    best_acc = correct_val\n",
        "    torch.save(model.state_dict(), os.path.join(my_save_path, \n",
        "                                              'audios', \n",
        "                                              'RGBD',\n",
        "                                              \"mobile-wb{:.2f}.pth\".format(100 * correct_val/num_val)))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xTCST85Jf6sA",
        "lU7Y4M1egAh4",
        "cD3P6O_vc458",
        "3WUCTNd1o8G4",
        "6XvAhx-tdXJt"
      ],
      "name": "RGBD.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
